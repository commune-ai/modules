{
    "code": {
        "base.py": "# Python Substrate Interface Library\n#\n# Copyright 2018-2023 Stichting Polkascan (Polkascan Foundation).\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n\nimport warnings\n\nfrom datetime import datetime\nfrom hashlib import blake2b\n\nimport json\nimport logging\n\nimport requests\nfrom typing import Optional, Union, List\n\nfrom websocket import create_connection, WebSocketConnectionClosedException\n\nfrom scalecodec.base import ScaleBytes, RuntimeConfigurationObject, ScaleType\nfrom scalecodec.types import GenericCall, GenericExtrinsic, Extrinsic, MultiAccountId, GenericRuntimeCallDefinition\nfrom scalecodec.type_registry import load_type_registry_preset\nfrom scalecodec.updater import update_type_registries\nfrom .extensions import Extension\nfrom .interfaces import ExtensionInterface\n\nfrom .storage import StorageKey\n\nfrom .exceptions import SubstrateRequestException, ConfigurationError, StorageFunctionNotFound, BlockNotFound, \\\n    ExtrinsicNotFound, ExtensionCallNotFound\nfrom .key import Keypair, KeypairType, MnemonicLanguageCode\nfrom .utils.ss58 import ss58_decode, ss58_encode, is_valid_ss58_address, get_ss58_format\n\n\nWELL_KNOWN_STORAGE_KEYS = {\n    \"Code\": {\n        \"storage_key\": \"0x3a636f6465\",\n        \"value_type_string\": \"RawBytes\",\n        \"docs\": \"Wasm code of the runtime\",\n        \"default\": '0x'\n    },\n    \"HeapPages\": {\n        \"storage_key\": \"0x3a686561707061676573\",\n        \"value_type_string\": \"u64\",\n        \"docs\": \"Number of wasm linear memory pages required for execution of the runtime.\",\n        \"default\": \"0x0000000000000000\"\n    },\n    \"ExtrinsicIndex\": {\n        \"storage_key\": \"0x3a65787472696e7369635f696e646578\",\n        \"value_type_string\": \"u32\",\n        \"docs\": \"Number of wasm linear memory pages required for execution of the runtime.\",\n        \"default\": \"0x00000000\"\n    },\n}\n\n\n__all__ = ['SubstrateInterface', 'ExtrinsicReceipt', 'logger']\n\nlogger = logging.getLogger(__name__)\n\n\ndef list_remove_iter(xs: list):\n    removed = False\n    def remove():\n        nonlocal removed\n        removed = True\n\n    i = 0\n    while i < len(xs):\n        removed = False\n        yield xs[i], remove\n        if removed:\n            xs.pop(i)\n        else:\n            i += 1\n\n\nclass SubstrateInterface:\n\n    def __init__(self, url=None, websocket=None, ss58_format=None, type_registry=None, type_registry_preset=None,\n                 cache_region=None, runtime_config=None, use_remote_preset=False, ws_options=None,\n                 auto_discover=True, auto_reconnect=True, config=None):\n        \"\"\"\n        A specialized class in interfacing with a Substrate node.\n\n        Parameters\n        ----------\n        url: the URL to the substrate node, either in format https://127.0.0.1:9933 or wss://127.0.0.1:9944\n        ss58_format: The address type which account IDs will be SS58-encoded to Substrate addresses. Defaults to 42, for Kusama the address type is 2\n        type_registry: A dict containing the custom type registry in format: {'types': {'customType': 'u32'},..}\n        type_registry_preset: The name of the predefined type registry shipped with the SCALE-codec, e.g. kusama\n        cache_region: a Dogpile cache region as a central store for the metadata cache\n        use_remote_preset: When True preset is downloaded from GitHub master, otherwise use files from local installed scalecodec package\n        ws_options: dict of options to pass to the websocket-client create_connection function\n        config: dict of config flags to overwrite default configuration\n        \"\"\"\n\n        if (not url and not websocket) or (url and websocket):\n            raise ValueError(\"Either 'url' or 'websocket' must be provided\")\n\n        # Initialize lazy loading variables\n        self.__version = None\n        self.__name = None\n        self.__properties = None\n        self.__chain = None\n\n        self.__token_decimals = None\n        self.__token_symbol = None\n        self.__ss58_format = None\n\n        if not runtime_config:\n            runtime_config = RuntimeConfigurationObject()\n\n        self.runtime_config = runtime_config\n\n        self.cache_region = cache_region\n\n        if ss58_format is not None:\n            self.ss58_format = ss58_format\n\n        self.type_registry_preset = type_registry_preset\n        self.type_registry = type_registry\n\n        self.request_id = 1\n        self.url = url\n        self.websocket = None\n\n        # Websocket connection options\n        self.ws_options = ws_options or {}\n\n        if 'max_size' not in self.ws_options:\n            self.ws_options['max_size'] = 2 ** 32\n\n        if 'read_limit' not in self.ws_options:\n            self.ws_options['read_limit'] = 2 ** 32\n\n        if 'write_limit' not in self.ws_options:\n            self.ws_options['write_limit'] = 2 ** 32\n\n        self.__rpc_message_queue = []\n\n        if self.url and (self.url[0:6] == 'wss://' or self.url[0:5] == 'ws://'):\n            self.connect_websocket()\n\n        elif websocket:\n            self.websocket = websocket\n\n        self.mock_extrinsics = None\n        self.default_headers = {\n            'content-type': \"application/json\",\n            'cache-control': \"no-cache\"\n        }\n\n        self.metadata = None\n\n        self.runtime_version = None\n        self.transaction_version = None\n\n        self.block_hash = None\n        self.block_id = None\n\n        self.__metadata_cache = {}\n\n        self.config = {\n            'use_remote_preset': use_remote_preset,\n            'auto_discover': auto_discover,\n            'auto_reconnect': auto_reconnect,\n            'rpc_methods': None,\n            'strict_scale_decode': True\n        }\n\n        if type(config) is dict:\n            self.config.update(config)\n\n\n        # Initialize extension interface\n        self.extensions = ExtensionInterface(self)\n\n        self.session = requests.Session()\n\n        self.reload_type_registry(use_remote_preset=use_remote_preset, auto_discover=auto_discover)\n\n    def connect_websocket(self):\n        \"\"\"\n        (Re)creates the websocket connection, if the URL contains a 'ws' or 'wss' scheme\n\n        Returns\n        -------\n\n        \"\"\"\n        if self.url and (self.url[0:6] == 'wss://' or self.url[0:5] == 'ws://'):\n            self.debug_message(\"Connecting to {} ...\".format(self.url))\n            self.websocket = create_connection(\n                self.url,\n                **self.ws_options\n            )\n\n    def close(self):\n        \"\"\"\n        Cleans up resources for this instance like active websocket connection and active extensions\n\n        Returns\n        -------\n\n        \"\"\"\n        if self.websocket:\n            self.debug_message(\"Closing websocket connection\")\n            self.websocket.close()\n\n        self.extensions.unregister_all()\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.close()\n\n    @staticmethod\n    def debug_message(message: str):\n        \"\"\"\n        Submits a message to the debug logger\n\n        Parameters\n        ----------\n        message: str Debug message\n\n        Returns\n        -------\n\n        \"\"\"\n        logger.debug(message)\n\n    def supports_rpc_method(self, name: str) -> bool:\n        \"\"\"\n        Check if substrate RPC supports given method\n        Parameters\n        ----------\n        name: name of method to check\n\n        Returns\n        -------\n        bool\n        \"\"\"\n        if self.config.get('rpc_methods') is None:\n            self.config['rpc_methods'] = []\n            result = self.rpc_request(\"rpc_methods\", []).get('result')\n            if result:\n                self.config['rpc_methods'] = result.get('methods', [])\n\n        return name in self.config['rpc_methods']\n\n    def rpc_request(self, method, params, result_handler=None):\n        \"\"\"\n        Method that handles the actual RPC request to the Substrate node. The other implemented functions eventually\n        use this method to perform the request.\n\n        Parameters\n        ----------\n        result_handler: Callback function that processes the result received from the node\n        method: method of the JSONRPC request\n        params: a list containing the parameters of the JSONRPC request\n\n        Returns\n        -------\n        a dict with the parsed result of the request.\n        \"\"\"\n\n        request_id = self.request_id\n        self.request_id += 1\n\n        payload = {\n            \"jsonrpc\": \"2.0\",\n            \"method\": method,\n            \"params\": params,\n            \"id\": request_id\n        }\n\n        self.debug_message('RPC request #{}: \"{}\"'.format(request_id, method))\n\n        if self.websocket:\n            try:\n                self.websocket.send(json.dumps(payload))\n            except WebSocketConnectionClosedException:\n                if self.config.get('auto_reconnect') and self.url:\n                    # Try to reconnect websocket and retry rpc_request\n                    self.debug_message(\"Connection Closed; Trying to reconnecting...\")\n                    self.connect_websocket()\n\n                    return self.rpc_request(method=method, params=params, result_handler=result_handler)\n                else:\n                    # websocket connection is externally created, re-raise exception\n                    raise\n\n            update_nr = 0\n            json_body = None\n            subscription_id = None\n\n            while json_body is None:\n                # Search for subscriptions\n                for message, remove_message in list_remove_iter(self.__rpc_message_queue):\n\n                    # Check if result message is matching request ID\n                    if 'id' in message and message['id'] == request_id:\n\n                        remove_message()\n\n                        # Check if response has error\n                        if 'error' in message:\n                            raise SubstrateRequestException(message['error'])\n\n                        # If result handler is set, pass result through and loop until handler return value is set\n                        if callable(result_handler):\n\n                            # Set subscription ID and only listen to messages containing this ID\n                            subscription_id = message['result']\n                            self.debug_message(f\"Websocket subscription [{subscription_id}] created\")\n\n                        else:\n                            json_body = message\n\n                # Process subscription updates\n                for message, remove_message in list_remove_iter(self.__rpc_message_queue):\n                    # Check if message is meant for this subscription\n                    if 'params' in message and message['params']['subscription'] == subscription_id:\n\n                        remove_message()\n\n                        self.debug_message(f\"Websocket result [{subscription_id} #{update_nr}]: {message}\")\n\n                        # Call result_handler with message for processing\n                        callback_result = result_handler(message, update_nr, subscription_id)\n                        if callback_result is not None:\n                            json_body = callback_result\n\n                        update_nr += 1\n\n                # Read one more message to queue\n                if json_body is None:\n                    self.__rpc_message_queue.append(json.loads(self.websocket.recv()))\n\n        else:\n\n            if result_handler:\n                raise ConfigurationError(\"Result handlers only available for websockets (ws://) connections\")\n\n            response = self.session.request(\"POST\", self.url, data=json.dumps(payload), headers=self.default_headers)\n\n            if response.status_code != 200:\n                raise SubstrateRequestException(\n                    \"RPC request failed with HTTP status code {}\".format(response.status_code))\n\n            json_body = response.json()\n\n            # Check if response has error\n            if 'error' in json_body:\n                raise SubstrateRequestException(json_body['error'])\n\n        return json_body\n\n    @property\n    def name(self):\n        if self.__name is None:\n            self.__name = self.rpc_request(\"system_name\", []).get('result')\n        return self.__name\n\n    @property\n    def properties(self):\n        if self.__properties is None:\n            self.__properties = self.rpc_request(\"system_properties\", []).get('result')\n        return self.__properties\n\n    @property\n    def chain(self):\n        if self.__chain is None:\n            self.__chain = self.rpc_request(\"system_chain\", []).get('result')\n        return self.__chain\n\n    @property\n    def version(self):\n        if self.__version is None:\n            self.__version = self.rpc_request(\"system_version\", []).get('result')\n        return self.__version\n\n    @property\n    def token_decimals(self):\n        if self.__token_decimals is None:\n            self.__token_decimals = self.properties.get('tokenDecimals')\n        return self.__token_decimals\n\n    @token_decimals.setter\n    def token_decimals(self, value):\n        if type(value) is not int and value is not None:\n            raise TypeError('Token decimals must be an int')\n        self.__token_decimals = value\n\n    @property\n    def token_symbol(self):\n        if self.__token_symbol is None:\n            if self.properties:\n                self.__token_symbol = self.properties.get('tokenSymbol')\n            else:\n                self.__token_symbol = 'UNIT'\n        return self.__token_symbol\n\n    @token_symbol.setter\n    def token_symbol(self, value):\n        self.__token_symbol = value\n\n    @property\n    def ss58_format(self):\n        if self.__ss58_format is None:\n            if self.properties:\n\n                if self.properties.get('ss58Format') is not None:\n                    self.__ss58_format = self.properties.get('ss58Format')\n                elif self.properties.get('SS58Prefix') is not None:\n                    self.__ss58_format = self.properties.get('SS58Prefix')\n            else:\n                self.__ss58_format = 42\n        return self.__ss58_format\n\n    @ss58_format.setter\n    def ss58_format(self, value):\n        if type(value) is not int and value is not None:\n            raise TypeError('ss58_format must be an int')\n        self.__ss58_format = value\n\n        if self.runtime_config:\n            self.runtime_config.ss58_format = value\n\n    def implements_scaleinfo(self) -> Optional[bool]:\n        \"\"\"\n        Returns True if current runtime implementation a `PortableRegistry` (`MetadataV14` and higher)\n\n        Returns\n        -------\n        bool\n        \"\"\"\n        if self.metadata:\n            return self.metadata.portable_registry is not None\n\n    def get_chain_head(self):\n        \"\"\"\n        A pass-though to existing JSONRPC method `chain_getHead`\n\n        Returns\n        -------\n\n        \"\"\"\n        if self.supports_rpc_method(\"chain_getHead\"):\n            response = self.rpc_request(\"chain_getHead\", [])\n        else:\n            response = self.rpc_request(\"chain_getBlockHash\", [])\n\n        if response is not None:\n            if 'error' in response:\n                raise SubstrateRequestException(response['error']['message'])\n\n            return response.get('result')\n\n    def get_chain_finalised_head(self):\n        \"\"\"\n        A pass-though to existing JSONRPC method `chain_getFinalizedHead`\n\n        Returns\n        -------\n\n        \"\"\"\n        response = self.rpc_request(\"chain_getFinalizedHead\", [])\n\n        if response is not None:\n            if 'error' in response:\n                raise SubstrateRequestException(response['error']['message'])\n\n            return response.get('result')\n\n    def get_block_hash(self, block_id: int = None) -> str:\n        \"\"\"\n        A pass-though to existing JSONRPC method `chain_getBlockHash`\n\n        Parameters\n        ----------\n        block_id\n\n        Returns\n        -------\n\n        \"\"\"\n        response = self.rpc_request(\"chain_getBlockHash\", [block_id])\n\n        if 'error' in response:\n            raise SubstrateRequestException(response['error']['message'])\n        else:\n            return response.get('result')\n\n    def get_block_number(self, block_hash: str) -> int:\n        \"\"\"\n        A convenience method to get the block number for given block_hash\n\n        Parameters\n        ----------\n        block_hash\n\n        Returns\n        -------\n\n        \"\"\"\n        response = self.rpc_request(\"chain_getHeader\", [block_hash])\n\n        if 'error' in response:\n            raise SubstrateRequestException(response['error']['message'])\n\n        elif 'result' in response:\n\n            if response['result']:\n                return int(response['result']['number'], 16)\n\n    def get_block_metadata(self, block_hash=None, decode=True):\n        \"\"\"\n        A pass-though to existing JSONRPC method `state_getMetadata`.\n\n        Parameters\n        ----------\n        block_hash\n        decode: True for decoded version\n\n        Returns\n        -------\n\n        \"\"\"\n        params = None\n        if block_hash:\n            params = [block_hash]\n        response = self.rpc_request(\"state_getMetadata\", params)\n\n        if 'error' in response:\n            raise SubstrateRequestException(response['error']['message'])\n\n        if response.get('result') and decode:\n            metadata_decoder = self.runtime_config.create_scale_object(\n                'MetadataVersioned', data=ScaleBytes(response.get('result'))\n            )\n            metadata_decoder.decode()\n\n            return metadata_decoder\n\n        return response\n\n    def get_storage_by_key(self, block_hash: str, storage_key: str):\n        \"\"\"\n        A pass-though to existing JSONRPC method `state_getStorage`\n\n        Parameters\n        ----------\n        block_hash\n        storage_key\n\n        Returns\n        -------\n\n        \"\"\"\n\n        if self.supports_rpc_method('state_getStorageAt'):\n            response = self.rpc_request(\"state_getStorageAt\", [storage_key, block_hash])\n        else:\n            response = self.rpc_request(\"state_getStorage\", [storage_key, block_hash])\n\n        if 'result' in response:\n            return response.get('result')\n        elif 'error' in response:\n            raise SubstrateRequestException(response['error']['message'])\n        else:\n            raise SubstrateRequestException(\"Unknown error occurred during retrieval of events\")\n\n    def get_block_runtime_version(self, block_hash):\n        \"\"\"\n        Retrieve the runtime version id of given block_hash\n        Parameters\n        ----------\n        block_hash\n\n        Returns\n        -------\n\n        \"\"\"\n        if self.supports_rpc_method(\"state_getRuntimeVersion\"):\n            response = self.rpc_request(\"state_getRuntimeVersion\", [block_hash])\n        else:\n            response = self.rpc_request(\"chain_getRuntimeVersion\", [block_hash])\n\n        if 'error' in response:\n            raise SubstrateRequestException(response['error']['message'])\n\n        return response.get('result')\n\n    def generate_storage_hash(self, storage_module: str, storage_function: str, params: list = None,\n                              hashers: list = None) -> str:\n        \"\"\"\n        Generate a storage key for given module/function\n\n        Parameters\n        ----------\n        storage_module\n        storage_function\n        params: Parameters of the storage function, provided in scale encoded hex-bytes or ScaleBytes instances\n        hashers: Hashing methods used to determine storage key, defaults to 'Twox64Concat' if not provided\n\n        Returns\n        -------\n        str Hexstring respresentation of the storage key\n        \"\"\"\n        warnings.warn(\"Use StorageKey.generate() instead\", DeprecationWarning)\n\n        storage_key = StorageKey.create_from_storage_function(\n            storage_module, storage_function, params, runtime_config=self.runtime_config, metadata=self.metadata\n        )\n\n        return '0x{}'.format(storage_key.data.hex())\n\n    def convert_storage_parameter(self, scale_type, value):\n        warnings.warn(\"Use StorageKey.generate() instead\", DeprecationWarning)\n\n        if type(value) is bytes:\n            value = f'0x{value.hex()}'\n\n        if scale_type == 'AccountId':\n            if value[0:2] != '0x':\n                return '0x{}'.format(ss58_decode(value, self.ss58_format))\n\n        return value\n\n    # Runtime functions used by Substrate API\n\n    def init_runtime(self, block_hash=None, block_id=None):\n        \"\"\"\n        This method is used by all other methods that deals with metadata and types defined in the type registry.\n        It optionally retrieves the block_hash when block_id is given and sets the applicable metadata for that\n        block_hash. Also it applies all the versioned types at the time of the block_hash.\n\n        Because parsing of metadata and type registry is quite heavy, the result will be cached per runtime id.\n        In the future there could be support for caching backends like Redis to make this cache more persistent.\n\n        Parameters\n        ----------\n        block_hash\n        block_id\n\n        Returns\n        -------\n\n        \"\"\"\n\n        if block_id and block_hash:\n            raise ValueError('Cannot provide block_hash and block_id at the same time')\n\n        # Check if runtime state already set to current block\n        if (block_hash and block_hash == self.block_hash) or (block_id and block_id == self.block_id):\n            return\n\n        if block_id is not None:\n            block_hash = self.get_block_hash(block_id)\n\n        if not block_hash:\n            block_hash = self.get_chain_head()\n\n        self.block_hash = block_hash\n        self.block_id = block_id\n\n        # In fact calls and storage functions are decoded against runtime of previous block, therefor retrieve\n        # metadata and apply type registry of runtime of parent block\n        block_header = self.rpc_request('chain_getHeader', [self.block_hash])\n\n        if block_header['result'] is None:\n            raise BlockNotFound(f'Block not found for \"{self.block_hash}\"')\n\n        parent_block_hash = block_header['result']['parentHash']\n\n        if parent_block_hash == '0x0000000000000000000000000000000000000000000000000000000000000000':\n            runtime_block_hash = self.block_hash\n        else:\n            runtime_block_hash = parent_block_hash\n\n        runtime_info = self.get_block_runtime_version(block_hash=runtime_block_hash)\n\n        if runtime_info is None:\n            raise SubstrateRequestException(f\"No runtime information for block '{block_hash}'\")\n\n        # Check if runtime state already set to current block\n        if runtime_info.get(\"specVersion\") == self.runtime_version:\n            return\n\n        self.runtime_version = runtime_info.get(\"specVersion\")\n        self.transaction_version = runtime_info.get(\"transactionVersion\")\n\n        if self.cache_region and self.runtime_version not in self.__metadata_cache:\n            # Try to retrieve metadata from Dogpile cache\n            cached_metadata = self.cache_region.get('METADATA_{}'.format(self.runtime_version))\n            if cached_metadata:\n                self.debug_message('Retrieved metadata for {} from Redis'.format(self.runtime_version))\n                self.__metadata_cache[self.runtime_version] = cached_metadata\n\n        if self.runtime_version in self.__metadata_cache:\n            # Get metadata from cache\n            self.debug_message('Retrieved metadata for {} from memory'.format(self.runtime_version))\n            self.metadata = self.__metadata_cache[self.runtime_version]\n        else:\n            self.metadata = self.get_block_metadata(block_hash=runtime_block_hash, decode=True)\n            self.debug_message('Retrieved metadata for {} from Substrate node'.format(self.runtime_version))\n\n            # Update metadata cache\n            self.__metadata_cache[self.runtime_version] = self.metadata\n\n            if self.cache_region:\n                self.debug_message('Stored metadata for {} in Redis'.format(self.runtime_version))\n                self.cache_region.set('METADATA_{}'.format(self.runtime_version), self.metadata)\n\n        # Update type registry\n        self.reload_type_registry(\n            use_remote_preset=self.config.get('use_remote_preset'),\n            auto_discover=self.config.get('auto_discover')\n        )\n\n        # Check if PortableRegistry is present in metadata (V14+), otherwise fall back on legacy type registry (<V14)\n        if self.implements_scaleinfo():\n            self.debug_message('Add PortableRegistry from metadata to type registry')\n            self.runtime_config.add_portable_registry(self.metadata)\n\n        # Set active runtime version\n        self.runtime_config.set_active_spec_version_id(self.runtime_version)\n\n        # Check and apply runtime constants\n        ss58_prefix_constant = self.get_constant(\"System\", \"SS58Prefix\", block_hash=block_hash)\n\n        if ss58_prefix_constant:\n            self.ss58_format = ss58_prefix_constant.value\n\n        # Set runtime compatibility flags\n        try:\n            _ = self.runtime_config.create_scale_object(\"sp_weights::weight_v2::Weight\")\n            self.config['is_weight_v2'] = True\n            self.runtime_config.update_type_registry_types({'Weight': 'sp_weights::weight_v2::Weight'})\n        except NotImplementedError:\n            self.config['is_weight_v2'] = False\n            self.runtime_config.update_type_registry_types({'Weight': 'WeightV1'})\n\n    def query_map(self, module: str, storage_function: str, params: Optional[list] = None, block_hash: str = None,\n                  max_results: int = None, start_key: str = None, page_size: int = 100,\n                  ignore_decoding_errors: bool = True) -> 'QueryMapResult':\n        \"\"\"\n        Iterates over all key-pairs located at the given module and storage_function. The storage\n        item must be a map.\n\n        Example:\n\n        ```\n        result = substrate.query_map('System', 'Account', max_results=100)\n\n        for account, account_info in result:\n            print(f\"Free balance of account '{account.value}': {account_info.value['data']['free']}\")\n        ```\n\n        Parameters\n        ----------\n        module: The module name in the metadata, e.g. System or Balances.\n        storage_function: The storage function name, e.g. Account or Locks.\n        params: The input parameters in case of for example a `DoubleMap` storage function\n        block_hash: Optional block hash for result at given block, when left to None the chain tip will be used.\n        max_results: the maximum of results required, if set the query will stop fetching results when number is reached\n        start_key: The storage key used as offset for the results, for pagination purposes\n        page_size: The results are fetched from the node RPC in chunks of this size\n        ignore_decoding_errors: When set this will catch all decoding errors, set the item to None and continue decoding\n\n        Returns\n        -------\n        QueryMapResult\n        \"\"\"\n\n        if block_hash is None:\n            # Retrieve chain tip\n            block_hash = self.get_chain_head()\n\n        if params is None:\n            params = []\n\n        self.init_runtime(block_hash=block_hash)\n\n        metadata_pallet = self.metadata.get_metadata_pallet(module)\n\n        if not metadata_pallet:\n            raise StorageFunctionNotFound(f'Pallet \"{module}\" not found')\n\n        storage_item = metadata_pallet.get_storage_function(storage_function)\n\n        if not metadata_pallet or not storage_item:\n            raise StorageFunctionNotFound(f'Storage function \"{module}.{storage_function}\" not found')\n\n        value_type = storage_item.get_value_type_string()\n        param_types = storage_item.get_params_type_string()\n        key_hashers = storage_item.get_param_hashers()\n\n        # Check MapType condititions\n        if len(param_types) == 0:\n            raise ValueError('Given storage function is not a map')\n\n        if len(params) > len(param_types) - 1:\n            raise ValueError(f'Storage function map can accept max {len(param_types) - 1} parameters, {len(params)} given')\n\n        # Generate storage key prefix\n        storage_key = StorageKey.create_from_storage_function(\n            module, storage_item.value['name'], params, runtime_config=self.runtime_config, metadata=self.metadata\n        )\n        prefix = storage_key.to_hex()\n\n        if not start_key:\n            start_key = prefix\n\n        # Make sure if the max result is smaller than the page size, adjust the page size\n        if max_results is not None and max_results < page_size:\n            page_size = max_results\n\n        # Retrieve storage keys\n        response = self.rpc_request(method=\"state_getKeysPaged\", params=[prefix, page_size, start_key, block_hash])\n\n        if 'error' in response:\n            raise SubstrateRequestException(response['error']['message'])\n\n        result_keys = response.get('result')\n\n        result = []\n        last_key = None\n\n        def concat_hash_len(key_hasher: str) -> int:\n            if key_hasher == \"Blake2_128Concat\":\n                return 16\n            elif key_hasher == \"Twox64Concat\":\n                return 8\n            elif key_hasher == \"Identity\":\n                return 0\n            else:\n                raise ValueError('Unsupported hash type')\n\n        if len(result_keys) > 0:\n\n            last_key = result_keys[-1]\n\n            # Retrieve corresponding value\n            response = self.rpc_request(method=\"state_queryStorageAt\", params=[result_keys, block_hash])\n\n            if 'error' in response:\n                raise SubstrateRequestException(response['error']['message'])\n\n            for result_group in response['result']:\n                for item in result_group['changes']:\n                    try:\n                        # Determine type string\n                        key_type_string = []\n                        for n in range(len(params), len(param_types)):\n                            key_type_string.append(f'[u8; {concat_hash_len(key_hashers[n])}]')\n                            key_type_string.append(param_types[n])\n\n                        item_key_obj = self.decode_scale(\n                            type_string=f\"({', '.join(key_type_string)})\",\n                            scale_bytes='0x' + item[0][len(prefix):],\n                            return_scale_obj=True,\n                            block_hash=block_hash\n                        )\n\n                        # strip key_hashers to use as item key\n                        if len(param_types) - len(params) == 1:\n                            item_key = item_key_obj.value_object[1]\n                        else:\n                            item_key = tuple(\n                                item_key_obj.value_object[key + 1] for key in range(len(params), len(param_types) + 1, 2)\n                            )\n\n                    except Exception:\n                        if not ignore_decoding_errors:\n                            raise\n                        item_key = None\n\n                    try:\n                        item_value = self.decode_scale(\n                            type_string=value_type,\n                            scale_bytes=item[1],\n                            return_scale_obj=True,\n                            block_hash=block_hash\n                        )\n                    except Exception:\n                        if not ignore_decoding_errors:\n                            raise\n                        item_value = None\n\n                    result.append([item_key, item_value])\n\n        return QueryMapResult(\n            records=result, page_size=page_size, module=module, storage_function=storage_function, params=params,\n            block_hash=block_hash, substrate=self, last_key=last_key, max_results=max_results,\n            ignore_decoding_errors=ignore_decoding_errors\n        )\n\n    def query_multi(self, storage_keys: List[StorageKey], block_hash: Optional[str] = None) -> list:\n        \"\"\"\n        Query multiple storage keys in one request.\n\n        Example:\n\n        ```\n        storage_keys = [\n            substrate.create_storage_key(\n                \"System\", \"Account\", [\"F4xQKRUagnSGjFqafyhajLs94e7Vvzvr8ebwYJceKpr8R7T\"]\n            ),\n            substrate.create_storage_key(\n                \"System\", \"Account\", [\"GSEX8kR4Kz5UZGhvRUCJG93D5hhTAoVZ5tAe6Zne7V42DSi\"]\n            )\n        ]\n\n        result = substrate.query_multi(storage_keys)\n        ```\n\n        Parameters\n        ----------\n        storage_keys: list of StorageKey objects\n        block_hash: Optional block_hash of state snapshot\n\n        Returns\n        -------\n        list of `(storage_key, scale_obj)` tuples\n        \"\"\"\n\n        self.init_runtime(block_hash=block_hash)\n\n        # Retrieve corresponding value\n        response = self.rpc_request(\"state_queryStorageAt\", [[s.to_hex() for s in storage_keys], block_hash])\n\n        if 'error' in response:\n            raise SubstrateRequestException(response['error']['message'])\n\n        result = []\n\n        storage_key_map = {s.to_hex(): s for s in storage_keys}\n\n        for result_group in response['result']:\n            for change_storage_key, change_data in result_group['changes']:\n                # Decode result for specified storage_key\n                storage_key = storage_key_map[change_storage_key]\n                if change_data is not None:\n                    change_data = ScaleBytes(change_data)\n\n                result.append((storage_key, storage_key.decode_scale_value(change_data)))\n\n        return result\n\n    def query(self, module: str, storage_function: str, params: list = None, block_hash: str = None,\n              subscription_handler: callable = None, raw_storage_key: bytes = None) -> ScaleType:\n        \"\"\"\n        Retrieves the storage entry for given module, function and optional parameters at given block hash.\n\n        When a subscription_handler callback function is passed, a subscription will be maintained as long as this\n        handler doesn't return a value.\n\n        Example of subscription handler:\n        ```\n        def subscription_handler(obj, update_nr, subscription_id):\n\n            if update_nr == 0:\n                print('Initial data:', obj.value)\n\n            if update_nr > 0:\n                # Do something with the update\n                print('data changed:', obj.value)\n\n            # The execution will block until an arbitrary value is returned, which will be the result of the `query`\n            if update_nr > 1:\n                return obj\n        ```\n\n        Parameters\n        ----------\n        module: The module name in the metadata, e.g. Balances or Account\n        storage_function: The storage function name, e.g. FreeBalance or AccountNonce\n        params: list of params, in the decoded format of the applicable ScaleTypes\n        block_hash: Optional block hash, when omitted the chain tip will be used\n        subscription_handler: Callback function that processes the updates of the storage query subscription\n        raw_storage_key: Optional raw storage key to query decode instead of generating one\n\n        Returns\n        -------\n        ScaleType\n        \"\"\"\n\n        if block_hash is not None:\n            # Check requirements\n            if callable(subscription_handler):\n                raise ValueError(\"Subscriptions can only be registered for current state; block_hash cannot be set\")\n        else:\n            # Retrieve chain tip\n            block_hash = self.get_chain_head()\n\n        if params is None:\n            params = []\n\n        self.init_runtime(block_hash=block_hash)\n\n        if module == 'Substrate':\n            # Search for 'well-known' storage keys\n            return self.__query_well_known(storage_function, block_hash)\n\n        # Search storage call in metadata\n        metadata_pallet = self.metadata.get_metadata_pallet(module)\n\n        if not metadata_pallet:\n            raise StorageFunctionNotFound(f'Pallet \"{module}\" not found')\n\n        storage_item = metadata_pallet.get_storage_function(storage_function)\n\n        if not metadata_pallet or not storage_item:\n            raise StorageFunctionNotFound(f'Storage function \"{module}.{storage_function}\" not found')\n\n        # SCALE type string of value\n        param_types = storage_item.get_params_type_string()\n        value_scale_type = storage_item.get_value_type_string()\n\n        if len(params) != len(param_types):\n            raise ValueError(f'Storage function requires {len(param_types)} parameters, {len(params)} given')\n\n        if raw_storage_key:\n            storage_key = StorageKey.create_from_data(\n                data=raw_storage_key, pallet=module, storage_function=storage_function,\n                value_scale_type=value_scale_type, metadata=self.metadata, runtime_config=self.runtime_config\n            )\n        else:\n\n            storage_key = StorageKey.create_from_storage_function(\n                module, storage_item.value['name'], params, runtime_config=self.runtime_config, metadata=self.metadata\n            )\n\n        if callable(subscription_handler):\n\n            # Wrap subscription handler to discard storage key arg\n            def result_handler(storage_key, updated_obj, update_nr, subscription_id):\n                return subscription_handler(updated_obj, update_nr, subscription_id)\n\n            return self.subscribe_storage([storage_key], result_handler)\n\n        else:\n\n            if self.supports_rpc_method('state_getStorageAt'):\n                response = self.rpc_request(\"state_getStorageAt\", [storage_key.to_hex(), block_hash])\n            else:\n                response = self.rpc_request(\"state_getStorage\", [storage_key.to_hex(), block_hash])\n\n            if 'error' in response:\n                raise SubstrateRequestException(response['error']['message'])\n\n            if 'result' in response:\n                if value_scale_type:\n\n                    if response.get('result') is not None:\n                        query_value = response.get('result')\n                    elif storage_item.value['modifier'] == 'Default':\n                        # Fallback to default value of storage function if no result\n                        query_value = storage_item.value_object['default'].value_object\n                    else:\n                        # No result is interpreted as an Option<...> result\n                        value_scale_type = f'Option<{value_scale_type}>'\n                        query_value = storage_item.value_object['default'].value_object\n\n                    obj = self.runtime_config.create_scale_object(\n                        type_string=value_scale_type,\n                        data=ScaleBytes(query_value),\n                        metadata=self.metadata\n                    )\n                    obj.decode(check_remaining=self.config.get('strict_scale_decode'))\n                    obj.meta_info = {'result_found': response.get('result') is not None}\n\n                    return obj\n\n    def __query_well_known(self, name: str, block_hash: str) -> ScaleType:\n        \"\"\"\n        Query well-known storage keys as defined in Substrate\n\n        Parameters\n        ----------\n        name\n        block_hash\n\n        Returns\n        -------\n        Optional[ScaleType]\n        \"\"\"\n        if name not in WELL_KNOWN_STORAGE_KEYS:\n            raise StorageFunctionNotFound(f'Well known storage key for \"{name}\" not found')\n\n        result = self.get_storage_by_key(block_hash, WELL_KNOWN_STORAGE_KEYS[name]['storage_key'])\n        obj = self.runtime_config.create_scale_object(\n            WELL_KNOWN_STORAGE_KEYS[name]['value_type_string']\n        )\n        if result:\n            obj.decode(ScaleBytes(result), check_remaining=self.config.get('strict_scale_decode'))\n            obj.meta_info = {'result_found': True}\n            return obj\n        elif WELL_KNOWN_STORAGE_KEYS[name]['default']:\n            obj.decode(\n                ScaleBytes(WELL_KNOWN_STORAGE_KEYS[name]['default']),\n                check_remaining=self.config.get('strict_scale_decode')\n            )\n            obj.meta_info = {'result_found': False}\n            return obj\n        else:\n            raise ValueError(\"No value to decode\")\n\n    def create_storage_key(self, pallet: str, storage_function: str, params: Optional[list] = None) -> StorageKey:\n        \"\"\"\n        Create a `StorageKey` instance providing storage function details. See `subscribe_storage()`.\n\n        Parameters\n        ----------\n        pallet: name of pallet\n        storage_function: name of storage function\n        params: Optional list of parameters in case of a Mapped storage function\n\n        Returns\n        -------\n        StorageKey\n        \"\"\"\n\n        self.init_runtime()\n\n        return StorageKey.create_from_storage_function(\n            pallet, storage_function, params, runtime_config=self.runtime_config, metadata=self.metadata\n        )\n\n    def subscribe_storage(self, storage_keys: List[StorageKey], subscription_handler: callable):\n        \"\"\"\n\n        Subscribe to provided storage_keys and keep tracking until `subscription_handler` returns a value\n\n        Example of a StorageKey:\n        ```\n        StorageKey.create_from_storage_function(\n            \"System\", \"Account\", [\"5GrwvaEF5zXb26Fz9rcQpDWS57CtERHpNehXCPcNoHGKutQY\"]\n        )\n        ```\n\n        Example of a subscription handler:\n        ```\n        def subscription_handler(storage_key, obj, update_nr, subscription_id):\n\n            if update_nr == 0:\n                print('Initial data:', storage_key, obj.value)\n\n            if update_nr > 0:\n                # Do something with the update\n                print('data changed:', storage_key, obj.value)\n\n            # The execution will block until an arbitrary value is returned, which will be the result of the function\n            if update_nr > 1:\n                return obj\n        ```\n\n        Parameters\n        ----------\n        storage_keys: StorageKey list of storage keys to subscribe to\n        subscription_handler: callable to handle value changes of subscription\n\n        Returns\n        -------\n\n        \"\"\"\n        self.init_runtime()\n\n        storage_key_map = {s.to_hex(): s for s in storage_keys}\n\n        def result_handler(message, update_nr, subscription_id):\n            # Process changes\n            for change_storage_key, change_data in message['params']['result']['changes']:\n                # Check for target storage key\n                storage_key = storage_key_map[change_storage_key]\n                result_found = False\n\n                if change_data is not None:\n                    change_scale_type = storage_key.value_scale_type\n                    result_found = True\n                elif storage_key.metadata_storage_function.value['modifier'] == 'Default':\n                    # Fallback to default value of storage function if no result\n                    change_scale_type = storage_key.value_scale_type\n                    change_data = storage_key.metadata_storage_function.value_object['default'].value_object\n                else:\n                    # No result is interpreted as an Option<...> result\n                    change_scale_type = f'Option<{storage_key.value_scale_type}>'\n                    change_data = storage_key.metadata_storage_function.value_object['default'].value_object\n\n                # Decode SCALE result data\n                updated_obj = self.runtime_config.create_scale_object(\n                    type_string=change_scale_type,\n                    data=ScaleBytes(change_data),\n                    metadata=self.metadata\n                )\n                updated_obj.decode(check_remaining=self.config.get('strict_scale_decode'))\n                updated_obj.meta_info = {'result_found': result_found}\n\n                subscription_result = subscription_handler(storage_key, updated_obj, update_nr, subscription_id)\n\n                if subscription_result is not None:\n                    # Handler returned end result: unsubscribe from further updates\n                    self.rpc_request(\"state_unsubscribeStorage\", [subscription_id])\n\n                    return subscription_result\n\n        if not callable(subscription_handler):\n            raise ValueError('Provided \"subscription_handler\" is not callable')\n\n        return self.rpc_request(\n            \"state_subscribeStorage\", [[s.to_hex() for s in storage_keys]], result_handler=result_handler\n        )\n\n    def retrieve_pending_extrinsics(self) -> list:\n        \"\"\"\n        Retrieves and decodes pending extrinsics from the node's transaction pool\n\n        Returns\n        -------\n        list of extrinsics\n        \"\"\"\n\n        self.init_runtime()\n\n        result_data = self.rpc_request(\"author_pendingExtrinsics\", [])\n\n        extrinsics = []\n\n        for extrinsic_data in result_data['result']:\n            extrinsic = self.runtime_config.create_scale_object('Extrinsic', metadata=self.metadata)\n            extrinsic.decode(ScaleBytes(extrinsic_data), check_remaining=self.config.get('strict_scale_decode'))\n            extrinsics.append(extrinsic)\n\n        return extrinsics\n\n    def runtime_call(self, api: str, method: str, params: Union[list, dict] = None, block_hash: str = None) -> ScaleType:\n        \"\"\"\n        Calls a runtime API method\n\n        Parameters\n        ----------\n        api: Name of the runtime API e.g. 'TransactionPaymentApi'\n        method: Name of the method e.g. 'query_fee_details'\n        params: List of parameters needed to call the runtime API\n        block_hash: Hash of the block at which to make the runtime API call\n\n        Returns\n        -------\n        ScaleType\n        \"\"\"\n        self.init_runtime()\n\n        self.debug_message(f\"Executing Runtime Call {api}.{method}\")\n\n        if params is None:\n            params = {}\n\n        try:\n            runtime_call_def = self.runtime_config.type_registry[\"runtime_api\"][api]['methods'][method]\n            runtime_api_types = self.runtime_config.type_registry[\"runtime_api\"][api].get(\"types\", {})\n        except KeyError:\n            raise ValueError(f\"Runtime API Call '{api}.{method}' not found in registry\")\n\n        if type(params) is list and len(params) != len(runtime_call_def['params']):\n            raise ValueError(\n                f\"Number of parameter provided ({len(params)}) does not \"\n                f\"match definition {len(runtime_call_def['params'])}\"\n            )\n\n        # Add runtime API types to registry\n        self.runtime_config.update_type_registry_types(runtime_api_types)\n\n        # Encode params\n        param_data = ScaleBytes(bytes())\n        for idx, param in enumerate(runtime_call_def['params']):\n            scale_obj = self.runtime_config.create_scale_object(param['type'])\n            if type(params) is list:\n                param_data += scale_obj.encode(params[idx])\n            else:\n                if param['name'] not in params:\n                    raise ValueError(f\"Runtime Call param '{param['name']}' is missing\")\n\n                param_data += scale_obj.encode(params[param['name']])\n\n        # RPC request\n        result_data = self.rpc_request(\"state_call\", [f'{api}_{method}', str(param_data), block_hash])\n\n        # Decode result\n        result_obj = self.runtime_config.create_scale_object(runtime_call_def['type'])\n        result_obj.decode(ScaleBytes(result_data['result']), check_remaining=self.config.get('strict_scale_decode'))\n\n        return result_obj\n\n    def get_events(self, block_hash: str = None) -> list:\n        \"\"\"\n        Convenience method to get events for a certain block (storage call for module 'System' and function 'Events')\n\n        Parameters\n        ----------\n        block_hash\n\n        Returns\n        -------\n        list\n        \"\"\"\n        events = []\n\n        if not block_hash:\n            block_hash = self.get_chain_head()\n\n        storage_obj = self.query(module=\"System\", storage_function=\"Events\", block_hash=block_hash)\n        if storage_obj:\n            events += storage_obj.elements\n        return events\n\n    def get_metadata(self, block_hash=None):\n        \"\"\"\n        Returns `MetadataVersioned` object for given block_hash or chaintip if block_hash is omitted\n\n\n        Parameters\n        ----------\n        block_hash\n\n        Returns\n        -------\n        MetadataVersioned\n        \"\"\"\n        self.init_runtime(block_hash=block_hash)\n\n        return self.metadata\n\n    def get_runtime_metadata(self, block_hash=None):\n        \"\"\"\n        Retrieves and decodes the metadata for given block or chaintip if block_hash is omitted.\n\n        Parameters\n        ----------\n        block_hash\n\n        Returns\n        -------\n\n        \"\"\"\n        warnings.warn(\"get_runtime_metadata() will be removed in future releases\", DeprecationWarning)\n\n        params = None\n        if block_hash:\n            params = [block_hash]\n        response = self.rpc_request(\"state_getMetadata\", params)\n\n        if 'error' in response:\n            raise SubstrateRequestException(response['error']['message'])\n\n        if 'result' in response:\n            metadata_decoder = self.runtime_config.create_scale_object(\n                'MetadataVersioned', data=ScaleBytes(response.get('result')))\n            response['result'] = metadata_decoder.decode()\n\n        return response\n\n    def create_scale_object(\n            self, type_string: str, data: ScaleBytes = None, block_hash: str = None, **kwargs\n    ) -> 'ScaleType':\n        \"\"\"\n        Convenience method to create a SCALE object of type `type_string`, this will initialize the runtime\n        automatically at moment of `block_hash`, or chain tip if omitted.\n\n        Parameters\n        ----------\n        type_string: str Name of SCALE type to create\n        data: ScaleBytes Optional ScaleBytes to decode\n        block_hash: Optional block hash for moment of decoding, when omitted the chain tip will be used\n        kwargs\n\n        Returns\n        -------\n        ScaleType\n        \"\"\"\n        self.init_runtime(block_hash=block_hash)\n\n        if 'metadata' not in kwargs:\n            kwargs['metadata'] = self.metadata\n\n        return self.runtime_config.create_scale_object(type_string, data=data, **kwargs)\n\n    def compose_call(\n            self, call_module: str, call_function: str, call_params: dict = None, block_hash: str = None\n    ) -> GenericCall:\n        \"\"\"\n        Composes a call payload which can be used in an extrinsic.\n\n        Parameters\n        ----------\n        call_module: Name of the runtime module e.g. Balances\n        call_function: Name of the call function e.g. transfer\n        call_params: This is a dict containing the params of the call. e.g. `{'dest': 'EaG2CRhJWPb7qmdcJvy3LiWdh26Jreu9Dx6R1rXxPmYXoDk', 'value': 1000000000000}`\n        block_hash: Use metadata at given block_hash to compose call\n\n        Returns\n        -------\n        GenericCall\n        \"\"\"\n\n        if call_params is None:\n            call_params = {}\n\n        self.init_runtime(block_hash=block_hash)\n\n        call = self.runtime_config.create_scale_object(\n            type_string='Call', metadata=self.metadata\n        )\n\n        call.encode({\n            'call_module': call_module,\n            'call_function': call_function,\n            'call_args': call_params\n        })\n\n        return call\n\n    def get_account_nonce(self, account_address) -> int:\n        \"\"\"\n        Returns current nonce for given account address\n\n        Parameters\n        ----------\n        account_address: SS58 formatted address\n\n        Returns\n        -------\n        int\n        \"\"\"\n        if self.supports_rpc_method('state_call'):\n            nonce_obj = self.runtime_call(\"AccountNonceApi\", \"account_nonce\", [account_address])\n            return nonce_obj.value\n        else:\n            response = self.rpc_request(\"system_accountNextIndex\", [account_address])\n        return response.get('result', 0)\n\n    def generate_signature_payload(self, call: GenericCall, era=None, nonce: int = 0, tip: int = 0,\n                                   tip_asset_id: int = None, include_call_length: bool = False) -> ScaleBytes:\n\n        # Retrieve genesis hash\n        genesis_hash = self.get_block_hash(0)\n\n        if not era:\n            era = '00'\n\n        if era == '00':\n            # Immortal extrinsic\n            block_hash = genesis_hash\n        else:\n            # Determine mortality of extrinsic\n            era_obj = self.runtime_config.create_scale_object('Era')\n\n            if isinstance(era, dict) and 'current' not in era and 'phase' not in era:\n                raise ValueError('The era dict must contain either \"current\" or \"phase\" element to encode a valid era')\n\n            era_obj.encode(era)\n            block_hash = self.get_block_hash(block_id=era_obj.birth(era.get('current')))\n\n        # Create signature payload\n        signature_payload = self.runtime_config.create_scale_object('ExtrinsicPayloadValue')\n\n        # Process signed extensions in metadata\n        if 'signed_extensions' in self.metadata[1][1]['extrinsic']:\n\n            # Base signature payload\n            signature_payload.type_mapping = [['call', 'CallBytes']]\n\n            # Add signed extensions to payload\n            signed_extensions = self.metadata.get_signed_extensions()\n\n            if 'CheckMortality' in signed_extensions:\n                signature_payload.type_mapping.append(\n                    ['era', signed_extensions['CheckMortality']['extrinsic']]\n                )\n\n            if 'CheckEra' in signed_extensions:\n                signature_payload.type_mapping.append(\n                    ['era', signed_extensions['CheckEra']['extrinsic']]\n                )\n\n            if 'CheckNonce' in signed_extensions:\n                signature_payload.type_mapping.append(\n                    ['nonce', signed_extensions['CheckNonce']['extrinsic']]\n                )\n\n            if 'ChargeTransactionPayment' in signed_extensions:\n                signature_payload.type_mapping.append(\n                    ['tip', signed_extensions['ChargeTransactionPayment']['extrinsic']]\n                )\n\n            if 'ChargeAssetTxPayment' in signed_extensions:\n                signature_payload.type_mapping.append(\n                    ['asset_id', signed_extensions['ChargeAssetTxPayment']['extrinsic']]\n                )\n\n            if 'CheckMetadataHash' in signed_extensions:\n                signature_payload.type_mapping.append(\n                    ['mode', signed_extensions['CheckMetadataHash']['extrinsic']]\n                )\n\n            if 'CheckSpecVersion' in signed_extensions:\n                signature_payload.type_mapping.append(\n                    ['spec_version', signed_extensions['CheckSpecVersion']['additional_signed']]\n                )\n\n            if 'CheckTxVersion' in signed_extensions:\n                signature_payload.type_mapping.append(\n                    ['transaction_version', signed_extensions['CheckTxVersion']['additional_signed']]\n                )\n\n            if 'CheckGenesis' in signed_extensions:\n                signature_payload.type_mapping.append(\n                    ['genesis_hash', signed_extensions['CheckGenesis']['additional_signed']]\n                )\n\n            if 'CheckMortality' in signed_extensions:\n                signature_payload.type_mapping.append(\n                    ['block_hash', signed_extensions['CheckMortality']['additional_signed']]\n                )\n\n            if 'CheckEra' in signed_extensions:\n                signature_payload.type_mapping.append(\n                    ['block_hash', signed_extensions['CheckEra']['additional_signed']]\n                )\n\n            if 'CheckMetadataHash' in signed_extensions:\n                signature_payload.type_mapping.append(\n                    ['metadata_hash', signed_extensions['CheckMetadataHash']['additional_signed']]\n                )\n\n        if include_call_length:\n\n            length_obj = self.runtime_config.create_scale_object('Bytes')\n            call_data = str(length_obj.encode(str(call.data)))\n\n        else:\n            call_data = str(call.data)\n\n        payload_dict = {\n            'call': call_data,\n            'era': era,\n            'nonce': nonce,\n            'tip': tip,\n            'spec_version': self.runtime_version,\n            'genesis_hash': genesis_hash,\n            'block_hash': block_hash,\n            'transaction_version': self.transaction_version,\n            'asset_id': {'tip': tip, 'asset_id': tip_asset_id},\n            'metadata_hash': None,\n            'mode': 'Disabled'\n        }\n\n        signature_payload.encode(payload_dict)\n\n        if signature_payload.data.length > 256:\n            return ScaleBytes(data=blake2b(signature_payload.data.data, digest_size=32).digest())\n\n        return signature_payload.data\n\n    def create_signed_extrinsic(\n            self, call: GenericCall, keypair: Keypair, era: dict = None, nonce: int = None,\n            tip: int = 0, tip_asset_id: int = None, signature: Union[bytes, str] = None\n    ) -> GenericExtrinsic:\n        \"\"\"\n        Creates an extrinsic signed by given account details\n\n        Parameters\n        ----------\n        call: GenericCall to create extrinsic for\n        keypair: Keypair used to sign the extrinsic\n        era: Specify mortality in blocks in follow format: {'period': [amount_blocks]} If omitted the extrinsic is immortal\n        nonce: nonce to include in extrinsics, if omitted the current nonce is retrieved on-chain\n        tip: The tip for the block author to gain priority during network congestion\n        tip_asset_id: Optional asset ID with which to pay the tip\n        signature: Optionally provide signature if externally signed\n\n        Returns\n        -------\n        GenericExtrinsic The signed Extrinsic\n        \"\"\"\n\n        og_keypair_crypto_type = keypair.crypto_type\n\n        if isinstance(keypair.crypto_type, str):\n            keypair.crypto_type = keypair.crypto_type_id\n\n        self.init_runtime()\n\n        # Check requirements\n        if not isinstance(call, GenericCall):\n            raise TypeError(\"'call' must be of type Call\")\n\n        # Check if extrinsic version is supported\n        if self.metadata[1][1]['extrinsic']['version'] != 4:\n            raise NotImplementedError(\n                f\"Extrinsic version {self.metadata[1][1]['extrinsic']['version']} not supported\"\n            )\n\n        # Retrieve nonce\n        if nonce is None:\n            nonce = self.get_account_nonce(keypair.ss58_address) or 0\n\n        # Process era\n        if era is None:\n            era = '00'\n        else:\n            if isinstance(era, dict) and 'current' not in era and 'phase' not in era:\n                # Retrieve current block id\n                era['current'] = self.get_block_number(self.get_chain_finalised_head())\n\n        if signature is not None:\n\n            if type(signature) is str and signature[0:2] == '0x':\n                signature = bytes.fromhex(signature[2:])\n\n            # Check if signature is a MultiSignature and contains signature version\n            if len(signature) == 65:\n                signature_version = signature[0]\n                signature = signature[1:]\n            else:\n                signature_version = keypair.crypto_type\n\n        else:\n            # Create signature payload\n            signature_payload = self.generate_signature_payload(\n                call=call, era=era, nonce=nonce, tip=tip, tip_asset_id=tip_asset_id\n            )\n\n            # Set Signature version to crypto type of keypair\n            signature_version = keypair.crypto_type\n\n            # Sign payload\n            signature = keypair.sign(signature_payload)\n\n        # Create extrinsic\n        extrinsic = self.runtime_config.create_scale_object(type_string='Extrinsic', metadata=self.metadata)\n\n        value = {\n            'account_id': f'0x{keypair.public_key.hex()}',\n            'signature': f'0x{signature.hex()}',\n            'call_function': call.value['call_function'],\n            'call_module': call.value['call_module'],\n            'call_args': call.value['call_args'],\n            'nonce': nonce,\n            'era': era,\n            'tip': tip,\n            'asset_id': {'tip': tip, 'asset_id': tip_asset_id},\n            'mode': 'Disabled'\n        }\n\n        # Check if ExtrinsicSignature is MultiSignature, otherwise omit signature_version\n        signature_cls = self.runtime_config.get_decoder_class(\"ExtrinsicSignature\")\n        if issubclass(signature_cls, self.runtime_config.get_decoder_class('Enum')):\n            value['signature_version'] = signature_version\n\n        extrinsic.encode(value)\n        keypair.crypto_type = og_keypair_crypto_type\n        return extrinsic\n\n    def create_unsigned_extrinsic(self, call: GenericCall) -> GenericExtrinsic:\n        \"\"\"\n        Create unsigned extrinsic for given `Call`\n        Parameters\n        ----------\n        call: GenericCall the call the extrinsic should contain\n\n        Returns\n        -------\n        GenericExtrinsic\n        \"\"\"\n\n        self.init_runtime()\n\n        # Create extrinsic\n        extrinsic = self.runtime_config.create_scale_object(type_string='Extrinsic', metadata=self.metadata)\n\n        extrinsic.encode({\n            'call_function': call.value['call_function'],\n            'call_module': call.value['call_module'],\n            'call_args': call.value['call_args']\n        })\n\n        return extrinsic\n\n    def generate_multisig_account(self, signatories: list, threshold: int) -> MultiAccountId:\n        \"\"\"\n        Generate deterministic Multisig account with supplied signatories and threshold\n        Parameters\n        ----------\n        signatories: List of signatories\n        threshold: Amount of approvals needed to execute\n\n        Returns\n        -------\n        MultiAccountId\n        \"\"\"\n\n        multi_sig_account = MultiAccountId.create_from_account_list(signatories, threshold)\n\n        multi_sig_account.ss58_address = ss58_encode(multi_sig_account.value.replace('0x', ''), self.ss58_format)\n\n        return multi_sig_account\n\n    def create_multisig_extrinsic(self, call: GenericCall, keypair: Keypair, multisig_account: MultiAccountId,\n                                  max_weight: Optional[Union[dict, int]] = None, era: dict = None, nonce: int = None,\n                                  tip: int = 0, tip_asset_id: int = None, signature: Union[bytes, str] = None\n                                  ) -> GenericExtrinsic:\n        \"\"\"\n        Create a Multisig extrinsic that will be signed by one of the signatories. Checks on-chain if the threshold\n        of the multisig account is reached and try to execute the call accordingly.\n\n        Parameters\n        ----------\n        call: GenericCall to create extrinsic for\n        keypair: Keypair of the signatory to approve given call\n        multisig_account: MultiAccountId to use of origin of the extrinsic (see `generate_multisig_account()`)\n        max_weight: Maximum allowed weight to execute the call ( Uses `get_payment_info()` by default)\n        era: Specify mortality in blocks in follow format: {'period': [amount_blocks]} If omitted the extrinsic is immortal\n        nonce: nonce to include in extrinsics, if omitted the current nonce is retrieved on-chain\n        tip: The tip for the block author to gain priority during network congestion\n        tip_asset_id: Optional asset ID with which to pay the tip\n        signature: Optionally provide signature if externally signed\n\n        Returns\n        -------\n        GenericExtrinsic\n        \"\"\"\n        if max_weight is None:\n            payment_info = self.get_payment_info(call, keypair)\n            max_weight = payment_info[\"weight\"]\n\n        # Check if call has existing approvals\n        multisig_details = self.query(\"Multisig\", \"Multisigs\", [multisig_account.value, call.call_hash])\n\n        if multisig_details.value:\n            maybe_timepoint = multisig_details.value['when']\n        else:\n            maybe_timepoint = None\n\n        # Compose 'as_multi' when final, 'approve_as_multi' otherwise\n        if multisig_details.value and len(multisig_details.value['approvals']) + 1 == multisig_account.threshold:\n            multi_sig_call = self.compose_call(\"Multisig\", \"as_multi\", {\n                'other_signatories': [s for s in multisig_account.signatories if s != f'0x{keypair.public_key.hex()}'],\n                'threshold': multisig_account.threshold,\n                'maybe_timepoint': maybe_timepoint,\n                'call': call,\n                'store_call': False,\n                'max_weight': max_weight\n            })\n        else:\n            multi_sig_call = self.compose_call(\"Multisig\", \"approve_as_multi\", {\n                'other_signatories': [s for s in multisig_account.signatories if s != f'0x{keypair.public_key.hex()}'],\n                'threshold': multisig_account.threshold,\n                'maybe_timepoint': maybe_timepoint,\n                'call_hash': call.call_hash,\n                'max_weight': max_weight\n            })\n\n        return self.create_signed_extrinsic(\n            multi_sig_call, keypair, era=era, nonce=nonce, tip=tip, tip_asset_id=tip_asset_id, signature=signature\n        )\n\n    def submit_extrinsic(self, extrinsic: GenericExtrinsic, wait_for_inclusion: bool = False,\n                         wait_for_finalization: bool = False) -> \"ExtrinsicReceipt\":\n        \"\"\"\n        Submit an extrinsic to the connected node, with the possibility to wait until the extrinsic is included\n         in a block and/or the block is finalized. The receipt returned provided information about the block and\n         triggered events\n\n        Parameters\n        ----------\n        extrinsic: Extrinsic The extrinsic to be sent to the network\n        wait_for_inclusion: wait until extrinsic is included in a block (only works for websocket connections)\n        wait_for_finalization: wait until extrinsic is finalized (only works for websocket connections)\n\n        Returns\n        -------\n        ExtrinsicReceipt\n\n        \"\"\"\n\n        # Check requirements\n        if not isinstance(extrinsic, GenericExtrinsic):\n            raise TypeError(\"'extrinsic' must be of type Extrinsics\")\n\n        def result_handler(message, update_nr, subscription_id):\n            # Check if extrinsic is included and finalized\n            if 'params' in message and type(message['params']['result']) is dict:\n\n                # Convert result enum to lower for backwards compatibility\n                message_result = {k.lower(): v for k, v in message['params']['result'].items()}\n\n                if 'finalized' in message_result and wait_for_finalization:\n                    self.rpc_request('author_unwatchExtrinsic', [subscription_id])\n                    return {\n                        'block_hash': message_result['finalized'],\n                        'extrinsic_hash': '0x{}'.format(extrinsic.extrinsic_hash.hex()),\n                        'finalized': True\n                    }\n                elif 'inblock' in message_result and wait_for_inclusion and not wait_for_finalization:\n                    self.rpc_request('author_unwatchExtrinsic', [subscription_id])\n                    return {\n                        'block_hash': message_result['inblock'],\n                        'extrinsic_hash': '0x{}'.format(extrinsic.extrinsic_hash.hex()),\n                        'finalized': False\n                    }\n\n        if wait_for_inclusion or wait_for_finalization:\n            response = self.rpc_request(\n                \"author_submitAndWatchExtrinsic\",\n                [str(extrinsic.data)],\n                result_handler=result_handler\n            )\n\n            result = ExtrinsicReceipt(\n                substrate=self,\n                extrinsic_hash=response['extrinsic_hash'],\n                block_hash=response['block_hash'],\n                finalized=response['finalized']\n            )\n\n        else:\n\n            response = self.rpc_request(\"author_submitExtrinsic\", [str(extrinsic.data)])\n\n            if 'result' not in response:\n                raise SubstrateRequestException(response.get('error'))\n\n            result = ExtrinsicReceipt(\n                substrate=self,\n                extrinsic_hash=response['result']\n            )\n\n        return result\n\n    def get_payment_info(self, call: GenericCall, keypair: Keypair):\n        \"\"\"\n        Retrieves fee estimation via RPC for given extrinsic\n\n        Parameters\n        ----------\n        call: Call object to estimate fees for\n        keypair: Keypair of the sender, does not have to include private key because no valid signature is required\n\n        Returns\n        -------\n        Dict with payment info\n\n        E.g. `{'class': 'normal', 'partialFee': 151000000, 'weight': {'ref_time': 143322000}}`\n\n        \"\"\"\n\n        # Check requirements\n        if not isinstance(call, GenericCall):\n            raise TypeError(\"'call' must be of type Call\")\n\n        # if not isinstance(keypair, Keypair):\n        #     raise TypeError(\"'keypair' must be of type Keypair\")\n\n        # No valid signature is required for fee estimation\n        signature = '0x' + '00' * 64\n\n        # Create extrinsic\n        extrinsic = self.create_signed_extrinsic(\n            call=call,\n            keypair=keypair,\n            signature=signature\n        )\n\n        if self.supports_rpc_method('state_call'):\n            extrinsic_len = self.runtime_config.create_scale_object('u32')\n            extrinsic_len.encode(len(extrinsic.data))\n\n            result = self.runtime_call(\"TransactionPaymentApi\", \"query_info\", [extrinsic, extrinsic_len])\n\n            return result.value\n        else:\n            # Backwards compatibility; deprecated RPC method\n            payment_info = self.rpc_request('payment_queryInfo', [str(extrinsic.data)])\n\n            # convert partialFee to int\n            if 'result' in payment_info:\n                payment_info['result']['partialFee'] = int(payment_info['result']['partialFee'])\n\n                if type(payment_info['result']['weight']) is int:\n                    # Transform format to WeightV2 if applicable as per https://github.com/paritytech/substrate/pull/12633\n                    try:\n                        weight_obj = self.runtime_config.create_scale_object(\"sp_weights::weight_v2::Weight\")\n                        if weight_obj is not None:\n                            payment_info['result']['weight'] = {\n                                'ref_time': payment_info['result']['weight'],\n                                'proof_size': 0\n                            }\n                    except NotImplementedError:\n                        pass\n\n                return payment_info['result']\n            else:\n                raise SubstrateRequestException(payment_info['error']['message'])\n\n    def get_type_registry(self, block_hash: str = None, max_recursion: int = 4) -> dict:\n        \"\"\"\n        Generates an exhaustive list of which RUST types exist in the runtime specified at given block_hash (or\n        chaintip if block_hash is omitted)\n\n        MetadataV14 or higher is required.\n\n        Parameters\n        ----------\n        block_hash: Chaintip will be used if block_hash is omitted\n        max_recursion: Increasing recursion will provide more detail but also has impact on performance\n\n        Returns\n        -------\n        dict\n        \"\"\"\n        self.init_runtime(block_hash=block_hash)\n\n        if not self.implements_scaleinfo():\n            raise NotImplementedError(\"MetadataV14 or higher runtimes is required\")\n\n        type_registry = {}\n\n        for scale_info_type in self.metadata.portable_registry['types']:\n\n            if 'path' in scale_info_type.value['type'] and len(scale_info_type.value['type']['path']) > 0:\n                type_string = '::'.join(scale_info_type.value[\"type\"][\"path\"])\n            else:\n                type_string = f'scale_info::{scale_info_type.value[\"id\"]}'\n\n            scale_cls = self.runtime_config.get_decoder_class(type_string)\n            type_registry[type_string] = scale_cls.generate_type_decomposition(\n                max_recursion=max_recursion\n            )\n\n        return type_registry\n\n    def get_type_definition(self, type_string: str, block_hash: str = None):\n        \"\"\"\n        Retrieves SCALE encoding specifications of given type_string\n\n        Parameters\n        ----------\n        type_string: RUST variable type, e.g. Vec<Address> or scale_info::0\n        block_hash\n\n        Returns\n        -------\n\n        \"\"\"\n        scale_obj = self.create_scale_object(type_string, block_hash=block_hash)\n        return scale_obj.generate_type_decomposition()\n\n    def get_metadata_modules(self, block_hash=None):\n        \"\"\"\n        Retrieves a list of modules in metadata for given block_hash (or chaintip if block_hash is omitted)\n\n        Parameters\n        ----------\n        block_hash\n\n        Returns\n        -------\n\n        \"\"\"\n        self.init_runtime(block_hash=block_hash)\n\n        return [{\n            'metadata_index': idx,\n            'module_id': module.get_identifier(),\n            'name': module.name,\n            'spec_version': self.runtime_version,\n            'count_call_functions': len(module.calls or []),\n            'count_storage_functions': len(module.storage or []),\n            'count_events': len(module.events or []),\n            'count_constants': len(module.constants or []),\n            'count_errors': len(module.errors or []),\n        } for idx, module in enumerate(self.metadata.pallets)]\n\n    def get_metadata_module(self, name, block_hash=None):\n        \"\"\"\n        Retrieves modules in metadata by name for given block_hash (or chaintip if block_hash is omitted)\n\n        Parameters\n        ----------\n        name\n        block_hash\n\n        Returns\n        -------\n        MetadataModule\n        \"\"\"\n        self.init_runtime(block_hash=block_hash)\n\n        return self.metadata.get_metadata_pallet(name)\n\n    def get_metadata_call_functions(self, block_hash=None) -> list:\n        \"\"\"\n        Retrieves a list of all call functions in metadata active for given block_hash (or chaintip if block_hash is omitted)\n\n        Parameters\n        ----------\n        block_hash\n\n        Returns\n        -------\n        list\n        \"\"\"\n        self.init_runtime(block_hash=block_hash)\n\n        call_list = []\n\n        for pallet in self.metadata.pallets:\n            if pallet.calls:\n                for call in pallet.calls:\n\n                    call_list.append(\n                        self.serialize_module_call(\n                            pallet, call, self.runtime_version, ''\n                        )\n                    )\n\n        return call_list\n\n    def get_metadata_call_function(self, module_name: str, call_function_name: str, block_hash: str = None):\n        \"\"\"\n        Retrieves the details of a call function given module name, call function name and block_hash\n        (or chaintip if block_hash is omitted)\n\n        Parameters\n        ----------\n        module_name\n        call_function_name\n        block_hash\n\n        Returns\n        -------\n\n        \"\"\"\n        self.init_runtime(block_hash=block_hash)\n\n        for pallet in self.metadata.pallets:\n            if pallet.name == module_name and pallet.calls:\n                for call in pallet.calls:\n                    if call.name == call_function_name:\n                        return call\n\n    def get_metadata_events(self, block_hash=None) -> list:\n        \"\"\"\n        Retrieves a list of all events in metadata active for given block_hash (or chaintip if block_hash is omitted)\n\n        Parameters\n        ----------\n        block_hash\n\n        Returns\n        -------\n        list\n        \"\"\"\n\n        self.init_runtime(block_hash=block_hash)\n\n        event_list = []\n\n        for event_index, (module, event) in self.metadata.event_index.items():\n            event_list.append(\n                self.serialize_module_event(\n                    module, event, self.runtime_version, event_index\n                )\n            )\n\n        return event_list\n\n    def get_metadata_event(self, module_name, event_name, block_hash=None):\n        \"\"\"\n        Retrieves the details of an event for given module name, call function name and block_hash\n        (or chaintip if block_hash is omitted)\n\n        Parameters\n        ----------\n        module_name\n        event_name\n        block_hash\n\n        Returns\n        -------\n\n        \"\"\"\n\n        self.init_runtime(block_hash=block_hash)\n\n        for pallet in self.metadata.pallets:\n            if pallet.name == module_name and pallet.events:\n                for event in pallet.events:\n                    if event.name == event_name:\n                        return event\n\n    def get_metadata_constants(self, block_hash=None) -> list:\n        \"\"\"\n        Retrieves a list of all constants in metadata active at given block_hash (or chaintip if block_hash is omitted)\n\n        Parameters\n        ----------\n        block_hash\n\n        Returns\n        -------\n        list\n        \"\"\"\n\n        self.init_runtime(block_hash=block_hash)\n\n        constant_list = []\n\n        for module_idx, module in enumerate(self.metadata.pallets):\n            for constant in module.constants or []:\n                constant_list.append(\n                    self.serialize_constant(\n                        constant, module, self.runtime_version\n                    )\n                )\n\n        return constant_list\n\n    def get_metadata_constant(self, module_name, constant_name, block_hash=None):\n        \"\"\"\n        Retrieves the details of a constant for given module name, call function name and block_hash\n        (or chaintip if block_hash is omitted)\n\n        Parameters\n        ----------\n        module_name\n        constant_name\n        block_hash\n\n        Returns\n        -------\n        MetadataModuleConstants\n        \"\"\"\n\n        self.init_runtime(block_hash=block_hash)\n\n        for module_idx, module in enumerate(self.metadata.pallets):\n\n            if module_name == module.name and module.constants:\n\n                for constant in module.constants:\n                    if constant_name == constant.value['name']:\n                        return constant\n\n    def get_constant(self, module_name, constant_name, block_hash=None) -> Optional[ScaleType]:\n        \"\"\"\n        Returns the decoded `ScaleType` object of the constant for given module name, call function name and block_hash\n        (or chaintip if block_hash is omitted)\n\n        Parameters\n        ----------\n        module_name\n        constant_name\n        block_hash\n\n        Returns\n        -------\n        ScaleType\n        \"\"\"\n\n        constant = self.get_metadata_constant(module_name, constant_name, block_hash=block_hash)\n        if constant:\n            # Decode to ScaleType\n            return self.decode_scale(\n                constant.type, ScaleBytes(constant.constant_value), block_hash=block_hash, return_scale_obj=True\n            )\n\n    def get_metadata_storage_functions(self, block_hash=None) -> list:\n        \"\"\"\n        Retrieves a list of all storage functions in metadata active at given block_hash (or chaintip if block_hash is\n        omitted)\n\n        Parameters\n        ----------\n        block_hash\n\n        Returns\n        -------\n        list\n        \"\"\"\n        self.init_runtime(block_hash=block_hash)\n\n        storage_list = []\n\n        for module_idx, module in enumerate(self.metadata.pallets):\n            if module.storage:\n                for storage in module.storage:\n                    storage_list.append(\n                        self.serialize_storage_item(\n                            storage_item=storage,\n                            module=module,\n                            spec_version_id=self.runtime_version\n                        )\n                    )\n\n        return storage_list\n\n    def get_metadata_storage_function(self, module_name, storage_name, block_hash=None):\n        \"\"\"\n        Retrieves the details of a storage function for given module name, call function name and block_hash\n\n        Parameters\n        ----------\n        module_name\n        storage_name\n        block_hash\n\n        Returns\n        -------\n\n        \"\"\"\n        self.init_runtime(block_hash=block_hash)\n\n        pallet = self.metadata.get_metadata_pallet(module_name)\n\n        if pallet:\n            return pallet.get_storage_function(storage_name)\n\n    def get_metadata_errors(self, block_hash=None) -> list:\n        \"\"\"\n        Retrieves a list of all errors in metadata active at given block_hash (or chaintip if block_hash is omitted)\n\n        Parameters\n        ----------\n        block_hash\n\n        Returns\n        -------\n        list\n        \"\"\"\n        self.init_runtime(block_hash=block_hash)\n\n        error_list = []\n\n        for module_idx, module in enumerate(self.metadata.pallets):\n            if module.errors:\n                for error in module.errors:\n                    error_list.append(\n                        self.serialize_module_error(\n                            module=module, error=error, spec_version=self.runtime_version\n                        )\n                    )\n\n        return error_list\n\n    def get_metadata_error(self, module_name, error_name, block_hash=None):\n        \"\"\"\n        Retrieves the details of an error for given module name, call function name and block_hash\n\n        Parameters\n        ----------\n        module_name\n        error_name\n        block_hash\n\n        Returns\n        -------\n\n        \"\"\"\n        self.init_runtime(block_hash=block_hash)\n\n        for module_idx, module in enumerate(self.metadata.pallets):\n            if module.name == module_name and module.errors:\n                for error in module.errors:\n                    if error_name == error.name:\n                        return error\n\n    def get_metadata_runtime_call_functions(self) -> list:\n        \"\"\"\n        Get a list of available runtime API calls\n\n        Returns\n        -------\n        list\n        \"\"\"\n        self.init_runtime()\n        call_functions = []\n\n        for api, methods in self.runtime_config.type_registry[\"runtime_api\"].items():\n            for method in methods[\"methods\"].keys():\n                call_functions.append(self.get_metadata_runtime_call_function(api, method))\n\n        return call_functions\n\n    def get_metadata_runtime_call_function(self, api: str, method: str) -> GenericRuntimeCallDefinition:\n        \"\"\"\n        Get details of a runtime API call\n\n        Parameters\n        ----------\n        api: Name of the runtime API e.g. 'TransactionPaymentApi'\n        method: Name of the method e.g. 'query_fee_details'\n\n        Returns\n        -------\n        GenericRuntimeCallDefinition\n        \"\"\"\n        self.init_runtime()\n\n        try:\n            runtime_call_def = self.runtime_config.type_registry[\"runtime_api\"][api]['methods'][method]\n            runtime_call_def['api'] = api\n            runtime_call_def['method'] = method\n            runtime_api_types = self.runtime_config.type_registry[\"runtime_api\"][api].get(\"types\", {})\n        except KeyError:\n            raise ValueError(f\"Runtime API Call '{api}.{method}' not found in registry\")\n\n        # Add runtime API types to registry\n        self.runtime_config.update_type_registry_types(runtime_api_types)\n\n        runtime_call_def_obj = self.create_scale_object(\"RuntimeCallDefinition\")\n        runtime_call_def_obj.encode(runtime_call_def)\n\n        return runtime_call_def_obj\n\n    def __get_block_handler(self, block_hash: str, ignore_decoding_errors: bool = False, include_author: bool = False,\n                            header_only: bool = False, finalized_only: bool = False,\n                            subscription_handler: callable = None):\n\n        try:\n            self.init_runtime(block_hash=block_hash)\n        except BlockNotFound:\n            return None\n\n        def decode_block(block_data, block_data_hash=None):\n\n            if block_data:\n                if block_data_hash:\n                    block_data['header']['hash'] = block_data_hash\n\n                if type(block_data['header']['number']) is str:\n                    # Convert block number from hex (backwards compatibility)\n                    block_data['header']['number'] = int(block_data['header']['number'], 16)\n\n                extrinsic_cls = self.runtime_config.get_decoder_class('Extrinsic')\n\n                if 'extrinsics' in block_data:\n                    for idx, extrinsic_data in enumerate(block_data['extrinsics']):\n                        extrinsic_decoder = extrinsic_cls(\n                            data=ScaleBytes(extrinsic_data),\n                            metadata=self.metadata,\n                            runtime_config=self.runtime_config\n                        )\n                        try:\n                            extrinsic_decoder.decode(check_remaining=self.config.get('strict_scale_decode'))\n                            block_data['extrinsics'][idx] = extrinsic_decoder\n\n                        except Exception as e:\n                            if not ignore_decoding_errors:\n                                raise\n                            block_data['extrinsics'][idx] = None\n\n                for idx, log_data in enumerate(block_data['header'][\"digest\"][\"logs\"]):\n                    if type(log_data) is str:\n                        # Convert digest log from hex (backwards compatibility)\n                        try:\n                            log_digest_cls = self.runtime_config.get_decoder_class('sp_runtime::generic::digest::DigestItem')\n\n                            if log_digest_cls is None:\n                                raise NotImplementedError(\"No decoding class found for 'DigestItem'\")\n\n                            log_digest = log_digest_cls(data=ScaleBytes(log_data))\n                            log_digest.decode(check_remaining=self.config.get('strict_scale_decode'))\n\n                            block_data['header'][\"digest\"][\"logs\"][idx] = log_digest\n\n                            if include_author and 'PreRuntime' in log_digest.value:\n\n                                if self.implements_scaleinfo():\n\n                                    engine = bytes(log_digest[1][0])\n                                    # Retrieve validator set\n                                    parent_hash = block_data['header']['parentHash']\n                                    validator_set = self.query(\"Session\", \"Validators\", block_hash=parent_hash)\n\n                                    if engine == b'BABE':\n                                        babe_predigest = self.runtime_config.create_scale_object(\n                                            type_string='RawBabePreDigest',\n                                            data=ScaleBytes(bytes(log_digest[1][1]))\n                                        )\n\n                                        babe_predigest.decode(check_remaining=self.config.get('strict_scale_decode'))\n\n                                        rank_validator = babe_predigest[1].value['authority_index']\n\n                                        block_author = validator_set[rank_validator]\n                                        block_data['author'] = block_author.value\n\n                                    elif engine == b'aura':\n                                        aura_predigest = self.runtime_config.create_scale_object(\n                                            type_string='RawAuraPreDigest',\n                                            data=ScaleBytes(bytes(log_digest[1][1]))\n                                        )\n\n                                        aura_predigest.decode(check_remaining=self.config.get('strict_scale_decode'))\n\n                                        rank_validator = aura_predigest.value['slot_number'] % len(validator_set)\n\n                                        block_author = validator_set[rank_validator]\n                                        block_data['author'] = block_author.value\n                                    else:\n                                        raise NotImplementedError(\n                                            f\"Cannot extract author for engine {log_digest.value['PreRuntime'][0]}\"\n                                        )\n                                else:\n\n                                    if log_digest.value['PreRuntime']['engine'] == 'BABE':\n                                        validator_set = self.query(\"Session\", \"Validators\", block_hash=block_hash)\n                                        rank_validator = log_digest.value['PreRuntime']['data']['authority_index']\n\n                                        block_author = validator_set.elements[rank_validator]\n                                        block_data['author'] = block_author.value\n                                    else:\n                                        raise NotImplementedError(\n                                            f\"Cannot extract author for engine {log_digest.value['PreRuntime']['engine']}\"\n                                        )\n\n                        except Exception:\n                            if not ignore_decoding_errors:\n                                raise\n                            block_data['header'][\"digest\"][\"logs\"][idx] = None\n\n            return block_data\n\n        if callable(subscription_handler):\n\n            rpc_method_prefix = 'Finalized' if finalized_only else 'New'\n\n            def result_handler(message, update_nr, subscription_id):\n\n                new_block = decode_block({'header': message['params']['result']})\n\n                subscription_result = subscription_handler(new_block, update_nr, subscription_id)\n\n                if subscription_result is not None:\n                    # Handler returned end result: unsubscribe from further updates\n                    self.rpc_request(f\"chain_unsubscribe{rpc_method_prefix}Heads\", [subscription_id])\n\n                return subscription_result\n\n            result = self.rpc_request(f\"chain_subscribe{rpc_method_prefix}Heads\", [], result_handler=result_handler)\n\n            return result\n\n        else:\n\n            if header_only:\n                response = self.rpc_request('chain_getHeader', [block_hash])\n                return decode_block({'header': response['result']}, block_data_hash=block_hash)\n\n            else:\n                response = self.rpc_request('chain_getBlock', [block_hash])\n                return decode_block(response['result']['block'], block_data_hash=block_hash)\n\n    def get_block(self, block_hash: str = None, block_number: int = None, ignore_decoding_errors: bool = False,\n                  include_author: bool = False, finalized_only: bool = False) -> Optional[dict]:\n        \"\"\"\n        Retrieves a block and decodes its containing extrinsics and log digest items. If `block_hash` and `block_number`\n        is omited the chain tip will be retrieve, or the finalized head if `finalized_only` is set to true.\n\n        Either `block_hash` or `block_number` should be set, or both omitted.\n\n        Parameters\n        ----------\n        block_hash: the hash of the block to be retrieved\n        block_number: the block number to retrieved\n        ignore_decoding_errors: When set this will catch all decoding errors, set the item to None and continue decoding\n        include_author: This will retrieve the block author from the validator set and add to the result\n        finalized_only: when no `block_hash` or `block_number` is set, this will retrieve the finalized head\n\n        Returns\n        -------\n        A dict containing the extrinsic and digest logs data\n        \"\"\"\n        if block_hash and block_number:\n            raise ValueError('Either block_hash or block_number should be be set')\n\n        if block_number is not None:\n            block_hash = self.get_block_hash(block_number)\n\n            if block_hash is None:\n                return\n\n        if block_hash and finalized_only:\n            raise ValueError('finalized_only cannot be True when block_hash is provided')\n\n        if block_hash is None:\n            # Retrieve block hash\n            if finalized_only:\n                block_hash = self.get_chain_finalised_head()\n            else:\n                block_hash = self.get_chain_head()\n\n        return self.__get_block_handler(\n            block_hash=block_hash, ignore_decoding_errors=ignore_decoding_errors, header_only=False,\n            include_author=include_author\n        )\n\n    def get_block_header(self, block_hash: str = None, block_number: int = None, ignore_decoding_errors: bool = False,\n                         include_author: bool = False, finalized_only: bool = False):\n        \"\"\"\n        Retrieves a block header and decodes its containing log digest items. If `block_hash` and `block_number`\n        is omited the chain tip will be retrieve, or the finalized head if `finalized_only` is set to true.\n\n        Either `block_hash` or `block_number` should be set, or both omitted.\n\n        See `get_block()` to also include the extrinsics in the result\n\n        Parameters\n        ----------\n        block_hash: the hash of the block to be retrieved\n        block_number: the block number to retrieved\n        ignore_decoding_errors: When set this will catch all decoding errors, set the item to None and continue decoding\n        include_author: This will retrieve the block author from the validator set and add to the result\n        finalized_only: when no `block_hash` or `block_number` is set, this will retrieve the finalized head\n\n        Returns\n        -------\n        A dict containing the header and digest logs data\n        \"\"\"\n        if block_hash and block_number:\n            raise ValueError('Either block_hash or block_number should be be set')\n\n        if block_number is not None:\n            block_hash = self.get_block_hash(block_number)\n\n            if block_hash is None:\n                return\n\n        if block_hash and finalized_only:\n            raise ValueError('finalized_only cannot be True when block_hash is provided')\n\n        if block_hash is None:\n            # Retrieve block hash\n            if finalized_only:\n                block_hash = self.get_chain_finalised_head()\n            else:\n                block_hash = self.get_chain_head()\n\n        else:\n            # Check conflicting scenarios\n            if finalized_only:\n                raise ValueError('finalized_only cannot be True when block_hash is provided')\n\n        return self.__get_block_handler(\n            block_hash=block_hash, ignore_decoding_errors=ignore_decoding_errors, header_only=True,\n            include_author=include_author\n        )\n\n    def subscribe_block_headers(self, subscription_handler: callable, ignore_decoding_errors: bool = False,\n                                include_author: bool = False, finalized_only=False):\n        \"\"\"\n        Subscribe to new block headers as soon as they are available. The callable `subscription_handler` will be\n        executed when a new block is available and execution will block until `subscription_handler` will return\n        a result other than `None`.\n\n        Example:\n\n        ```\n        def subscription_handler(obj, update_nr, subscription_id):\n\n            print(f\"New block #{obj['header']['number']} produced by {obj['header']['author']}\")\n\n            if update_nr > 10\n              return {'message': 'Subscription will cancel when a value is returned', 'updates_processed': update_nr}\n\n\n        result = substrate.subscribe_block_headers(subscription_handler, include_author=True)\n        ```\n\n        Parameters\n        ----------\n        subscription_handler\n        ignore_decoding_errors: When set this will catch all decoding errors, set the item to None and continue decoding\n        include_author: This will retrieve the block author from the validator set and add to the result\n        finalized_only: when no `block_hash` or `block_number` is set, this will retrieve the finalized head\n\n        Returns\n        -------\n        Value return by `subscription_handler`\n        \"\"\"\n        # Retrieve block hash\n        if finalized_only:\n            block_hash = self.get_chain_finalised_head()\n        else:\n            block_hash = self.get_chain_head()\n\n        return self.__get_block_handler(\n            block_hash, subscription_handler=subscription_handler, ignore_decoding_errors=ignore_decoding_errors,\n            include_author=include_author, finalized_only=finalized_only\n        )\n\n    def retrieve_extrinsic_by_identifier(self, extrinsic_identifier: str) -> \"ExtrinsicReceipt\":\n        \"\"\"\n        Retrieve an extrinsic by its identifier in format \"[block_number]-[extrinsic_index]\" e.g. 333456-4\n\n        Parameters\n        ----------\n        extrinsic_identifier\n\n        Returns\n        -------\n        ExtrinsicReceipt\n        \"\"\"\n        return ExtrinsicReceipt.create_from_extrinsic_identifier(\n            substrate=self, extrinsic_identifier=extrinsic_identifier\n        )\n\n    def retrieve_extrinsic_by_hash(self, block_hash: str, extrinsic_hash: str) -> \"ExtrinsicReceipt\":\n        \"\"\"\n        Retrieve an extrinsic by providing the block_hash and the extrinsic hash\n\n        Parameters\n        ----------\n        block_hash\n        extrinsic_hash\n\n        Returns\n        -------\n        ExtrinsicReceipt\n        \"\"\"\n        return ExtrinsicReceipt(\n            substrate=self,\n            block_hash=block_hash,\n            extrinsic_hash=extrinsic_hash\n        )\n\n    def get_extrinsics(self, block_hash: str = None, block_number: int = None) -> list:\n        \"\"\"\n        Return extrinsics for given block_hash or block_number\n\n        Parameters\n        ----------\n        block_hash\n        block_number\n\n        Returns\n        -------\n\n        \"\"\"\n        block = self.get_block(block_hash=block_hash, block_number=block_number)\n        if block:\n            return block['extrinsics']\n\n    def extension_call(self, name, **kwargs):\n        for extension in self.extensions:\n            if isinstance(extension, Extension):\n                if hasattr(extension, name):\n                    try:\n                        self.debug_message(f\"Call '{name}' using extension {extension.__class__.__name__} ...\")\n                        results = getattr(extension, name)(**kwargs)\n                        return results\n                    except NotImplementedError:\n                        pass\n\n        raise ExtensionCallNotFound(f\"No extension found that implements '{name}'\")\n\n    def filter_extrinsics(self, **kwargs) -> list:\n        return self.extension_call('filter_extrinsics', **kwargs)\n\n    def filter_events(self, **kwargs) -> list:\n        return self.extension_call('filter_events', **kwargs)\n\n    def search_block_number(self, block_datetime: datetime, block_time: int = 6) -> int:\n        return self.extension_call('search_block_number', block_datetime=block_datetime, block_time=block_time)\n\n    def get_block_timestamp(self, block_number: int) -> int:\n        return self.extension_call('get_block_timestamp', block_number=block_number)\n\n    def decode_scale(self, type_string, scale_bytes, block_hash=None, return_scale_obj=False):\n        \"\"\"\n        Helper function to decode arbitrary SCALE-bytes (e.g. 0x02000000) according to given RUST type_string\n        (e.g. BlockNumber). The relevant versioning information of the type (if defined) will be applied if block_hash\n        is set\n\n        Parameters\n        ----------\n        type_string\n        scale_bytes\n        block_hash\n        return_scale_obj: if True the SCALE object itself is returned, otherwise the serialized dict value of the object\n\n        Returns\n        -------\n\n        \"\"\"\n        self.init_runtime(block_hash=block_hash)\n\n        if type(scale_bytes) == str:\n            scale_bytes = ScaleBytes(scale_bytes)\n\n        obj = self.runtime_config.create_scale_object(\n            type_string=type_string,\n            data=scale_bytes,\n            metadata=self.metadata\n        )\n\n        obj.decode(check_remaining=self.config.get('strict_scale_decode'))\n\n        if return_scale_obj:\n            return obj\n        else:\n            return obj.value\n\n    def encode_scale(self, type_string, value, block_hash=None) -> ScaleBytes:\n        \"\"\"\n        Helper function to encode arbitrary data into SCALE-bytes for given RUST type_string\n\n        Parameters\n        ----------\n        type_string\n        value\n        block_hash\n\n        Returns\n        -------\n        ScaleBytes\n        \"\"\"\n        self.init_runtime(block_hash=block_hash)\n\n        obj = self.runtime_config.create_scale_object(\n            type_string=type_string, metadata=self.metadata\n        )\n        return obj.encode(value)\n\n    def ss58_encode(self, public_key: Union[str, bytes], ss58_format: int = None) -> str:\n        \"\"\"\n        Helper function to encode a public key to SS58 address.\n\n        If no target `ss58_format` is provided, it will default to the ss58 format of the network it's connected to.\n\n        Parameters\n        ----------\n        public_key: 32 bytes or hex-string. e.g. 0x6e39f36c370dd51d9a7594846914035de7ea8de466778ea4be6c036df8151f29\n        ss58_format: target networkID to format the address for, defaults to the network it's connected to\n\n        Returns\n        -------\n        str containing the SS58 address\n        \"\"\"\n\n        if ss58_format is None:\n            ss58_format = self.ss58_format\n\n        return ss58_encode(public_key, ss58_format=ss58_format)\n\n    def ss58_decode(self, ss58_address: str) -> str:\n        \"\"\"\n        Helper function to decode a SS58 address to a public key\n\n        Parameters\n        ----------\n        ss58_address\n\n        Returns\n        -------\n        str containing the hex representation of the public key\n        \"\"\"\n        return ss58_decode(ss58_address, valid_ss58_format=self.ss58_format)\n\n    def is_valid_ss58_address(self, value: str) -> bool:\n        \"\"\"\n        Helper function to validate given value as ss58_address for current network/ss58_format\n\n        Parameters\n        ----------\n        value\n\n        Returns\n        -------\n        bool\n        \"\"\"\n        return is_valid_ss58_address(value, valid_ss58_format=self.ss58_format)\n\n    # Serializing helper function\n\n    def serialize_storage_item(self, storage_item, module, spec_version_id) -> dict:\n        \"\"\"\n        Helper function to serialize a storage item\n\n        Parameters\n        ----------\n        storage_item\n        module\n        spec_version_id\n\n        Returns\n        -------\n        dict\n        \"\"\"\n        storage_dict = {\n            \"storage_name\": storage_item.name,\n            \"storage_modifier\": storage_item.modifier,\n            \"storage_default_scale\": storage_item['default'].get_used_bytes(),\n            \"storage_default\": None,\n            \"documentation\": '\\n'.join(storage_item.docs),\n            \"module_id\": module.get_identifier(),\n            \"module_prefix\": module.value['storage']['prefix'],\n            \"module_name\": module.name,\n            \"spec_version\": spec_version_id,\n            \"type_keys\": storage_item.get_params_type_string(),\n            \"type_hashers\": storage_item.get_param_hashers(),\n            \"type_value\": storage_item.get_value_type_string()\n        }\n\n        type_class, type_info = next(iter(storage_item.type.items()))\n\n        storage_dict[\"type_class\"] = type_class\n\n        value_scale_type = storage_item.get_value_type_string()\n\n        if storage_item.value['modifier'] == 'Default':\n            # Fallback to default value of storage function if no result\n            query_value = storage_item.value_object['default'].value_object\n        else:\n            # No result is interpreted as an Option<...> result\n            value_scale_type = f'Option<{value_scale_type}>'\n            query_value = storage_item.value_object['default'].value_object\n\n        try:\n            obj = self.runtime_config.create_scale_object(\n                type_string=value_scale_type,\n                data=ScaleBytes(query_value),\n                metadata=self.metadata\n            )\n            obj.decode()\n            storage_dict[\"storage_default\"] = obj.decode()\n        except Exception:\n            storage_dict[\"storage_default\"] = '[decoding error]'\n\n        return storage_dict\n\n    def serialize_constant(self, constant, module, spec_version_id) -> dict:\n        \"\"\"\n        Helper function to serialize a constant\n\n        Parameters\n        ----------\n        constant\n        module\n        spec_version_id\n\n        Returns\n        -------\n        dict\n        \"\"\"\n        try:\n            value_obj = self.runtime_config.create_scale_object(\n                type_string=constant.type, data=ScaleBytes(constant.constant_value)\n            )\n            constant_decoded_value = value_obj.decode()\n        except Exception:\n            constant_decoded_value = '[decoding error]'\n\n        return {\n            \"constant_name\": constant.name,\n            \"constant_type\": constant.type,\n            \"constant_value\": constant_decoded_value,\n            \"constant_value_scale\": f\"0x{constant.constant_value.hex()}\",\n            \"documentation\": '\\n'.join(constant.docs),\n            \"module_id\": module.get_identifier(),\n            \"module_prefix\": module.value['storage']['prefix'] if module.value['storage'] else None,\n            \"module_name\": module.name,\n            \"spec_version\": spec_version_id\n        }\n\n    def serialize_module_call(self, module, call, spec_version, call_index=None) -> dict:\n        \"\"\"\n        Helper function to serialize a call function\n\n        Parameters\n        ----------\n        module\n        call\n        spec_version\n        call_index\n\n        Returns\n        -------\n        dict\n        \"\"\"\n        return {\n            # \"call_id\": call.get_identifier(),\n            \"call_name\": call.name,\n            \"call_args\": [call_arg.value for call_arg in call.args],\n            # \"lookup\": '0x{}'.format(call_index),\n            \"documentation\": '\\n'.join(call.docs),\n            # \"module_id\": module.get_identifier(),\n            \"module_prefix\": module.value['storage']['prefix'] if module.value['storage'] else None,\n            \"module_name\": module.name,\n            \"spec_version\": spec_version\n        }\n\n    def serialize_module_event(self, module, event, spec_version, event_index) -> dict:\n        \"\"\"\n        Helper function to serialize an event\n\n        Parameters\n        ----------\n        module\n        event\n        spec_version\n        event_index\n\n        Returns\n        -------\n        dict\n        \"\"\"\n        return {\n            \"event_id\": event.name,\n            \"event_name\": event.name,\n            \"event_args\": [\n                {\n                    \"event_arg_index\": idx,\n                    \"type\": arg\n                } for idx, arg in enumerate(event.args)\n            ],\n            \"lookup\": '0x{}'.format(event_index),\n            \"documentation\": '\\n'.join(event.docs),\n            \"module_id\": module.get_identifier(),\n            \"module_prefix\": module.prefix,\n            \"module_name\": module.name,\n            \"spec_version\": spec_version\n        }\n\n    def serialize_module_error(self, module, error, spec_version) -> dict:\n        \"\"\"\n        Helper function to serialize an error\n\n        Parameters\n        ----------\n        module\n        error\n        spec_version\n\n        Returns\n        -------\n        dict\n        \"\"\"\n        return {\n            \"error_name\": error.name,\n            \"documentation\": '\\n'.join(error.docs),\n            \"module_id\": module.get_identifier(),\n            \"module_prefix\": module.value['storage']['prefix'] if module.value['storage'] else None,\n            \"module_name\": module.name,\n            \"spec_version\": spec_version\n        }\n\n    def update_type_registry_presets(self) -> bool:\n        try:\n            update_type_registries()\n            self.reload_type_registry(use_remote_preset=False)\n            return True\n        except Exception:\n            return False\n\n    def reload_type_registry(self, use_remote_preset: bool = True, auto_discover: bool = True):\n        \"\"\"\n        Reload type registry and preset used to instantiate the SubtrateInterface object. Useful to periodically apply\n        changes in type definitions when a runtime upgrade occurred\n\n        Parameters\n        ----------\n        use_remote_preset: When True preset is downloaded from Github master, otherwise use files from local installed scalecodec package\n        auto_discover\n\n        Returns\n        -------\n\n        \"\"\"\n        self.runtime_config.clear_type_registry()\n\n        self.runtime_config.implements_scale_info = self.implements_scaleinfo()\n\n        # Load metadata types in runtime configuration\n        self.runtime_config.update_type_registry(load_type_registry_preset(name=\"core\"))\n        self.apply_type_registry_presets(use_remote_preset=use_remote_preset, auto_discover=auto_discover)\n\n    def apply_type_registry_presets(self, use_remote_preset: bool = True, auto_discover: bool = True):\n        if self.type_registry_preset is not None:\n            # Load type registry according to preset\n            type_registry_preset_dict = load_type_registry_preset(\n                name=self.type_registry_preset, use_remote_preset=use_remote_preset\n            )\n\n            if not type_registry_preset_dict:\n                raise ValueError(f\"Type registry preset '{self.type_registry_preset}' not found\")\n\n        elif auto_discover:\n            # Try to auto discover type registry preset by chain name\n            type_registry_name = self.chain.lower().replace(' ', '-')\n            try:\n                type_registry_preset_dict = load_type_registry_preset(type_registry_name)\n                self.debug_message(f\"Auto set type_registry_preset to {type_registry_name} ...\")\n                self.type_registry_preset = type_registry_name\n            except ValueError:\n                type_registry_preset_dict = None\n\n        else:\n            type_registry_preset_dict = None\n\n        if type_registry_preset_dict:\n            # Load type registries in runtime configuration\n            if self.implements_scaleinfo() is False:\n                # Only runtime with no embedded types in metadata need the default set of explicit defined types\n                self.runtime_config.update_type_registry(\n                    load_type_registry_preset(\"legacy\", use_remote_preset=use_remote_preset)\n                )\n\n            if self.type_registry_preset != \"legacy\":\n                self.runtime_config.update_type_registry(type_registry_preset_dict)\n\n        if self.type_registry:\n            # Load type registries in runtime configuration\n            self.runtime_config.update_type_registry(self.type_registry)\n\n    def register_extension(self, extension: Extension):\n        \"\"\"\n        Register an Extension and adds its functionality to the ExtensionRegistry\n\n        Parameters\n        ----------\n        extension: Extension\n\n        Returns\n        -------\n\n        \"\"\"\n        self.extensions.register(extension)\n\n\nclass ExtrinsicReceipt:\n    \"\"\"\n    Object containing information of submitted extrinsic. Block hash where extrinsic is included is required\n        when retrieving triggered events or determine if extrinsic was succesfull\n    \"\"\"\n\n    def __init__(self, substrate: SubstrateInterface, extrinsic_hash: str = None, block_hash: str = None,\n                 block_number: int = None, extrinsic_idx: int = None, finalized=None):\n        \"\"\"\n        Object containing information of submitted extrinsic. Block hash where extrinsic is included is required\n        when retrieving triggered events or determine if extrinsic was succesfull\n\n        Parameters\n        ----------\n        substrate\n        extrinsic_hash\n        block_hash\n        finalized\n        \"\"\"\n        self.substrate = substrate\n        self.extrinsic_hash = extrinsic_hash\n        self.block_hash = block_hash\n        self.block_number = block_number\n        self.finalized = finalized\n\n        self.__extrinsic_idx = extrinsic_idx\n        self.__extrinsic = None\n\n        self.__triggered_events = None\n        self.__is_success = None\n        self.__error_message = None\n        self.__weight = None\n        self.__total_fee_amount = None\n\n    def get_extrinsic_identifier(self) -> str:\n        \"\"\"\n        Returns the on-chain identifier for this extrinsic in format \"[block_number]-[extrinsic_idx]\" e.g. 134324-2\n        Returns\n        -------\n        str\n        \"\"\"\n        if self.block_number is None:\n            if self.block_hash is None:\n                raise ValueError('Cannot create extrinsic identifier: block_hash is not set')\n\n            self.block_number = self.substrate.get_block_number(self.block_hash)\n\n            if self.block_number is None:\n                raise ValueError('Cannot create extrinsic identifier: unknown block_hash')\n\n        return f'{self.block_number}-{self.extrinsic_idx}'\n\n    @classmethod\n    def create_from_extrinsic_identifier(\n            cls, substrate: SubstrateInterface, extrinsic_identifier: str\n    ) -> \"ExtrinsicReceipt\":\n        \"\"\"\n        Create an `ExtrinsicReceipt` with on-chain identifier for this extrinsic in format\n        \"[block_number]-[extrinsic_idx]\" e.g. 134324-2\n\n        Parameters\n        ----------\n        substrate: SubstrateInterface\n        extrinsic_identifier: str\n\n        Returns\n        -------\n        ExtrinsicReceipt\n        \"\"\"\n        id_parts = extrinsic_identifier.split('-', maxsplit=1)\n        block_number: int = int(id_parts[0])\n        extrinsic_idx: int = int(id_parts[1])\n\n        # Retrieve block hash\n        block_hash = substrate.get_block_hash(block_number)\n\n        return cls(\n            substrate=substrate,\n            block_hash=block_hash,\n            block_number=block_number,\n            extrinsic_idx=extrinsic_idx\n        )\n\n    def retrieve_extrinsic(self):\n        if not self.block_hash:\n            raise ValueError(\"ExtrinsicReceipt can't retrieve events because it's unknown which block_hash it is \"\n                             \"included, manually set block_hash or use `wait_for_inclusion` when sending extrinsic\")\n        # Determine extrinsic idx\n\n        block = self.substrate.get_block(block_hash=self.block_hash)\n\n        extrinsics = block['extrinsics']\n\n        if len(extrinsics) > 0:\n            if self.__extrinsic_idx is None:\n                self.__extrinsic_idx = self.__get_extrinsic_index(\n                    block_extrinsics=extrinsics,\n                    extrinsic_hash=self.extrinsic_hash\n                )\n\n            if self.__extrinsic_idx >= len(extrinsics):\n                raise ExtrinsicNotFound()\n\n            self.__extrinsic = extrinsics[self.__extrinsic_idx]\n\n    @property\n    def extrinsic_idx(self) -> int:\n        \"\"\"\n        Retrieves the index of this extrinsic in containing block\n\n        Returns\n        -------\n        int\n        \"\"\"\n        if self.__extrinsic_idx is None:\n            self.retrieve_extrinsic()\n        return self.__extrinsic_idx\n\n    @property\n    def extrinsic(self) -> GenericExtrinsic:\n        \"\"\"\n        Retrieves the `Extrinsic` subject of this receipt\n\n        Returns\n        -------\n        Extrinsic\n        \"\"\"\n        if self.__extrinsic is None:\n            self.retrieve_extrinsic()\n        return self.__extrinsic\n\n    @property\n    def triggered_events(self) -> list:\n        \"\"\"\n        Gets triggered events for submitted extrinsic. block_hash where extrinsic is included is required, manually\n        set block_hash or use `wait_for_inclusion` when submitting extrinsic\n\n        Returns\n        -------\n        list\n        \"\"\"\n        if self.__triggered_events is None:\n            if not self.block_hash:\n                raise ValueError(\"ExtrinsicReceipt can't retrieve events because it's unknown which block_hash it is \"\n                                 \"included, manually set block_hash or use `wait_for_inclusion` when sending extrinsic\")\n\n            if self.extrinsic_idx is None:\n                self.retrieve_extrinsic()\n\n            self.__triggered_events = []\n\n            for event in self.substrate.get_events(block_hash=self.block_hash):\n                if event.extrinsic_idx == self.extrinsic_idx:\n                    self.__triggered_events.append(event)\n\n        return self.__triggered_events\n\n    def process_events(self):\n        if self.triggered_events:\n\n            self.__total_fee_amount = 0\n\n            # Process fees\n            has_transaction_fee_paid_event = False\n\n            for event in self.triggered_events:\n                if event.value['module_id'] == 'TransactionPayment' and event.value['event_id'] == 'TransactionFeePaid':\n                    self.__total_fee_amount = event.value['attributes']['actual_fee']\n                    has_transaction_fee_paid_event = True\n\n            # Process other events\n            for event in self.triggered_events:\n\n                # Check events\n                if self.substrate.implements_scaleinfo():\n\n                    if event.value['module_id'] == 'System' and event.value['event_id'] == 'ExtrinsicSuccess':\n                        self.__is_success = True\n                        self.__error_message = None\n\n                        if 'dispatch_info' in event.value['attributes']:\n                            self.__weight = event.value['attributes']['dispatch_info']['weight']\n                        else:\n                            # Backwards compatibility\n                            self.__weight = event.value['attributes']['weight']\n\n                    elif event.value['module_id'] == 'System' and event.value['event_id'] == 'ExtrinsicFailed':\n                        self.__is_success = False\n\n                        if type(event.value['attributes']) is dict:\n                            dispatch_info = event.value['attributes']['dispatch_info']\n                            dispatch_error = event.value['attributes']['dispatch_error']\n                        else:\n                            # Backwards compatibility\n                            dispatch_info = event.value['attributes'][1]\n                            dispatch_error = event.value['attributes'][0]\n\n                        self.__weight = dispatch_info['weight']\n\n                        if 'Module' in dispatch_error:\n\n                            if type(dispatch_error['Module']) is tuple:\n                                module_index = dispatch_error['Module'][0]\n                                error_index = dispatch_error['Module'][1]\n                            else:\n                                module_index = dispatch_error['Module']['index']\n                                error_index = dispatch_error['Module']['error']\n\n                            if type(error_index) is str:\n                                # Actual error index is first u8 in new [u8; 4] format\n                                error_index = int(error_index[2:4], 16)\n\n                            module_error = self.substrate.metadata.get_module_error(\n                                module_index=module_index,\n                                error_index=error_index\n                            )\n                            self.__error_message = {\n                                'type': 'Module',\n                                'name': module_error.name,\n                                'docs': module_error.docs\n                            }\n                        elif 'BadOrigin' in dispatch_error:\n                            self.__error_message = {\n                                'type': 'System',\n                                'name': 'BadOrigin',\n                                'docs': 'Bad origin'\n                            }\n                        elif 'CannotLookup' in dispatch_error:\n                            self.__error_message = {\n                                'type': 'System',\n                                'name': 'CannotLookup',\n                                'docs': 'Cannot lookup'\n                            }\n                        elif 'Other' in dispatch_error:\n                            self.__error_message = {\n                                'type': 'System',\n                                'name': 'Other',\n                                'docs': 'Unspecified error occurred'\n                            }\n\n                    elif not has_transaction_fee_paid_event:\n\n                        if event.value['module_id'] == 'Treasury' and event.value['event_id'] == 'Deposit':\n                            if type(event.value['attributes']) is dict:\n                                self.__total_fee_amount += event.value['attributes']['value']\n                            else:\n                                # Backwards compatibility\n                                self.__total_fee_amount += event.value['attributes']\n\n                        elif event.value['module_id'] == 'Balances' and event.value['event_id'] == 'Deposit':\n                            if type(event.value['attributes']) is dict:\n                                self.__total_fee_amount += event.value['attributes']['amount']\n                            else:\n                                # Backwards compatibility\n                                self.__total_fee_amount += event.value['attributes'][1]\n\n                else:\n\n                    if event.event_module.name == 'System' and event.event.name == 'ExtrinsicSuccess':\n                        self.__is_success = True\n                        self.__error_message = None\n\n                        for param in event.params:\n                            if param['type'] == 'DispatchInfo':\n                                self.__weight = param['value']['weight']\n\n                    elif event.event_module.name == 'System' and event.event.name == 'ExtrinsicFailed':\n                        self.__is_success = False\n\n                        for param in event.params:\n                            if param['type'] == 'DispatchError':\n                                if 'Module' in param['value']:\n\n                                    if type(param['value']['Module']['error']) is str:\n                                        # Actual error index is first u8 in new [u8; 4] format (e.g. 0x01000000)\n                                        error_index = int(param['value']['Module']['error'][2:4], 16)\n                                    else:\n                                        error_index = param['value']['Module']['error']\n\n                                    module_error = self.substrate.metadata.get_module_error(\n                                        module_index=param['value']['Module']['index'],\n                                        error_index=error_index\n                                    )\n                                    self.__error_message = {\n                                        'type': 'Module',\n                                        'name': module_error.name,\n                                        'docs': module_error.docs\n                                    }\n                                elif 'BadOrigin' in param['value']:\n                                    self.__error_message = {\n                                        'type': 'System',\n                                        'name': 'BadOrigin',\n                                        'docs': 'Bad origin'\n                                    }\n                                elif 'CannotLookup' in param['value']:\n                                    self.__error_message = {\n                                        'type': 'System',\n                                        'name': 'CannotLookup',\n                                        'docs': 'Cannot lookup'\n                                    }\n                                elif 'Other' in param['value']:\n                                    self.__error_message = {\n                                        'type': 'System',\n                                        'name': 'Other',\n                                        'docs': 'Unspecified error occurred'\n                                    }\n\n                            if param['type'] == 'DispatchInfo':\n                                self.__weight = param['value']['weight']\n\n                    elif event.event_module.name == 'Treasury' and event.event.name == 'Deposit':\n                        self.__total_fee_amount += event.params[0]['value']\n\n                    elif event.event_module.name == 'Balances' and event.event.name == 'Deposit':\n                        self.__total_fee_amount += event.params[1]['value']\n\n    @property\n    def is_success(self) -> bool:\n        \"\"\"\n        Returns `True` if `ExtrinsicSuccess` event is triggered, `False` in case of `ExtrinsicFailed`\n        In case of False `error_message` will contain more details about the error\n\n\n        Returns\n        -------\n        bool\n        \"\"\"\n        if self.__is_success is None:\n            self.process_events()\n\n        return self.__is_success\n\n    @property\n    def error_message(self) -> Optional[dict]:\n        \"\"\"\n        Returns the error message if the extrinsic failed in format e.g.:\n\n        `{'type': 'System', 'name': 'BadOrigin', 'docs': 'Bad origin'}`\n\n        Returns\n        -------\n        dict\n        \"\"\"\n        if self.__error_message is None:\n            if self.is_success:\n                return None\n            self.process_events()\n        return self.__error_message\n\n    @property\n    def weight(self) -> Union[int, dict]:\n        \"\"\"\n        Contains the actual weight when executing this extrinsic\n\n        Returns\n        -------\n        int (WeightV1) or dict (WeightV2)\n        \"\"\"\n        if self.__weight is None:\n            self.process_events()\n        return self.__weight\n\n    @property\n    def total_fee_amount(self) -> int:\n        \"\"\"\n        Contains the total fee costs deducted when executing this extrinsic. This includes fee for the validator (\n        (`Balances.Deposit` event) and the fee deposited for the treasury (`Treasury.Deposit` event)\n\n        Returns\n        -------\n        int\n        \"\"\"\n        if self.__total_fee_amount is None:\n            self.process_events()\n        return self.__total_fee_amount\n\n    # Helper functions\n    @staticmethod\n    def __get_extrinsic_index(block_extrinsics: list, extrinsic_hash: str) -> int:\n        \"\"\"\n        Returns the index of a provided extrinsic\n        \"\"\"\n        for idx, extrinsic in enumerate(block_extrinsics):\n            if extrinsic.extrinsic_hash and f'0x{extrinsic.extrinsic_hash.hex()}' == extrinsic_hash:\n                return idx\n        raise ExtrinsicNotFound()\n\n    # Backwards compatibility methods\n    def __getitem__(self, item):\n        return getattr(self, item)\n\n    def __iter__(self):\n        for item in self.__dict__.items():\n            yield item\n\n    def get(self, name):\n        return self[name]\n\n\nclass QueryMapResult:\n\n    def __init__(self, records: list, page_size: int, module: str = None, storage_function: str = None,\n                 params: list = None, block_hash: str = None, substrate: SubstrateInterface = None,\n                 last_key: str = None, max_results: int = None, ignore_decoding_errors: bool = False):\n        self.current_index = -1\n        self.records = records\n        self.page_size = page_size\n        self.module = module\n        self.storage_function = storage_function\n        self.block_hash = block_hash\n        self.substrate = substrate\n        self.last_key = last_key\n        self.max_results = max_results\n        self.params = params\n        self.ignore_decoding_errors = ignore_decoding_errors\n        self.loading_complete = False\n\n    def retrieve_next_page(self, start_key) -> list:\n        if not self.substrate:\n            return []\n\n        result = self.substrate.query_map(module=self.module, storage_function=self.storage_function,\n                                          params=self.params, page_size=self.page_size, block_hash=self.block_hash,\n                                          start_key=start_key, max_results=self.max_results,\n                                          ignore_decoding_errors=self.ignore_decoding_errors)\n\n        # Update last key from new result set to use as offset for next page\n        self.last_key = result.last_key\n\n        return result.records\n\n    def __iter__(self):\n        self.current_index = -1\n        return self\n\n    def __next__(self):\n        self.current_index += 1\n\n        if self.max_results is not None and self.current_index >= self.max_results:\n            self.loading_complete = True\n            raise StopIteration\n\n        if self.current_index >= len(self.records) and not self.loading_complete:\n            # try to retrieve next page from node\n            self.records += self.retrieve_next_page(start_key=self.last_key)\n\n        if self.current_index >= len(self.records):\n            self.loading_complete = True\n            raise StopIteration\n\n        return self.records[self.current_index]\n\n    def __getitem__(self, item):\n        return self.records[item]\n"
    },
    "schema": {
        "retrieve_next_page": {
            "input": {
                "self": {
                    "value": "_empty",
                    "type": "_empty"
                },
                "start_key": {
                    "value": "_empty",
                    "type": "_empty"
                }
            },
            "output": {
                "value": null,
                "type": "<class 'list'>"
            },
            "docs": null,
            "cost": 1,
            "name": "retrieve_next_page",
            "source": {
                "start": 3473,
                "length": 13,
                "path": "~/commune/commune/modules/subspace/base.py",
                "code": null,
                "hash": "sha256:56b051f49d955872d4a0e3e749dd63c3423727804564a73f93e4b024d272c087",
                "end": 3486
            }
        }
    },
    "name": "subspace.base",
    "key": "5FUFdYf95zNPGEotz5ifxkjA6o1nW5KhDGEon377a7ZNPenk",
    "founder": "5GKvu9qC8VPjXnofUxZP6zxTmvzTBCY1vpJAkh6gWF8YxPKy",
    "cid": "sha256:1dc22e61f2eb54e44c2ac721a46bf4cdec40f0dd69336948bf4951de3ab22ba8",
    "time": 1746536250.150084,
    "signature": "0x9e0a7a7677704425c05d85de5e768236c6bfbf91576ead2eb7ad4405e0405332be57508330185553edcf1a99459fde286edcaeb65219f73a393d46c0c770c380"
}