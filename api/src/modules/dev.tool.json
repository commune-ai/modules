{
    "code": {
        "cmd.py": "\nimport commune as c\nimport subprocess\nimport shlex\nimport os\nfrom typing import List, Dict, Union, Optional, Any\n\nclass Cmd:\n    \"\"\"\n    Command-line execution tool for running shell commands with various options.\n    \n    This tool provides a clean interface for executing shell commands with options\n    for capturing output, handling errors, and processing results.\n    \"\"\"\n    \n    def __init__(self, cwd: str = None, shell: bool = False, env: Dict[str, str] = None):\n        \"\"\"\n        Initialize the Cmd tool.\n        \n        Args:\n            cwd: Current working directory for command execution\n            shell: Whether to use shell execution (can be a security risk)\n            env: Environment variables to set for command execution\n        \"\"\"\n        self.cwd = cwd\n        self.shell = shell\n        self.env = env\n        \n    def forward(\n        self,\n        command: Union[str, List[str]],\n        capture_output: bool = True,\n        text: bool = True,\n        check: bool = False,\n        timeout: Optional[float] = None,\n        cwd: Optional[str] = None,\n        env: Optional[Dict[str, str]] = None,\n        shell: Optional[bool] = None,\n        verbose: bool = True\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Execute a shell command and return the results.\n        \n        Args:\n            command: Command to execute (string or list of arguments)\n            capture_output: Whether to capture stdout/stderr\n            text: Whether to return strings instead of bytes\n            check: Whether to raise an exception on non-zero exit code\n            timeout: Maximum time to wait for command completion (in seconds)\n            cwd: Working directory for command execution (overrides instance setting)\n            env: Environment variables (overrides instance setting)\n            shell: Whether to use shell execution (overrides instance setting)\n            verbose: Whether to print command and output information\n            \n        Returns:\n            Dictionary containing:\n            - success: Whether the command executed successfully\n            - returncode: Exit code of the command\n            - stdout: Standard output (if captured)\n            - stderr: Standard error (if captured)\n            - command: The command that was executed\n        \"\"\"\n        # Use instance defaults if not specified\n        cwd = cwd if cwd is not None else self.cwd\n        env = env if env is not None else self.env\n        shell = shell if shell is not None else self.shell\n        \n        # Process the command\n        if isinstance(command, str) and not shell:\n            command = shlex.split(command)\n        \n        if verbose:\n            c.print(f\"Executing: {command}\", color=\"cyan\")\n        \n        try:\n            # Execute the command\n            result = subprocess.run(\n                command,\n                capture_output=capture_output,\n                text=text,\n                check=check,\n                timeout=timeout,\n                cwd=cwd,\n                env=env,\n                shell=shell\n            )\n            \n            # Prepare the result dictionary\n            output = {\n                \"success\": result.returncode == 0,\n                \"returncode\": result.returncode,\n                \"command\": command\n            }\n            \n            # Add stdout/stderr if captured\n            if capture_output:\n                output[\"stdout\"] = result.stdout\n                output[\"stderr\"] = result.stderr\n                \n                if verbose:\n                    if result.stdout:\n                        c.print(\"STDOUT:\", color=\"green\")\n                        c.print(result.stdout)\n                    if result.stderr:\n                        c.print(\"STDERR:\", color=\"red\")\n                        c.print(result.stderr)\n            \n            if verbose:\n                status = \"Success\" if output[\"success\"] else f\"Failed (code: {result.returncode})\"\n                c.print(f\"Command execution: {status}\", color=\"green\" if output[\"success\"] else \"red\")\n                \n            return output\n            \n        except subprocess.TimeoutExpired as e:\n            if verbose:\n                c.print(f\"Command timed out after {timeout} seconds\", color=\"red\")\n            return {\n                \"success\": False,\n                \"error\": \"timeout\",\n                \"command\": command,\n                \"timeout\": timeout,\n                \"message\": str(e)\n            }\n            \n        except subprocess.SubprocessError as e:\n            if verbose:\n                c.print(f\"Command execution error: {e}\", color=\"red\")\n            return {\n                \"success\": False,\n                \"error\": \"subprocess_error\",\n                \"command\": command,\n                \"message\": str(e)\n            }\n            \n        except Exception as e:\n            if verbose:\n                c.print(f\"Unexpected error: {e}\", color=\"red\")\n            return {\n                \"success\": False,\n                \"error\": \"unexpected\",\n                \"command\": command,\n                \"message\": str(e)\n            }\n    \n    def pipe(\n        self,\n        commands: List[str],\n        verbose: bool = True,\n        **kwargs\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Execute a pipeline of commands, passing output from one to the next.\n        \n        Args:\n            commands: List of commands to execute in sequence\n            verbose: Whether to print command and output information\n            **kwargs: Additional arguments to pass to forward()\n            \n        Returns:\n            Dictionary with the result of the final command\n        \"\"\"\n        if not commands:\n            return {\"success\": False, \"error\": \"no_commands\", \"message\": \"No commands provided\"}\n        \n        if verbose:\n            c.print(f\"Executing pipeline of {len(commands)} commands\", color=\"cyan\")\n        \n        result = None\n        for i, cmd in enumerate(commands):\n            if verbose:\n                c.print(f\"Step {i+1}/{len(commands)}: {cmd}\", color=\"blue\")\n                \n            if result is not None and result.get(\"stdout\"):\n                # Use previous command's output as input\n                if kwargs.get(\"shell\", self.shell):\n                    cmd = f\"echo '{result['stdout']}' | {cmd}\"\n                else:\n                    # For non-shell execution, we need a different approach\n                    result = self.forward(\n                        f\"bash -c \\\"echo '{result['stdout']}' | {cmd}\\\"\",\n                        shell=True,\n                        verbose=verbose,\n                        **kwargs\n                    )\n                    continue\n                    \n            result = self.forward(cmd, verbose=verbose, **kwargs)\n            \n            if not result[\"success\"]:\n                if verbose:\n                    c.print(f\"Pipeline failed at step {i+1}\", color=\"red\")\n                break\n                \n        return result\n",
        "create_file.py": "\nimport commune as c\nimport os\nfrom typing import Dict, Any, Optional, Union\nfrom ..utils import abspath, put_text, ensure_directory_exists\n\nclass CreateFile:\n    \"\"\"\n    A utility tool for creating new files at specified paths.\n    \n    This class provides functionality to:\n    - Create new files with specified content\n    - Ensure parent directories exist\n    - Handle different file types appropriately\n    - Provide feedback on the operation\n    \"\"\"\n    \n    def __init__(self, **kwargs):\n        \"\"\"\n        Initialize the CreateFile tool.\n        \n        Args:\n            **kwargs: Additional configuration parameters\n        \"\"\"\n        pass\n    \n    def forward(self, \n                file_path: str, \n                content: str = \"\",\n                create_parent_dirs: bool = True,\n                overwrite: bool = False,\n                verbose: bool = True) -> Dict[str, Any]:\n        \"\"\"\n        Create a new file at the specified path with the given content.\n        \n        Args:\n            file_path: Path where the file should be created\n            content: Content to write to the file\n            create_parent_dirs: Whether to create parent directories if they don't exist\n            overwrite: Whether to overwrite the file if it already exists\n            verbose: Print detailed information about the operation\n            \n        Returns:\n            Dictionary with operation results including:\n            - success: Whether the operation was successful\n            - file_path: Path to the created file\n            - message: Description of the operation result\n        \"\"\"\n        file_path = abspath(file_path)\n        \n        # Check if file already exists\n        if os.path.exists(file_path) and not overwrite:\n            if verbose:\n                c.print(f\"File already exists: {file_path}\", color=\"yellow\")\n            return {\n                \"success\": False,\n                \"file_path\": file_path,\n                \"message\": f\"File already exists and overwrite is False\"\n            }\n        \n        # Create parent directories if needed\n        parent_dir = os.path.dirname(file_path)\n        if create_parent_dirs and parent_dir and not os.path.exists(parent_dir):\n            try:\n                ensure_directory_exists(parent_dir)\n                if verbose:\n                    c.print(f\"Created parent directory: {parent_dir}\", color=\"blue\")\n            except Exception as e:\n                if verbose:\n                    c.print(f\"Failed to create parent directory: {str(e)}\", color=\"red\")\n                return {\n                    \"success\": False,\n                    \"file_path\": file_path,\n                    \"message\": f\"Failed to create parent directory: {str(e)}\"\n                }\n        \n        # Write content to file\n        try:\n            put_text(file_path, content)\n            if verbose:\n                c.print(f\"Successfully created file: {file_path}\", color=\"green\")\n            return {\n                \"success\": True,\n                \"file_path\": file_path,\n                \"message\": \"File created successfully\"\n            }\n        except Exception as e:\n            if verbose:\n                c.print(f\"Failed to create file: {str(e)}\", color=\"red\")\n            return {\n                \"success\": False,\n                \"file_path\": file_path,\n                \"message\": f\"Failed to create file: {str(e)}\"\n            }\n    \n    \n",
        "delete_file.py": "\nimport commune as c\nimport os\nimport shutil\nfrom typing import Dict, Any, Optional, Union\nfrom ..utils import abspath\n\nclass DeleteFile:\n    \"\"\"\n    A utility tool for deleting files and directories at specified paths.\n    \n    This class provides functionality to:\n    - Delete individual files\n    - Optionally delete directories (recursively or not)\n    - Implement safety checks before deletion\n    - Provide feedback on the operation\n    \"\"\"\n    \n    def __init__(self, **kwargs):\n        \"\"\"\n        Initialize the DeleteFile tool.\n        \n        Args:\n            **kwargs: Additional configuration parameters\n        \"\"\"\n        pass\n    \n    def forward(self, \n                path: str, \n                recursive: bool = False,\n                force: bool = False,\n                allow_dir: bool = False,\n                verbose: bool = True) -> Dict[str, Any]:\n        \"\"\"\n        Delete a file or directory at the specified path.\n        \n        Args:\n            path: Path to the file or directory to delete\n            recursive: Whether to recursively delete directories (only applies if allow_dir=True)\n            force: Whether to ignore non-existent files\n            allow_dir: Whether to allow directory deletion\n            verbose: Print detailed information about the operation\n            \n        Returns:\n            Dictionary with operation results including:\n            - success: Whether the operation was successful\n            - path: Path that was targeted for deletion\n            - message: Description of the operation result\n        \"\"\"\n        path = abspath(path)\n        \n        # Check if path exists\n        if not os.path.exists(path):\n            if force:\n                if verbose:\n                    c.print(f\"Path does not exist, but force=True: {path}\", color=\"yellow\")\n                return {\n                    \"success\": True,\n                    \"path\": path,\n                    \"message\": \"Path does not exist, but operation considered successful due to force=True\"\n                }\n            else:\n                if verbose:\n                    c.print(f\"Path does not exist: {path}\", color=\"red\")\n                return {\n                    \"success\": False,\n                    \"path\": path,\n                    \"message\": \"Path does not exist\"\n                }\n        \n        # Handle directory deletion\n        if os.path.isdir(path):\n            if not allow_dir:\n                if verbose:\n                    c.print(f\"Path is a directory but allow_dir=False: {path}\", color=\"red\")\n                return {\n                    \"success\": False,\n                    \"path\": path,\n                    \"message\": \"Path is a directory but allow_dir=False\"\n                }\n            \n            try:\n                if recursive:\n                    shutil.rmtree(path)\n                    if verbose:\n                        c.print(f\"Successfully deleted directory recursively: {path}\", color=\"green\")\n                    return {\n                        \"success\": True,\n                        \"path\": path,\n                        \"message\": \"Directory deleted recursively\"\n                    }\n                else:\n                    os.rmdir(path)\n                    if verbose:\n                        c.print(f\"Successfully deleted empty directory: {path}\", color=\"green\")\n                    return {\n                        \"success\": True,\n                        \"path\": path,\n                        \"message\": \"Empty directory deleted\"\n                    }\n            except OSError as e:\n                if not recursive and len(os.listdir(path)) > 0:\n                    if verbose:\n                        c.print(f\"Cannot delete non-empty directory without recursive=True: {path}\", color=\"red\")\n                    return {\n                        \"success\": False,\n                        \"path\": path,\n                        \"message\": \"Cannot delete non-empty directory without recursive=True\"\n                    }\n                if verbose:\n                    c.print(f\"Failed to delete directory: {str(e)}\", color=\"red\")\n                return {\n                    \"success\": False,\n                    \"path\": path,\n                    \"message\": f\"Failed to delete directory: {str(e)}\"\n                }\n        \n        # Handle file deletion\n        try:\n            os.remove(path)\n            if verbose:\n                c.print(f\"Successfully deleted file: {path}\", color=\"green\")\n            return {\n                \"success\": True,\n                \"path\": path,\n                \"message\": \"File deleted successfully\"\n            }\n        except Exception as e:\n            if verbose:\n                c.print(f\"Failed to delete file: {str(e)}\", color=\"red\")\n            return {\n                \"success\": False,\n                \"path\": path,\n                \"message\": f\"Failed to delete file: {str(e)}\"\n            }\n",
        "insert_text.py": "\nimport commune as c\nimport os\nimport re\nfrom typing import Dict, List, Union, Optional, Any\nfrom ..utils import get_text, put_text, abspath\nprint = c.print\nclass Insert:\n    \"\"\"\n    A utility tool for inserting text between specified anchor points in files.\n    \n    This class provides functionality to:\n    - Find anchor points in files\n    - Insert new content between those anchor points\n    - Replace existing content between anchor points\n    - Preserve the original file structure\n    - Handle multiple insertions in a single operation\n    \"\"\"\n    \n    def __init__(self, cache_dir: str = '~/.commune/insert_cache', **kwargs):\n        \"\"\"\n        Initialize the Insert tool.\n        \n        Args:\n            cache_dir: Directory to store cache files if needed\n            **kwargs: Additional configuration parameters\n        \"\"\"\n        self.cache_dir = abspath(cache_dir)\n        if not os.path.exists(self.cache_dir):\n            os.makedirs(self.cache_dir, exist_ok=True)\n    \n    def forward(self, \n                file_path: str, \n                new_content: str,\n                start_anchor: str,\n                end_anchor: str,\n                create_if_missing: bool = False,\n                backup: bool = True,\n                verbose: bool = True) -> Dict[str, Any]:\n        \"\"\"\n        Insert content between two anchor points in a file.\n        \n        Args:\n            file_path: Path to the target file\n            new_content: Content to insert between the anchors\n            start_anchor: Text marking the beginning of the insertion point\n            end_anchor: Text marking the end of the insertion point\n            create_if_missing: Create the file with anchors if it doesn't exist\n            backup: Create a backup of the original file before modifying\n            verbose: Print detailed information about the operation\n            \n        Returns:\n            Dictionary with operation results including:\n            - success: Whether the operation was successful\n            - file_path: Path to the modified file\n            - backup_path: Path to the backup file (if created)\n            - message: Description of the operation result\n        \"\"\"\n        file_path = abspath(file_path)\n        \n        # Check if file exists\n        if not os.path.exists(file_path):\n            if not create_if_missing:\n                if verbose:\n                    print(f\"File not found: {file_path}\", color=\"red\")\n                return {\n                    \"success\": False,\n                    \"file_path\": file_path,\n                    \"message\": f\"File not found and create_if_missing is False\"\n                }\n            else:\n                # Create new file with anchors and content\n                content = f\"{start_anchor}\\n{new_content}\\n{end_anchor}\"\n                put_text(file_path, content)\n                if verbose:\n                    print(f\"Created new file with content: {file_path}\", color=\"green\")\n                return {\n                    \"success\": True,\n                    \"file_path\": file_path,\n                    \"message\": \"Created new file with anchors and content\"\n                }\n        \n        # Read the original content\n        original_content = get_text(file_path)\n        if original_content is None:\n            if verbose:\n                print(f\"Could not read file: {file_path}\", color=\"red\")\n            return {\n                \"success\": False,\n                \"file_path\": file_path,\n                \"message\": \"Could not read file content\"\n            }\n        \n        # Create backup if requested\n        backup_path = None\n        if backup:\n            backup_path = f\"{file_path}.bak\"\n            put_text(backup_path, original_content)\n            if verbose:\n                print(f\"Created backup: {backup_path}\", color=\"blue\")\n        \n        # Find the anchor points\n        pattern = re.escape(start_anchor) + r\"(.*?)\" + re.escape(end_anchor)\n        match = re.search(pattern, original_content, re.DOTALL)\n        \n        if match:\n            # Replace content between anchors\n            new_file_content = original_content.replace(\n                f\"{start_anchor}{match.group(1)}{end_anchor}\",\n                f\"{start_anchor}\\n{new_content}\\n{end_anchor}\"\n            )\n            if verbose:\n                print(f\"Found anchors and replacing content\", color=\"green\")\n        else:\n            # Anchors not found - append to end of file\n            if verbose:\n                print(f\"Anchors not found in file, appending to end\", color=\"yellow\")\n            new_file_content = f\"{original_content}\\n\\n{start_anchor}\\n{new_content}\\n{end_anchor}\"\n        \n        # Write the modified content\n        put_text(file_path, new_file_content)\n        \n        if verbose:\n            print(f\"Successfully inserted content in: {file_path}\", color=\"green\")\n        \n        return {\n            \"success\": True,\n            \"file_path\": file_path,\n            \"backup_path\": backup_path,\n            \"message\": \"Successfully inserted content between anchors\"\n        }\n    ",
        "memory/README.md": "\n# Memory Tool\n\nA flexible memory management system for AI applications that provides both short-term and long-term memory capabilities.\n\n## Features\n\n- **Short-term Memory**: In-memory storage with automatic expiration\n- **Long-term Memory**: Persistent file-based storage\n- **Relevance Filtering**: Find memories most relevant to a query\n- **Memory Management**: Automatic cleanup of expired items\n- **Memory Search**: Search through stored memories\n- **Memory Summarization**: Generate summaries of stored memories\n\n## Usage\n\n```python\nimport commune as c\n\n# Initialize the memory tool\nmemory = c.module('dev.tool.memory')()\n\n# Store information in short-term memory (expires after default TTL)\nmemory.add_short_term(\"user_preference\", {\"theme\": \"dark\", \"language\": \"python\"})\n\n# Store information in long-term memory (persistent)\nmemory.add_long_term(\"project_requirements\", {\n    \"name\": \"AI Assistant\",\n    \"features\": [\"code generation\", \"memory management\", \"file editing\"]\n})\n\n# Retrieve memories\nuser_pref = memory.get_short_term(\"user_preference\")\nrequirements = memory.get_long_term(\"project_requirements\")\n\n# Filter a list of items by relevance to a query\nfiles = [\"main.py\", \"utils.py\", \"memory.py\", \"database.py\"]\nrelevant_files = memory.forward(files, query=\"memory management\", n=2)\n# Returns: [\"memory.py\", \"utils.py\"]\n\n# Search long-term memory\nrelevant_memories = memory.search_long_term(\"project features\")\n\n# Generate a summary of memories\nsummary = memory.summarize_memories(query=\"user preferences\")\n```\n\n## Integration with Dev Module\n\nThe Memory tool is designed to work seamlessly with the Dev module:\n\n```python\ndev = c.module('dev')()\ndev.set_memory(c.module('dev.tool.memory')())\n\n# Now Dev will use the memory tool to maintain context\n```\n\n## Advanced Features\n\n### Memory Eviction Policies\n\nWhen short-term memory reaches capacity, items are evicted using a Least Recently Used (LRU) strategy.\n\n### Memory Persistence\n\nLong-term memories are stored as JSON files in the specified directory (default: `~/.commune/memory/long_term`).\n\n### Relevance Scoring\n\nThe tool uses LLM-based relevance scoring to find the most relevant memories for a given query.\n",
        "memory/memory.py": "\nimport commune as c\nimport os\nimport json\nimport time\nfrom typing import Dict, List, Any, Optional, Union\nfrom pathlib import Path\n\nclass Memory:\n    \"\"\"\n    A memory management tool that provides both short-term and long-term memory capabilities.\n    \n    This tool helps maintain context across interactions by:\n    - Storing temporary information in short-term memory (in-memory)\n    - Persisting important information in long-term memory (file-based)\n    - Retrieving and filtering memories based on relevance\n    - Managing memory expiration and prioritization\n    \"\"\"\n    \n    def __init__(\n        self,\n        long_term_path: str = \"~/.commune/memory/long_term\",\n        short_term_capacity: int = 100,\n        default_ttl: int = 3600,  # 1 hour default TTL for short-term memory\n        model: str = 'dev.model.openrouter',\n        **kwargs\n    ):\n        \"\"\"\n        Initialize the Memory module.\n        \n        Args:\n            long_term_path: Path to store long-term memories\n            short_term_capacity: Maximum number of items in short-term memory\n            default_ttl: Default time-to-live for short-term memories (in seconds)\n            model: Model to use for relevance scoring\n            **kwargs: Additional arguments to pass to the model\n        \"\"\"\n        self.model = c.module(model)(**kwargs)\n        self.long_term_path = os.path.expanduser(long_term_path)\n        self.short_term_capacity = short_term_capacity\n        self.default_ttl = default_ttl\n        \n        # Initialize memory stores\n        self.short_term = {}  # {key: {'data': Any, 'timestamp': float, 'ttl': int}}\n        \n        # Ensure long-term storage directory exists\n        os.makedirs(self.long_term_path, exist_ok=True)\n        \n    def add_short_term(\n        self, \n        key: str, \n        data: Any, \n        ttl: Optional[int] = None\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Add an item to short-term memory.\n        \n        Args:\n            key: Unique identifier for the memory\n            data: Data to store\n            ttl: Time-to-live in seconds (None for default)\n            \n        Returns:\n            Dictionary with status and info about the stored memory\n        \"\"\"\n        # Clean expired items first\n        self._clean_expired_short_term()\n        \n        # Check capacity\n        if len(self.short_term) >= self.short_term_capacity:\n            self._evict_short_term()\n            \n        # Store with timestamp\n        self.short_term[key] = {\n            'data': data,\n            'timestamp': time.time(),\n            'ttl': ttl if ttl is not None else self.default_ttl\n        }\n        \n        return {\n            'status': 'success',\n            'key': key,\n            'ttl': ttl if ttl is not None else self.default_ttl,\n            'expires_at': time.time() + (ttl if ttl is not None else self.default_ttl)\n        }\n    \n    def get_short_term(self, key: str) -> Optional[Any]:\n        \"\"\"\n        Retrieve an item from short-term memory.\n        \n        Args:\n            key: Key of the memory to retrieve\n            \n        Returns:\n            The stored data or None if not found or expired\n        \"\"\"\n        # Clean expired items first\n        self._clean_expired_short_term()\n        \n        if key in self.short_term:\n            # Update access timestamp (keeps frequently accessed items alive)\n            self.short_term[key]['timestamp'] = time.time()\n            return self.short_term[key]['data']\n        \n        return None\n    \n    def add_long_term(self, key: str, data: Any) -> Dict[str, Any]:\n        \"\"\"\n        Add an item to long-term memory.\n        \n        Args:\n            key: Unique identifier for the memory\n            data: Data to store\n            \n        Returns:\n            Dictionary with status and info about the stored memory\n        \"\"\"\n        # Sanitize key for filename\n        safe_key = self._sanitize_key(key)\n        file_path = os.path.join(self.long_term_path, f\"{safe_key}.json\")\n        \n        memory_data = {\n            'data': data,\n            'timestamp': time.time(),\n            'metadata': {\n                'created_at': time.time(),\n                'key': key,\n                'type': type(data).__name__\n            }\n        }\n        \n        try:\n            with open(file_path, 'w') as f:\n                json.dump(memory_data, f, indent=2)\n                \n            return {\n                'status': 'success',\n                'key': key,\n                'path': file_path\n            }\n        except Exception as e:\n            return {\n                'status': 'error',\n                'key': key,\n                'error': str(e)\n            }\n    \n    def get_long_term(self, key: str) -> Optional[Any]:\n        \"\"\"\n        Retrieve an item from long-term memory.\n        \n        Args:\n            key: Key of the memory to retrieve\n            \n        Returns:\n            The stored data or None if not found\n        \"\"\"\n        safe_key = self._sanitize_key(key)\n        file_path = os.path.join(self.long_term_path, f\"{safe_key}.json\")\n        \n        if os.path.exists(file_path):\n            try:\n                with open(file_path, 'r') as f:\n                    memory_data = json.load(f)\n                return memory_data['data']\n            except Exception:\n                return None\n        \n        return None\n    \n    def list_memories(\n        self, \n        memory_type: str = 'all'\n    ) -> Dict[str, List[str]]:\n        \"\"\"\n        List available memories.\n        \n        Args:\n            memory_type: Type of memories to list ('short', 'long', or 'all')\n            \n        Returns:\n            Dictionary with lists of memory keys\n        \"\"\"\n        result = {'short_term': [], 'long_term': []}\n        \n        # Clean expired items first\n        self._clean_expired_short_term()\n        \n        if memory_type in ['short', 'all']:\n            result['short_term'] = list(self.short_term.keys())\n            \n        if memory_type in ['long', 'all']:\n            try:\n                files = os.listdir(self.long_term_path)\n                result['long_term'] = [\n                    os.path.splitext(f)[0] for f in files \n                    if f.endswith('.json')\n                ]\n            except Exception:\n                result['long_term'] = []\n                \n        return result\n    \n    def delete_memory(\n        self, \n        key: str, \n        memory_type: str = 'all'\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Delete a memory.\n        \n        Args:\n            key: Key of the memory to delete\n            memory_type: Type of memory to delete ('short', 'long', or 'all')\n            \n        Returns:\n            Dictionary with deletion status\n        \"\"\"\n        result = {'status': 'success', 'deleted': []}\n        \n        if memory_type in ['short', 'all']:\n            if key in self.short_term:\n                del self.short_term[key]\n                result['deleted'].append('short_term')\n                \n        if memory_type in ['long', 'all']:\n            safe_key = self._sanitize_key(key)\n            file_path = os.path.join(self.long_term_path, f\"{safe_key}.json\")\n            \n            if os.path.exists(file_path):\n                try:\n                    os.remove(file_path)\n                    result['deleted'].append('long_term')\n                except Exception as e:\n                    result['status'] = 'partial'\n                    result['error'] = str(e)\n        \n        if not result['deleted']:\n            result['status'] = 'not_found'\n            \n        return result\n    \n    def forward(\n        self, \n        data: Union[List[str], Dict[str, Any], str],\n        query: str = None,\n        n: int = 5,\n        memory_type: str = 'short',\n        store: bool = True,\n        key: str = None,\n        **kwargs\n    ) -> Union[List[str], Dict[str, Any], str]:\n        \"\"\"\n        Process data through memory, optionally storing it and retrieving\n        relevant items based on a query.\n        \n        Args:\n            data: Data to process (can be a list, dict, or string)\n            query: Optional query to filter/retrieve relevant memories\n            n: Number of items to return when filtering\n            memory_type: Where to store/retrieve from ('short' or 'long')\n            store: Whether to store the data in memory\n            key: Optional key for storing (generated if not provided)\n            **kwargs: Additional arguments for the model\n            \n        Returns:\n            Processed data, potentially filtered by relevance to query\n        \"\"\"\n        # Generate a key if not provided\n        if store and key is None:\n            if isinstance(data, str):\n                key = f\"mem_{hash(data) & 0xffffffff}\"\n            else:\n                key = f\"mem_{int(time.time())}_{hash(str(data)) & 0xffffffff}\"\n        \n        # Store the data if requested\n        if store:\n            if memory_type == 'short':\n                self.add_short_term(key, data)\n            else:\n                self.add_long_term(key, data)\n        \n        # If there's a query, filter the data by relevance\n        if query and isinstance(data, list):\n            return self._filter_by_relevance(data, query, n, **kwargs)\n        \n        return data\n    \n    def _filter_by_relevance(\n        self, \n        items: List[Any], \n        query: str, \n        n: int = 5,\n        **kwargs\n    ) -> List[Any]:\n        \"\"\"\n        Filter a list of items by relevance to a query.\n        \n        Args:\n            items: List of items to filter\n            query: Query to compare against\n            n: Maximum number of items to return\n            **kwargs: Additional arguments for the model\n            \n        Returns:\n            List of most relevant items\n        \"\"\"\n        if not items:\n            return []\n        \n        # For simple string items, we can use the model to score relevance\n        if all(isinstance(item, str) for item in items):\n            # Prepare the prompt for relevance scoring\n            prompt = str({\n                \"task\": \"Rank these items by relevance to the query and return the top N most relevant items.\",\n                \"query\": query,\n                \"items\": items,\n                \"n\": n,\n                \"format\": \"Return a JSON array of the most relevant items in order of relevance.\"\n            })\n            \n            try:\n                # Get relevance scores from model\n                result = self.model.forward(prompt, **kwargs)\n                \n                # Parse the result - expecting a JSON array\n                import re\n                json_match = re.search(r'\\[.*\\]', result, re.DOTALL)\n                if json_match:\n                    try:\n                        relevant_items = json.loads(json_match.group(0))\n                        # Ensure we only return items that were in the original list\n                        return [item for item in relevant_items if item in items][:n]\n                    except json.JSONDecodeError:\n                        pass\n            except Exception as e:\n                c.print(f\"Error in relevance filtering: {e}\", color=\"red\")\n        \n        # Fallback: return first n items\n        return items[:n]\n    \n    def _clean_expired_short_term(self) -> int:\n        \"\"\"\n        Remove expired items from short-term memory.\n        \n        Returns:\n            Number of items removed\n        \"\"\"\n        now = time.time()\n        expired_keys = [\n            key for key, value in self.short_term.items()\n            if now > value['timestamp'] + value['ttl']\n        ]\n        \n        for key in expired_keys:\n            del self.short_term[key]\n            \n        return len(expired_keys)\n    \n    def _evict_short_term(self) -> None:\n        \"\"\"\n        Evict items from short-term memory when capacity is reached.\n        Uses LRU (Least Recently Used) strategy.\n        \"\"\"\n        if not self.short_term:\n            return\n            \n        # Find oldest item by timestamp\n        oldest_key = min(\n            self.short_term.keys(),\n            key=lambda k: self.short_term[k]['timestamp']\n        )\n        \n        # Remove it\n        del self.short_term[oldest_key]\n    \n    def _sanitize_key(self, key: str) -> str:\n        \"\"\"\n        Sanitize a key for use as a filename.\n        \n        Args:\n            key: Key to sanitize\n            \n        Returns:\n            Sanitized key\n        \"\"\"\n        # Replace invalid filename characters\n        import re\n        return re.sub(r'[^\\w\\-\\.]', '_', str(key))\n    \n    def search_long_term(\n        self, \n        query: str, \n        n: int = 5,\n        **kwargs\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search long-term memory for relevant items.\n        \n        Args:\n            query: Search query\n            n: Maximum number of items to return\n            **kwargs: Additional arguments for the model\n            \n        Returns:\n            List of relevant memory items with metadata\n        \"\"\"\n        # Get all long-term memories\n        memories = []\n        try:\n            files = os.listdir(self.long_term_path)\n            for filename in files:\n                if filename.endswith('.json'):\n                    file_path = os.path.join(self.long_term_path, filename)\n                    try:\n                        with open(file_path, 'r') as f:\n                            memory_data = json.load(f)\n                            memories.append({\n                                'key': os.path.splitext(filename)[0],\n                                'data': memory_data['data'],\n                                'timestamp': memory_data['timestamp'],\n                                'metadata': memory_data.get('metadata', {})\n                            })\n                    except Exception:\n                        continue\n        except Exception as e:\n            c.print(f\"Error searching long-term memory: {e}\", color=\"red\")\n            return []\n        \n        if not memories:\n            return []\n            \n        # Use the model to rank memories by relevance\n        memory_texts = [\n            f\"Memory {i}: {str(mem['data'])[:500]}\" \n            for i, mem in enumerate(memories)\n        ]\n        \n        prompt = str({\n            \"task\": \"Rank these memory items by relevance to the query and return the indices of the top N most relevant items in order.\",\n            \"query\": query,\n            \"memory_items\": memory_texts,\n            \"n\": n,\n            \"format\": \"Return a JSON array of indices, e.g. [2, 5, 0]\"\n        })\n        \n        try:\n            result = self.model.forward(prompt, **kwargs)\n            \n            # Parse the result - expecting a JSON array of indices\n            import re\n            json_match = re.search(r'\\[.*\\]', result, re.DOTALL)\n            if json_match:\n                try:\n                    indices = json.loads(json_match.group(0))\n                    # Return the memories in order of relevance\n                    return [memories[i] for i in indices if i < len(memories)]\n                except (json.JSONDecodeError, TypeError, IndexError):\n                    pass\n        except Exception as e:\n            c.print(f\"Error in relevance ranking: {e}\", color=\"red\")\n        \n        # Fallback: return most recent memories\n        memories.sort(key=lambda x: x['timestamp'], reverse=True)\n        return memories[:n]\n    \n    def summarize_memories(\n        self, \n        query: Optional[str] = None, \n        memory_type: str = 'all',\n        **kwargs\n    ) -> str:\n        \"\"\"\n        Generate a summary of relevant memories.\n        \n        Args:\n            query: Optional query to filter relevant memories\n            memory_type: Type of memories to summarize ('short', 'long', or 'all')\n            **kwargs: Additional arguments for the model\n            \n        Returns:\n            Summary text\n        \"\"\"\n        memories = []\n        \n        # Collect short-term memories if requested\n        if memory_type in ['short', 'all']:\n            self._clean_expired_short_term()\n            for key, value in self.short_term.items():\n                memories.append({\n                    'key': key,\n                    'data': value['data'],\n                    'source': 'short_term',\n                    'timestamp': value['timestamp']\n                })\n        \n        # Collect long-term memories if requested\n        if memory_type in ['long', 'all']:\n            long_term_memories = self.search_long_term(\n                query if query else \"recent important information\", \n                n=10,\n                **kwargs\n            )\n            for mem in long_term_memories:\n                memories.append({\n                    'key': mem['key'],\n                    'data': mem['data'],\n                    'source': 'long_term',\n                    'timestamp': mem['timestamp']\n                })\n        \n        if not memories:\n            return \"No memories available.\"\n        \n        # Sort by timestamp (newest first)\n        memories.sort(key=lambda x: x['timestamp'], reverse=True)\n        \n        # Filter by relevance if query provided\n        if query:\n            memory_texts = [\n                f\"Memory {i} ({mem['source']}): {str(mem['data'])[:500]}\" \n                for i, mem in enumerate(memories)\n            ]\n            \n            prompt = str({\n                \"task\": \"Filter these memory items by relevance to the query and return the indices of relevant items.\",\n                \"query\": query,\n                \"memory_items\": memory_texts,\n                \"format\": \"Return a JSON array of indices, e.g. [2, 5, 0]\"\n            })\n            \n            try:\n                result = self.model.forward(prompt, **kwargs)\n                \n                # Parse the result\n                import re\n                json_match = re.search(r'\\[.*\\]', result, re.DOTALL)\n                if json_match:\n                    try:\n                        indices = json.loads(json_match.group(0))\n                        memories = [memories[i] for i in indices if i < len(memories)]\n                    except (json.JSONDecodeError, TypeError, IndexError):\n                        pass\n            except Exception:\n                pass\n        \n        # Generate summary\n        memory_texts = [\n            f\"Memory {i+1} ({mem['source']}): {str(mem['data'])}\" \n            for i, mem in enumerate(memories)\n        ]\n        \n        prompt = str({\n            \"task\": \"Summarize these memory items into a coherent summary.\",\n            \"memory_items\": memory_texts,\n            \"query\": query if query else \"Summarize recent important information\",\n            \"format\": \"Return a concise summary that captures the key information.\"\n        })\n        \n        try:\n            summary = self.model.forward(prompt, **kwargs)\n            return summary\n        except Exception as e:\n            return f\"Error generating summary: {e}\"\n",
        "select_files.py": "\nimport commune as c\nimport json\nimport os\nfrom typing import List, Dict, Union, Optional, Any\n\nprint = c.print\nclass SelectFiles:\n    \"\"\"\n    Advanced search and relevance ranking module powered by LLMs.\n    \n    This module helps find the most relevant items from a list of options based on a query,\n    using LLM-based semantic understanding to rank and filter options.\n    \"\"\"\n\n    def __init__(self, provider='dev.model.openrouter'):\n        \"\"\"\n        Initialize the Find module.\n        \n        Args:\n            model: Pre-initialized model instance (optional)\n            default_provider: Provider to use if no model is provided\n            default_model: Default model to use for ranking\n        \"\"\"\n        self.model = c.module(provider)()\n\n    def forward(self,  \n              query: str = 'most relevant', \n              path: Union[List[str], Dict[Any, str]] = './',  \n              n: int = 10,  \n              trials: int = 3,\n              min_score: int = 0,\n              max_score: int = 10,\n              threshold: int = 5,\n              model: str = None,\n              context: Optional[str] = None,\n              temperature: float = 0.5,\n              allow_selection: bool = False,\n              verbose: bool = True) -> List[str]:\n        \"\"\"\n        Find the most relevant options based on a query.\n        \n        Args:\n            options: List of options or dictionary of options\n            query: Search query to match against options\n            n: Maximum number of results to return\n            trials: Number of retry attempts if an error occurs\n            min_score: Minimum possible score\n            max_score: Maximum possible score\n            threshold: Minimum score required to include in results\n            model: Model to use for ranking\n            context: Additional context to help with ranking\n            temperature: Temperature for generation (lower = more deterministic)\n            allow_selection: Whether to allow user to select files by index\n            verbose: Whether to print output during generation\n            \n        Returns:\n            List of the most relevant options\n        \"\"\"\n        \n\n        anchors = [\"<START_JSON>\", \"</END_JSON>\"]\n        options = self.files(path)\n        home_path = os.path.expanduser(\"~\")\n        idx2options = {i: option.replace(home_path, '~') for i, option in enumerate(options)}\n        if not idx2options:\n            return []\n           \n        # Format context if provided\n        context_str = f\"\\nCONTEXT:\\n{context}\" if context else \"\"\n        \n        # Build the prompt\n\n        prompt = f'''\n        --QUERY--\n        {query}\n        {context_str}\n        --OPTIONS--\n        {idx2options} \n        --RULES--\n        - Evaluate each option based on its relevance to the query\n        - Return at most {n} options with their scores\n        - Score range: {min_score} (lowest) to {max_score} (highest)\n        - Only include options with scores >= {threshold}\n        - Be conservative with scoring to prioritize quality over quantity\n        - Respond ONLY with the JSON format specified below\n        --OUTPUT_FORMAT--\n        {anchors[0]}(data:(idx:INT, score:INT)]){anchors[1]}\n        '''\n        \n        # Generate the response\n        output = ''\n\n        response = self.model.forward( \n            prompt, \n            model=model, \n            stream=True,\n            temperature=temperature\n        )\n        for ch in response: \n            if verbose:\n                print(ch, end='')\n            output += ch\n            if anchors[1] in output:\n                break\n                \n        # Extract and parse the JSON\n        try:\n            if anchors[0] in output:\n                json_str = output.split(anchors[0])[1].split(anchors[1])[0]\n            else:\n                json_str = output\n                \n            if verbose:\n                print(\"\\nParsing response...\", color=\"cyan\")\n                \n            result = json.loads(json_str)\n            \n            # Validate the response structure\n            if not isinstance(result, dict) or \"data\" not in result:\n                if verbose:\n                    print(\"Invalid response format, missing 'data' field\", color=\"red\")\n                result = {\"data\": []}\n                \n            # Filter and convert to final output format\n            filtered_options = []\n            for item in result[\"data\"]:\n                if isinstance(item, dict) and \"idx\" in item and \"score\" in item:\n                    idx, score = item[\"idx\"], item[\"score\"]\n                    if score >= threshold and idx in idx2options:\n                        filtered_options.append((idx, idx2options[idx]))         \n            if verbose:\n                print(f\"Found {filtered_options} relevant options\", color=\"green\")\n            # Allow user to select files by index if requested\n            if allow_selection and filtered_options:\n                selected_options = self.select_by_index(filtered_options, verbose)\n                return [option[1] for option in selected_options]\n            return [os.path.expanduser(option[1]) for option in filtered_options]\n            \n        except json.JSONDecodeError as e:\n            if verbose:\n                print(f\"JSON parsing error: {e}\", color=\"red\")\n                print(f\"Raw output: {output}\", color=\"red\")\n            if trials > 0:\n                print(f\"Retrying... ({trials} attempts left)\", color=\"yellow\")\n                return self.forward(options, query, n, trials - 1, min_score, max_score, threshold, model, context, temperature, allow_selection, verbose)\n            raise ValueError(f\"Failed to parse LLM response as JSON: {e}\")\n    \n    def select_by_index(self, options, verbose=True):\n        \"\"\"\n        Allow user to select files by index from a list of options.\n        \n        Args:\n            options: List of tuples containing (idx, option)\n            verbose: Whether to print output during selection\n            \n        Returns:\n            List of selected options\n        \"\"\"\n        if verbose:\n            print(\"\\nSelect files by index (comma-separated, e.g. '0,2,3')\", color=\"yellow\")\n            print(\"Press Enter to accept all files, or Ctrl+C to cancel\", color=\"yellow\")\n            \n        # Display options with indices\n        for i, (idx, option) in enumerate(options):\n            print(f\"[{i}] {option}\", color=\"cyan\")\n        \n        try:\n            # Get user input\n            selection = input(\"\\nEnter indices of files to select: \")\n            \n            # If empty, select all\n            if not selection.strip():\n                if verbose:\n                    print(\"Selecting all files\", color=\"green\")\n                return options\n            \n            # Parse selection\n            selected_indices = [int(idx.strip()) for idx in selection.split(',') if idx.strip().isdigit()]\n            selected_options = [options[idx] for idx in selected_indices if 0 <= idx < len(options)]\n            \n            if verbose:\n                print(f\"Selected {len(selected_options)} files\", color=\"green\")\n            \n            return selected_options\n            \n        except (KeyboardInterrupt, EOFError):\n            # Handle keyboard interrupt (Ctrl+C) or EOF\n            if verbose:\n                print(\"\\nSelection cancelled, defaulting to all files\", color=\"yellow\")\n            return options\n        except Exception as e:\n            # Handle any other errors\n            if verbose:\n                print(f\"\\nError during selection: {e}\", color=\"red\")\n                print(\"Defaulting to all files\", color=\"yellow\")\n            return options\n\n    def files(self, path: str) -> List[str]:\n        return c.files(path)",
        "summarize.py": "\nimport commune as c\nimport json\nimport os\nfrom typing import List, Dict, Union, Optional, Any\n\nprint = c.print\nclass Summarize:\n    \"\"\"\n    Advanced search and relevance ranking module powered by LLMs.\n    \n    This module helps find the most relevant items from a list of options based on a query,\n    using LLM-based semantic understanding to rank and filter options.\n    \"\"\"\n\n    \n    def __init__(self, provider='dev.model.openrouter'):\n        \"\"\"\n        Initialize the Find module.\n        \n        Args:\n            model: Pre-initialized model instance (optional)\n            default_provider: Provider to use if no model is provided\n            default_model: Default model to use for ranking\n        \"\"\"\n        self.model = c.module(provider)()\n        self.anchors = [\"<START_JSON>\", \"</END_JSON>\"]\n\n    def forward(self,  \n              path: str = __file__, # Path to the file containing options or a file  \n              query: str = 'most relevant', \n              model: str = None,\n              temperature: float = 0.5,\n              task = None,\n              verbose: bool = True) -> List[str]:\n        anchors = self.anchors\n        # Format context if provided\n        assert os.path.exists(path), f\"File not found: {path}\"\n        assert os.path.isfile(path), f\"Path is not a file: {path}\"\n        content = c.text(path)\n\n        # hash\n        cache_path = 'reuslts/' + c.hash(path)\n\n        # Build the prompt\n\n        prompt = f'''\n        TASK\n        - summarize the follwoing based on the format based on the wquery \n        - query --> {query}\n        CONTENT\n        {content} \n        RESULT_FORMAT\n        {anchors[0]}(LIST(DICT(obj:str, desc:str))){anchors[1]}\n        '''\n        \n        # Generate the response\n        output = ''\n        response = self.model.forward( \n            prompt, \n            model=model, \n            stream=True,\n            temperature=temperature\n        )\n\n        # PROCEESS THE REPSONSE \n        for ch in response: \n            if verbose:\n                print(ch, end='')\n            output += ch\n\n        output = anchors[0].join(output.split(anchors[0])[1:])\n        output = anchors[1].join(output.split(anchors[1])[:-1])\n        if verbose:\n            print(\"\\nParsing response...\", color=\"cyan\")\n            \n        result =   json.loads(output)\n    \n        return result\n",
        "tool.py": "\nimport commune as c\nimport json\nimport os\nfrom typing import List, Dict, Union, Optional, Any\nimport importlib\nimport inspect\n\nprint = c.print\n\nclass Tool:\n\n\n    fn = 'forward'\n    \"\"\"\n    A toolbox that provides access to various tools and can intelligently select\n    the most appropriate tool based on a query.\n    \n    This module helps organize and access tools within the dev.tool namespace,\n    with the ability to automatically select the most relevant tool for a given task.\n    \"\"\"\n    def __init__(self, model='dev.model.openrouter', prefix='dev.tool'):\n\n        self.prefix = prefix\n        self.model = c.module(model)()\n\n    def forward(\n        self, \n        query: str = 'i want to edit a file of ./', \n        *extra_query,\n        tools: Optional[List[str]] = None, \n        **kwargs\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Forward the query to the appropriate tool based on the provided query.\n        \n        Args:\n            query (str): The query to be processed.\n            tools (List[str], optional): List of specific tools to consider. If None, all tools are considered.\n            **kwargs: Additional arguments to pass to the selected tool.\n        \n        Returns:\n            Dict[str, Any]: The result from the selected tool.\n        \"\"\"\n        \n        # Forward the query to the selected tool\n        prompt = self.preprocess(\" \".join([query] + list(extra_query)))\n        output  =  self.model.forward(prompt, **kwargs)\n        output = self.postprocess(output)\n        return output\n\n        \n    def preprocess(self, prompt):\n\n        selector = c.mod('dev.tool.select')()\n        tool2schema  = self.tool2schema()\n        module =  selector.forward(query=query, options=tool2schema, n=1, **kwargs)[0]['name']\n        tool_schema = c.schema(module)\n        # get the function name from the module\n        fn_name = selector.forward(query=query, options=tool_schema, n=1, **kwargs)[0]['name']\n        anchors = ['<PARAMS>', '</PARAMS>']\n        prompt = str({\n            \"query\": query,\n            \"schema\": schema[fn_name],\n            'task': 'your goal is to create a plan of selecting at least one tool to be execturd',\n            'outputformat': f\"{anchors[0]}\\nLIST(DICT(FN, PARAMS))\\n{anchors[1]}\\n\",\n        })\n\n    def postprocess(self, output):\n        return json.loads(output.split(anchors[0])[1].split(anchors[1])[0])\n\n\n    def tools(self) -> List[str]:\n        return [t for t in  c.mods() if t.startswith(self.prefix)]\n\n\n    def tool2code(self) -> str:\n        tool2schema = {\n            tool: c.schema(tool, include_code=True)\n            for tool in self.tools()\n        }\n        \n    \n    def tool2schema(self) -> Dict[str, str]:\n        \"\"\"\n        Map each tool to its schema.\n        \n        Returns:\n            Dict[str, str]: Dictionary mapping tool names to their schemas.\n        \"\"\"\n        tool2schema = {}\n        for tool in self.tools():\n            tool2schema[tool] = self.schema(tool)\n            tool2schema[tool].pop('name', None)\n            tool2schema[tool].pop('format', None)\n        return tool2schema\n    \n    def schema(self, tool: str,) -> Dict[str, str]:\n        \"\"\"\n        Get the schema for a specific tool.\n        \n        Args:\n            tool (str): The name of the tool.\n        \n        Returns:\n            Dict[str, str]: The schema for the specified tool.\n        \"\"\"\n        fn = self.fn\n        schema =  c.fnschema(getattr( c.module(tool), fn))\n        schema['input'].pop('self', None)\n        params_format = ' '.join([f'<{k.upper()}>{v[\"type\"]}</{k.upper()}>' for k,v in schema['input'].items()]) \n        fn_format = f'FN::{fn.upper()}'\n        schema['format'] =  f'<{fn_format}>' + params_format + f'</{fn_format}>'\n        return schema\n\n    def tool2code(self) -> Dict[str, str]:\n        \"\"\"\n        Map each tool to its code.\n        \n        Returns:\n            Dict[str, str]: Dictionary mapping tool names to their code.\n        \"\"\"\n        tool2code = {\n            tool: c.code(tool)\n            for tool in self.tools()\n        }\n        return tool2code\n\n    def tool2size(self) -> Dict[str, int]:\n        \"\"\"\n        Map each tool to its code size.\n        \n        Returns:\n            Dict[str, int]: Dictionary mapping tool names to their code size.\n        \"\"\"\n        tool2code_size = {\n            tool: len(c.code(tool))\n            for tool in self.tools()\n        }\n        return tool2code_size\n\n",
        "web_scraper.py": "import commune as c\nimport requests\nimport json\nimport os\nimport time\nfrom typing import List, Dict, Union, Optional, Any\nfrom bs4 import BeautifulSoup\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.chrome.service import Service\nfrom webdriver_manager.chrome import ChromeDriverManager\n\nprint = c.print\n\nclass WebScraper:\n    \"\"\"\n    A tool for scraping the web and retrieving relevant information based on queries\n    without relying on search engine APIs.\n    \n    This tool provides functionality to:\n    - Search the web using direct scraping of search engines\n    - Extract and format relevant information from search results\n    - Return context that can be used for further processing\n    - Cache results to minimize redundant requests\n    \"\"\"\n    \n    def __init__(self, \n                 search_engine: str = 'bing',\n                 cache_dir: str = '~/.commune/web_scraper_cache',\n                 cache_expiry: int = 3600,  # 1 hour\n                 use_selenium: bool = True,\n                 headless: bool = True,\n                 **kwargs):\n        \"\"\"\n        Initialize the WebScraper tool.\n        \n        Args:\n            search_engine: Search engine to use ('google', 'bing', 'duckduckgo')\n            cache_dir: Directory to store cached results\n            cache_expiry: Time in seconds before cache entries expire\n            use_selenium: Whether to use Selenium for JavaScript-heavy sites\n            headless: Whether to run browser in headless mode (Selenium only)\n            **kwargs: Additional configuration parameters\n        \"\"\"\n        self.search_engine = search_engine.lower()\n        self.cache_dir = os.path.expanduser(cache_dir)\n        self.cache_expiry = cache_expiry\n        self.use_selenium = use_selenium\n        self.headless = headless\n        self.driver = None\n        \n        # Create cache directory if it doesn't exist\n        if not os.path.exists(self.cache_dir):\n            os.makedirs(self.cache_dir, exist_ok=True)\n        \n        # Set up search engine configurations\n        self.engine_configs = {\n            'google': {\n                'search_url': 'https://www.google.com/search?q={query}&num={num_results}',\n                'result_selector': 'div.g',\n                'title_selector': 'h3',\n                'link_selector': 'a',\n                'snippet_selector': 'div.VwiC3b',\n                'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36'\n            },\n            'bing': {\n                'search_url': 'https://www.bing.com/search?q={query}&count={num_results}',\n                'result_selector': '.b_algo',\n                'title_selector': 'h2',\n                'link_selector': 'a',\n                'snippet_selector': '.b_caption p',\n                'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36'\n            },\n            'duckduckgo': {\n                'search_url': 'https://html.duckduckgo.com/html/?q={query}',\n                'result_selector': '.result',\n                'title_selector': '.result__title',\n                'link_selector': '.result__url',\n                'snippet_selector': '.result__snippet',\n                'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36'\n            }\n        }\n        \n        # Validate configuration\n        if self.search_engine not in self.engine_configs:\n            raise ValueError(f\"Unsupported search engine: {self.search_engine}. Supported engines: {list(self.engine_configs.keys())}\")\n    \n    def _initialize_selenium(self):\n        \"\"\"\n        Initialize Selenium WebDriver if not already initialized.\n        \"\"\"\n        if self.driver is not None:\n            return\n        \n        try:\n            chrome_options = Options()\n            if self.headless:\n                chrome_options.add_argument('--headless')\n            chrome_options.add_argument('--no-sandbox')\n            chrome_options.add_argument('--disable-dev-shm-usage')\n            chrome_options.add_argument(f\"user-agent={self.engine_configs[self.search_engine]['user_agent']}\")\n            \n            # Initialize Chrome WebDriver\n            service = Service(ChromeDriverManager().install())\n            self.driver = webdriver.Chrome(service=service, options=chrome_options)\n            print(\"Selenium WebDriver initialized successfully\", color=\"green\")\n        except Exception as e:\n            print(f\"Failed to initialize Selenium WebDriver: {e}\", color=\"red\")\n            self.use_selenium = False\n    \n    def _close_selenium(self):\n        \"\"\"\n        Close Selenium WebDriver if it's open.\n        \"\"\"\n        if self.driver is not None:\n            try:\n                self.driver.quit()\n            except Exception:\n                pass\n            finally:\n                self.driver = None\n    \n    def forward(self,\n                query: str,\n                num_results: int = 5,\n                include_snippets: bool = True,\n                include_links: bool = True,\n                filter_domains: Optional[List[str]] = None,\n                safe_search: bool = True,\n                use_cache: bool = False,\n                cache_key: Optional[str] = None,\n                verbose: bool = True) -> Dict[str, Any]:\n        \"\"\"\n        Search the web for information related to the query.\n        \n        Args:\n            query: Search query string\n            num_results: Number of results to return\n            include_snippets: Whether to include text snippets in results\n            include_links: Whether to include links in results\n            filter_domains: List of domains to include/exclude (e.g., ['wikipedia.org'])\n            safe_search: Whether to enable safe search filtering\n            use_cache: Whether to use cached results if available\n            cache_key: Custom key for caching (defaults to query hash)\n            verbose: Whether to print detailed information\n            \n        Returns:\n            Dictionary containing:\n            - success: Whether the search was successful\n            - results: List of search results\n            - context: Extracted context from results\n            - query: Original search query\n            - source: Search engine used\n        \"\"\"\n        if verbose:\n            c.print(f\"Searching for: {query}\", color=\"cyan\")\n        \n        # Generate cache key if not provided\n        if use_cache and not cache_key:\n            cache_key = f\"{self.search_engine}_{hash(query)}_{num_results}\"\n        \n        # Check cache first if enabled\n        if use_cache:\n            cached_result = self._get_from_cache(cache_key)\n            if cached_result:\n                if verbose:\n                    c.print(f\"Retrieved results from cache\", color=\"green\")\n                return cached_result\n        \n        try:\n            # Perform search based on engine\n            if self.use_selenium:\n                # Initialize Selenium if needed\n                self._initialize_selenium()\n                results = self._search_with_selenium(query, num_results, safe_search, filter_domains)\n            else:\n                results = self._search_with_requests(query, num_results, safe_search, filter_domains)\n            \n            # Process results\n            processed_results = []\n            for result in results:\n                processed_result = {}\n                \n                if include_links and 'link' in result:\n                    processed_result['url'] = result['link']\n                \n                if 'title' in result:\n                    processed_result['title'] = result['title']\n                \n                if include_snippets and 'snippet' in result:\n                    processed_result['snippet'] = result['snippet']\n                \n                processed_results.append(processed_result)\n            \n            # Extract context from results\n            context = self._extract_context(processed_results)\n            \n            # Prepare response\n            response = {\n                \"success\": True,\n                \"results\": processed_results,\n                \"context\": context,\n                \"query\": query,\n                \"source\": self.search_engine\n            }\n            \n            # Cache the results if enabled\n            if use_cache:\n                self._save_to_cache(cache_key, response)\n            \n            if verbose:\n                c.print(f\"Found {len(processed_results)} results\", color=\"green\")\n                if len(processed_results) > 0:\n                    c.print(\"Top result:\", color=\"blue\")\n                    c.print(f\"Title: {processed_results[0].get('title', 'N/A')}\")\n                    if include_snippets:\n                        c.print(f\"Snippet: {processed_results[0].get('snippet', 'N/A')}\")\n            \n            return response\n            \n        except Exception as e:\n            error_msg = f\"Search failed: {str(e)}\"\n            if verbose:\n                c.print(error_msg, color=\"red\")\n            \n            return {\n                \"success\": False,\n                \"error\": error_msg,\n                \"query\": query,\n                \"source\": self.search_engine\n            }\n        finally:\n            # Close Selenium if we're not caching the driver\n            if self.use_selenium and not getattr(self, 'keep_driver_alive', False):\n                self._close_selenium()\n    \n    def _search_with_selenium(self, query, num_results, safe_search, filter_domains):\n        \"\"\"\n        Perform a search using Selenium WebDriver.\n        \n        Args:\n            query: Search query\n            num_results: Number of results to return\n            safe_search: Whether to enable safe search\n            filter_domains: Domains to filter\n            \n        Returns:\n            List of search results\n        \"\"\"\n        config = self.engine_configs[self.search_engine]\n        \n        # Add domain filtering if specified\n        search_query = query\n        if filter_domains:\n            site_query = ' OR '.join([f'site:{domain}' for domain in filter_domains])\n            search_query = f\"({search_query}) {site_query}\"\n        \n        # Add safe search if enabled\n        if safe_search and self.search_engine == 'google':\n            search_query += \" &safe=active\"\n        \n        # Format the search URL\n        search_url = config['search_url'].format(query=search_query.replace(' ', '+'), num_results=num_results)\n        \n        # Navigate to the search page\n        self.driver.get(search_url)\n        time.sleep(2)  # Allow page to load\n        \n        # Extract search results\n        results = []\n        result_elements = self.driver.find_elements(By.CSS_SELECTOR, config['result_selector'])\n        \n        for element in result_elements[:num_results]:\n            try:\n                title_element = element.find_element(By.CSS_SELECTOR, config['title_selector'])\n                title = title_element.text.strip()\n                \n                link_element = title_element.find_element(By.CSS_SELECTOR, config['link_selector'])\n                link = link_element.get_attribute('href')\n                \n                snippet = \"\"\n                try:\n                    snippet_element = element.find_element(By.CSS_SELECTOR, config['snippet_selector'])\n                    snippet = snippet_element.text.strip()\n                except Exception:\n                    pass  # Snippet might not be available\n                \n                results.append({\n                    'title': title,\n                    'link': link,\n                    'snippet': snippet\n                })\n                \n                if len(results) >= num_results:\n                    break\n            except Exception as e:\n                print(f\"Error extracting result: {e}\", color=\"yellow\")\n        \n        return results\n    \n    def _search_with_requests(self, query, num_results, safe_search, filter_domains):\n        \"\"\"\n        Perform a search using requests and BeautifulSoup.\n        \n        Args:\n            query: Search query\n            num_results: Number of results to return\n            safe_search: Whether to enable safe search\n            filter_domains: Domains to filter\n            \n        Returns:\n            List of search results\n        \"\"\"\n        config = self.engine_configs[self.search_engine]\n        \n        # Add domain filtering if specified\n        search_query = query\n        if filter_domains:\n            site_query = ' OR '.join([f'site:{domain}' for domain in filter_domains])\n            search_query = f\"({search_query}) {site_query}\"\n        \n        # Add safe search if enabled\n        if safe_search and self.search_engine == 'google':\n            search_query += \" &safe=active\"\n        \n        # Format the search URL\n        search_url = config['search_url'].format(query=search_query.replace(' ', '+'), num_results=num_results)\n        \n        # Set up headers to mimic a browser\n        headers = {\n            'User-Agent': config['user_agent'],\n            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n            'Accept-Language': 'en-US,en;q=0.5',\n            'Referer': f\"https://www.{self.search_engine}.com/\",\n            'DNT': '1',\n            'Connection': 'keep-alive',\n            'Upgrade-Insecure-Requests': '1'\n        }\n        \n        # Send request\n        response = requests.get(search_url, headers=headers)\n        response.raise_for_status()\n        \n        # Parse HTML\n        soup = BeautifulSoup(response.text, 'html.parser')\n        \n        # Extract search results\n        results = []\n        result_elements = soup.select(config['result_selector'])\n        \n        for element in result_elements[:num_results]:\n            try:\n                title_element = element.select_one(config['title_selector'])\n                title = title_element.get_text().strip() if title_element else 'No title'\n                \n                link_element = title_element.select_one(config['link_selector']) if title_element else None\n                link = link_element.get('href') if link_element else ''\n                \n                # For Google, links might be relative or in a special format\n                if self.search_engine == 'google' and link and not link.startswith('http'):\n                    if link.startswith('/url?q='):\n                        link = link.split('/url?q=')[1].split('&')[0]\n                \n                snippet_element = element.select_one(config['snippet_selector'])\n                snippet = snippet_element.get_text().strip() if snippet_element else ''\n                \n                results.append({\n                    'title': title,\n                    'link': link,\n                    'snippet': snippet\n                })\n                \n                if len(results) >= num_results:\n                    break\n            except Exception as e:\n                print(f\"Error extracting result: {e}\", color=\"yellow\")\n        \n        return results\n    \n    def _extract_context(self, results):\n        \"\"\"\n        Extract and format context from search results.\n        \n        Args:\n            results: List of search results\n            \n        Returns:\n            Formatted context string\n        \"\"\"\n        if not results:\n            return \"\"\n        \n        context = []\n        for i, result in enumerate(results):\n            title = result.get('title', 'No title')\n            snippet = result.get('snippet', 'No description available')\n            url = result.get('url', '')\n            \n            entry = f\"[{i+1}] {title}\\n\"\n            if snippet:\n                entry += f\"{snippet}\\n\"\n            if url:\n                entry += f\"Source: {url}\\n\"\n            \n            context.append(entry)\n        \n        return \"\\n\".join(context)\n    \n    def _get_from_cache(self, key):\n        \"\"\"\n        Retrieve results from cache if available and not expired.\n        \n        Args:\n            key: Cache key\n            \n        Returns:\n            Cached results or None if not found/expired\n        \"\"\"\n        cache_file = os.path.join(self.cache_dir, f\"{key}.json\")\n        \n        if not os.path.exists(cache_file):\n            return None\n        \n        # Check if cache is expired\n        if self.cache_expiry > 0:\n            file_age = time.time() - os.path.getmtime(cache_file)\n            if file_age > self.cache_expiry:\n                return None\n        \n        try:\n            with open(cache_file, 'r') as f:\n                return json.load(f)\n        except Exception:\n            return None\n    \n    def _save_to_cache(self, key, data):\n        \"\"\"\n        Save results to cache.\n        \n        Args:\n            key: Cache key\n            data: Data to cache\n        \"\"\"\n        cache_file = os.path.join(self.cache_dir, f\"{key}.json\")\n        \n        try:\n            with open(cache_file, 'w') as f:\n                json.dump(data, f)\n        except Exception as e:\n            c.print(f\"Failed to save to cache: {e}\", color=\"yellow\")\n    \n    def search_and_summarize(self,\n                            query: str,\n                            model: Optional[str] = None,\n                            num_results: int = 5,\n                            max_tokens: int = 300,\n                            verbose: bool = True) -> Dict[str, Any]:\n        \"\"\"\n        Search the web and generate a concise summary of the results.\n        \n        Args:\n            query: Search query\n            model: Model to use for summarization (uses default if None)\n            num_results: Number of search results to consider\n            max_tokens: Maximum length of summary\n            verbose: Whether to print detailed information\n            \n        Returns:\n            Dictionary containing:\n            - success: Whether the operation was successful\n            - summary: Generated summary\n            - query: Original search query\n            - results: Raw search results\n        \"\"\"\n        # First, search the web\n        search_results = self.forward(\n            query=query,\n            num_results=num_results,\n            verbose=verbose\n        )\n        \n        if not search_results[\"success\"]:\n            return search_results\n        \n        try:\n            # Get the model for summarization\n            llm = c.module('dev.model.openrouter')()\n            \n            # Create prompt for summarization\n            context = search_results[\"context\"]\n            prompt = f\"\"\"\n            Based on the following search results for the query \"{query}\", provide a concise, \n            informative summary of the key information. Focus on factual information and \n            include the most important points from multiple sources if available.\n            \n            SEARCH RESULTS:\n            {context}\n            \n            SUMMARY:\n            \"\"\"\n            \n            # Generate summary\n            summary = llm.forward(\n                prompt=prompt,\n                model=model,\n                max_tokens=max_tokens\n            )\n            \n            if verbose:\n                c.print(\"Generated summary:\", color=\"green\")\n                c.print(summary)\n            \n            return {\n                \"success\": True,\n                \"summary\": summary,\n                \"query\": query,\n                \"results\": search_results[\"results\"]\n            }\n            \n        except Exception as e:\n            error_msg = f\"Summarization failed: {str(e)}\"\n            if verbose:\n                c.print(error_msg, color=\"red\")\n            \n            return {\n                \"success\": False,\n                \"error\": error_msg,\n                \"query\": query,\n                \"results\": search_results[\"results\"]\n            }\n\n# Example usage\nif __name__ == \"__main__\":\n    scraper = WebScraper(use_selenium=True, headless=True)\n    results = scraper.forward(\"latest AI developments\", num_results=5)\n    print(results[\"context\"])\n"
    },
    "schema": {
        "forward": {
            "input": {
                "self": {
                    "value": "_empty",
                    "type": "_empty"
                },
                "query": {
                    "value": "i want to edit a file of ./",
                    "type": "str"
                },
                "extra_query": {
                    "value": "_empty",
                    "type": "_empty"
                },
                "tools": {
                    "value": null,
                    "type": "NoneType"
                },
                "kwargs": {
                    "value": "_empty",
                    "type": "_empty"
                }
            },
            "output": {
                "value": null,
                "type": "typing.Dict[str, typing.Any]"
            },
            "docs": "\n        Forward the query to the appropriate tool based on the provided query.\n        \n        Args:\n            query (str): The query to be processed.\n            tools (List[str], optional): List of specific tools to consider. If None, all tools are considered.\n            **kwargs: Additional arguments to pass to the selected tool.\n        \n        Returns:\n            Dict[str, Any]: The result from the selected tool.\n        ",
            "cost": 1,
            "name": "forward",
            "source": {
                "start": 27,
                "length": 24,
                "path": "~/commune/commune/modules/dev/src/dev/tool/tool.py",
                "code": null,
                "hash": "sha256:1ae38c12036ef5d43830aec973599f10fa685162bab60905a2295b32eb38f896",
                "end": 51
            }
        },
        "postprocess": {
            "input": {
                "self": {
                    "value": "_empty",
                    "type": "_empty"
                },
                "output": {
                    "value": "_empty",
                    "type": "_empty"
                }
            },
            "output": {
                "value": null,
                "type": "None"
            },
            "docs": null,
            "cost": 1,
            "name": "postprocess",
            "source": {
                "start": 69,
                "length": 2,
                "path": "~/commune/commune/modules/dev/src/dev/tool/tool.py",
                "code": null,
                "hash": "sha256:47a9c7bbc4ee5ff86189ca7be69d0dcb0285f9fdd7ac189be6ab1f7306c2b43f",
                "end": 71
            }
        },
        "preprocess": {
            "input": {
                "self": {
                    "value": "_empty",
                    "type": "_empty"
                },
                "prompt": {
                    "value": "_empty",
                    "type": "_empty"
                }
            },
            "output": {
                "value": null,
                "type": "None"
            },
            "docs": null,
            "cost": 1,
            "name": "preprocess",
            "source": {
                "start": 53,
                "length": 15,
                "path": "~/commune/commune/modules/dev/src/dev/tool/tool.py",
                "code": null,
                "hash": "sha256:1ae169c04bf3b5e33afadddf48e569e076fcb198a97b3172668365dad70fb3a8",
                "end": 68
            }
        },
        "schema": {
            "input": {
                "self": {
                    "value": "_empty",
                    "type": "_empty"
                },
                "tool": {
                    "value": "_empty",
                    "type": "_empty"
                }
            },
            "output": {
                "value": null,
                "type": "typing.Dict[str, str]"
            },
            "docs": "\n        Get the schema for a specific tool.\n        \n        Args:\n            tool (str): The name of the tool.\n        \n        Returns:\n            Dict[str, str]: The schema for the specified tool.\n        ",
            "cost": 1,
            "name": "schema",
            "source": {
                "start": 98,
                "length": 17,
                "path": "~/commune/commune/modules/dev/src/dev/tool/tool.py",
                "code": null,
                "hash": "sha256:49a145a5e5fca650ac38766080dec82c7a43b6511c235c22cd0f8d1d67892d5f",
                "end": 115
            }
        },
        "tool2code": {
            "input": {
                "self": {
                    "value": "_empty",
                    "type": "_empty"
                }
            },
            "output": {
                "value": null,
                "type": "typing.Dict[str, str]"
            },
            "docs": "\n        Map each tool to its code.\n        \n        Returns:\n            Dict[str, str]: Dictionary mapping tool names to their code.\n        ",
            "cost": 1,
            "name": "tool2code",
            "source": {
                "start": 116,
                "length": 12,
                "path": "~/commune/commune/modules/dev/src/dev/tool/tool.py",
                "code": null,
                "hash": "sha256:c0f95d2c7cb0b42edeff831dca664845713c2b5218589e679341df516396a1e7",
                "end": 128
            }
        },
        "tool2schema": {
            "input": {
                "self": {
                    "value": "_empty",
                    "type": "_empty"
                }
            },
            "output": {
                "value": null,
                "type": "typing.Dict[str, str]"
            },
            "docs": "\n        Map each tool to its schema.\n        \n        Returns:\n            Dict[str, str]: Dictionary mapping tool names to their schemas.\n        ",
            "cost": 1,
            "name": "tool2schema",
            "source": {
                "start": 84,
                "length": 13,
                "path": "~/commune/commune/modules/dev/src/dev/tool/tool.py",
                "code": null,
                "hash": "sha256:54f8925f98b5799ba549b9175fbeb02b95f42139e14460f7a870b1cb7af7c5c4",
                "end": 97
            }
        },
        "tool2size": {
            "input": {
                "self": {
                    "value": "_empty",
                    "type": "_empty"
                }
            },
            "output": {
                "value": null,
                "type": "typing.Dict[str, int]"
            },
            "docs": "\n        Map each tool to its code size.\n        \n        Returns:\n            Dict[str, int]: Dictionary mapping tool names to their code size.\n        ",
            "cost": 1,
            "name": "tool2size",
            "source": {
                "start": 129,
                "length": 12,
                "path": "~/commune/commune/modules/dev/src/dev/tool/tool.py",
                "code": null,
                "hash": "sha256:ee439e24f473d7053f3284bd4e951a3a09900c4d3fbd60431d45129f93d86ec8",
                "end": 141
            }
        },
        "tools": {
            "input": {
                "self": {
                    "value": "_empty",
                    "type": "_empty"
                }
            },
            "output": {
                "value": null,
                "type": "typing.List[str]"
            },
            "docs": null,
            "cost": 1,
            "name": "tools",
            "source": {
                "start": 73,
                "length": 2,
                "path": "~/commune/commune/modules/dev/src/dev/tool/tool.py",
                "code": null,
                "hash": "sha256:9bf0a0107ef8fed485d471021094e404f56aa8c35f06754a3e2779a3610b50ca",
                "end": 75
            }
        }
    },
    "name": "dev.tool",
    "key": "5CyJY9EJ19miWF6FNkAEmsAWKpCLTSDvq4zyfGQhjJvejVGN",
    "founder": "5GKvu9qC8VPjXnofUxZP6zxTmvzTBCY1vpJAkh6gWF8YxPKy",
    "cid": "sha256:776178211d9e0c05fe0646630d98baff66fee1633f924b7b1eea58153fdf6b79",
    "time": 1746536301.4023879,
    "signature": "0x5eb1e5da7509131a2652ae5ef861ccf77b48b04cb782c124792b976854e5ad6db37cb148d87391680d3b8ea3dc684fee9e71cdf7ec20e844da2b38f5f1753786"
}