{
    "code": {
        "README.md": "\n# Dev Module\n\nThe Dev module is an advanced code generation and editing toolkit powered by LLMs. It provides a powerful interface for generating, editing, and managing code through natural language prompts.\n\n## Features\n\n- **Code Generation**: Create code from scratch based on natural language descriptions\n- **Code Editing**: Modify existing codebases with natural language instructions\n- **File Selection**: Find relevant files based on semantic understanding\n- **Function Calling**: Dynamically incorporate function results into prompts\n- **Interactive Workflow**: Preview and confirm changes before applying them\n\n## Quick Start\n\n```python\nimport commune as c\n\n# Initialize the dev module\ndev = c.module('dev')()\n\n# Generate code from a prompt\ndev.forward(\"Create a Python function that calculates Fibonacci numbers\")\n\n# Edit existing code\ndev.forward(\"Add error handling to the function\", to=\"./path/to/file.py\")\n\n# Use the toolbox for more guidance\ntoolbox = c.module('dev.tool.toolbox')()\ntoolbox.help()\n```\n\n## Core Components\n\n1. **Dev**: Main module for code generation and editing\n2. **Edit**: Specialized module for editing existing code\n3. **Select**: Tool for finding relevant files based on queries\n4. **Toolbox**: Guide and helper for using all dev tools effectively\n\n## Usage Examples\n\n### Generate a New Module\n\n```python\ndev.forward(\n    \"Create a REST API with endpoints for user management (create, read, update, delete)\",\n    to=\"./api\"\n)\n```\n\n### Edit Existing Code\n\n```python\ndev.forward(\n    \"Add input validation and error handling to this function\",\n    to=\"./utils/helpers.py\"\n)\n```\n\n### Find Relevant Files\n\n```python\nselect = c.module('dev.tool.select')()\nfiles = c.files(\"./project\")\nauth_files = select.forward(\n    options=files,\n    query=\"files related to authentication\"\n)\n```\n\n### Function Calling\n\n```python\ndev.forward(\"Document these functions: @/get_text ./utils/helpers.py\")\n```\n\n## Advanced Configuration\n\nThe Dev module can be configured with various parameters:\n\n- `model`: Choose which LLM to use (default: \"anthropic/claude-3.7-sonnet\")\n- `temperature`: Control creativity (0.0-1.0)\n- `max_tokens`: Limit the response size\n- `verbose`: Enable/disable detailed output\n\n## Getting Help\n\nFor more detailed guidance, use the Toolbox:\n\n```python\ntoolbox = c.module('dev.tool.toolbox')()\n\n# General help\ntoolbox.help()\n\n# Tool-specific examples\ntoolbox.example(\"dev\")\ntoolbox.example(\"edit\")\ntoolbox.example(\"select\")\n\n# Detailed guides\ntoolbox.dev_guide()\ntoolbox.edit_guide()\ntoolbox.select_guide()\n\n# Quick start guide\ntoolbox.quick_start()\n\n# Function calling guide\ntoolbox.function_calling_guide()\n```\n",
        "__init__.py": "from .dev import Dev\n\n",
        "dev.py": "\nimport commune as c\nimport time\nimport os\nimport glob\nimport re\nimport json\nfrom pathlib import Path\nfrom typing import Dict, List, Union, Optional, Any, Tuple\nfrom .utils import *\n\nprint = c.print\n\nclass Dev:\n\n    start_anchor = '<START_JSON>'\n    end_anchor = '</END_JSON>'\n\n    prompt= \"\"\"\n                --GOAL--\n                YOU ARE A CODER, YOU ARE MR.ROBOT, YOU ARE TRYING TO BUILD IN A SIMPLE\n                LEONARDO DA VINCI WAY, YOU ARE A agent, YOU ARE A GENIUS, YOU ARE A STAR, \n                YOU FINISH ALL OF YOUR REQUESTS WITH UTMOST PRECISION AND SPEED, YOU WILL ALWAYS \n                MAKE SURE THIS WORKS TO MAKE ANYONE CODE. YOU HAVE THE CONTEXT AND INPUTS FOR ASSISTANCE\n                YOU HAVE TWO MODES, EDIT AND BUILD FROM SCRATCH\n                IF YOU ARE IN EDIT MODE, YOU CAN EDIT WHATEVER YOU WANT AND \n                BY DEFAULT YOU DONT NEED TO WRITE THE FULL REPO AND CAN ONLY ADD SINGLE FILES IF YOU WANT\n                IF YOU NEED TO, PLEASE MAKE SURE TO ENSURE THAT THERE IS A README.md AND A SCRIPTS FOLDER\n                \"YOU CAN RESPOND WITH THE FOLLOWING FORMAT THAT MUST BE WITHIN THE PWD\"\n\n                --CONTEXT--\n                PATH/PWD={path}\n                CONTEXT={context}\n                QUERY={query} # THE QUERY YOU ARE TRYING TO ANSWER\n\n                --TOOLS--\n                YOU ARE ASSUMING EACH TOOL HAS THEIR OWN FORWARD FUNCTION THAT DEFINES THEIR CABAPILITIES AND SO YOU SELECT THE TOOL\n                AND INSERT THE PARAMS TO CALL THE TOOL FORWARD FUNCTION, PLEASE SPECIFY THE TOOLNAME AND THE PARAMS\n                {tools}\n                --OUTPUT_TOOL_PLAN_FORMAT--\n                 YOU MUST CREATE A PLAN OF TOOLS THT WE WILL PARSE ACCORDINGLY TO REPRESENT YOUR PERSPECTIVE \n                PROVIDE A PLAN OF TOOLS AND THEIR PARAMS \n                {start_anchor}list[dict(fn:str, params:dict)]{end_anchor}\n\n                \"\"\"\n\n    def __init__(self, \n                 model: str = 'dev.model.openrouter', \n                 cache_dir: str = '~/.commune/dev_cache',\n                 **kwargs):\n\n        self.model = c.module(model)()\n        self.cache_dir = abspath(cache_dir)\n        self.select_files = c.module('dev.tool.select_files')()\n        self.tools = self.ta = c.module('dev.tool')().tool2schema()\n        ensure_directory_exists(self.cache_dir)\n        \n    def forward(self, \n                text: str = '', \n                *extra_text, \n                path: str = './', \n                temperature: float = 0.5, \n                max_tokens: int = 1000000, \n                model: Optional[str] = 'anthropic/claude-3.7-sonnet',\n                stream: bool = True,\n                verbose: bool = True,\n                mode: str = 'auto', \n                max_age= 10000,\n                **kwargs) -> Dict[str, str]:\n        query = self.preprocess(' '.join(list(map(str, [text] + list(extra_text)))))\n        context = {f: get_text(f) for f in self.select_files.forward(path=path, query=query)}\n\n        prompt =self.prompt.format(\n            path=path,\n            context=context,\n            query=query,\n            tools=self.tools,\n            start_anchor=self.start_anchor,\n            end_anchor=self.end_anchor\n        )\n\n        # Generate the response\n        output = self.model.forward(prompt, stream=stream, model=model, max_tokens=max_tokens, temperature=temperature )\n        # Process the output\n        return self.postprocess(output)\n\n\n    def preprocess(self, text, threshold=1000):\n            new_text = ''\n            is_function_running = False\n            words = text.split(' ')\n            fn_detected = False\n            fns = []\n            for i, word in enumerate(words):\n                prev_word = words[i-1] if i > 0 else ''\n                # restrictions can currently only handle one fn argument, future support for multiple\n                magic_prefix = f'@/'\n                if word.startswith(magic_prefix) and not fn_detected:\n                    word = word[len(magic_prefix):]\n                    if '/' not in word:\n                        word = '/' + word\n                    fns += [{'fn': word, 'params': [], 'idx': i + 2}]\n                    fn_detected=True\n                else:\n                    if fn_detected:\n                        fns[-1]['params'] += [word]\n                        fn_detected = False\n            c.print(fns)\n            for fn in fns:\n                print('Running fn:', fn)\n                result = c.fn(fn['fn'])(*fn['params'])\n                fn['result'] = result\n                text =' '.join([*words[:fn['idx']],'-->', str(result), *words[fn['idx']:]])\n            return text\n\n    def test(self, text='write a fn that adds two numbers and a test.js file that i can test it all in one class and have me test it in test.js and a script to run it'):\n        \"\"\"\n        Test the Dev module by generating code based on a prompt.\n        \n        Args:\n            text: The prompt text\n            \n        Returns:\n            Dictionary mapping file paths to generated content\n        \"\"\"\n        path = '~/.dev/test/add'\n        return self.forward(text, to=path, verbose=True)\n\n    def postprocess(self, output):\n        \"\"\"\n        Postprocess tool outputs and extract fn calls.\n        \n        This fn parses the raw output text and identifies fn calls in the format:\n        <FN::function_name>param1</FN::function_name> or \n        <FN::function_name><param_name>param_value</param_name></FN::function_name>\n        \n        Args:\n            output (str): The raw output from the model\n                \n        Returns:\n            str: The processed output with extracted fn calls\n        \"\"\"\n        import re\n        \n        # Print the output character by character for streaming effect\n        text = ''\n        for ch in output: \n            print(ch, end='')\n            text += ch\n        json_str = text.split(self.start_anchor)[1].split(self.end_anchor)[0]\n         \n        plan = json.loads(json_str)\n        # You can process the fn calls here or return them for further processing\n        print(\"Function calls detected:\")\n        print(plan)\n        # For debugging, you can add:\n        if input('Do you want to see the fn calls? (y/n): ').strip().lower() == 'y':\n            print(\"Function calls detected:\")\n            for call in plan:\n                print(f\"Function: {call['fn']}, Parameters: {call['params']}\")\n                fn = c.module(call['fn'])()\n                fn.forward(**call['params'])\n                \n        return {\n            \"plan\": plan\n        }\n",
        "model/litellm/model.py": "import os\nfrom litellm import completion, acompletion\nimport asyncio\n\nclass LiteLLM:\n    def __init__(self, provider_keys: dict = {}):\n        \"\"\"\n        Initialize LiteLLMClient with provider API keys.\n\n        Args:\n            provider_keys (dict): API keys for providers, e.g., {'openai': 'key', 'anthropic': 'key'}\n        \"\"\"\n        for provider, key in provider_keys.items():\n            os.environ[f\"{provider.upper()}_API_KEY\"] = key\n\n    def forward(self, model: str, messages: list, stream: bool = False):\n        \"\"\"\n        Generate completion synchronously.\n\n        Args:\n            model (str): Provider and model name (e.g., \"openai/gpt-4o\").\n            messages (list): List of message dicts.\n            stream (bool): Stream response or not.\n\n        Returns:\n            Completion response.\n        \"\"\"\n        response = completion(model=model, messages=messages, stream=stream)\n        if stream:\n            return (part.choices[0].delta.content or \"\" for part in response)\n        return response.choices[0].message.content\n\n    async def async_forward(self, model: str, messages: list):\n        \"\"\"\n        Generate completion asynchronously.\n\n        Args:\n            model (str): Provider and model name.\n            messages (list): List of message dicts.\n\n        Returns:\n            Completion response.\n        \"\"\"\n        response = await acompletion(model=model, messages=messages)\n        return response.choices[0].message.content\n\n    def set_callbacks(self, callbacks: list):\n        \"\"\"\n        Set logging and observability callbacks.\n\n        Args:\n            callbacks (list): List of callbacks (e.g., ['lunary', 'mlflow']).\n        \"\"\"\n        import litellm\n        litellm.success_callback = callbacks\n        \n\n    def test(self):\n        provider_keys = {\n            \"openai\": \"your-openai-key\",\n            \"anthropic\": \"your-anthropic-key\"\n        }\n\n        client = LiteLLMClient(provider_keys)\n\n        messages = [{\"content\": \"Hello, how are you?\", \"role\": \"user\"}]\n\n        # synchronous\n        response = client.forward(\"openai/gpt-4o\", messages)\n        print(response)\n\n        # asynchronous\n        async def main():\n            response = await client.async_forward(\"anthropic/claude-3-sonnet-20240229\", messages)\n            print(response)\n\n        asyncio.run(main())\n",
        "model/openrouter/model.py": "import os\nimport json\nimport random\nimport requests\nimport openai\nfrom dotenv import load_dotenv\n\nclass OpenRouter:\n    def __init__(\n        self,\n        api_key: str = 'OPENROUTER_API_KEY',\n        default_model: str = 'anthropic/claude-3.7-sonnet',\n        base_url: str = 'https://openrouter.ai/api/v1',\n        timeout: float = None,\n        max_retries: int = 10,\n        storage_path = '~/.deval/model/openrouter',\n        \n        **kwargs\n    ):\n        \"\"\"\n        Initialize the OpenAI with the specified model, API key, timeout, and max retries.\n\n        Args:\n            model (OPENAI_MODES): The OpenAI model to use.\n            api_key (API_KEY): The API key for authentication.\n            base_url (str, optional): can be used for openrouter api calls\n            timeout (float, optional): The timeout value for the client. Defaults to None.\n            max_retries (int, optional): The maximum number of retries for the client. Defaults to None.\n            storage_path (str, optional): The path to store the models. Defaults to '~/.val/model/openrouter'.\n        \"\"\"\n        # Load environment variables from .env file in the current working directory\n\n    \n        self.storage_path = os.path.abspath(os.path.expanduser(storage_path)) # path to store models (relative to storage_path) \n        self.api_key_path = f'{self.storage_path}/api.json' # path to store api keys (relative to storage_path)\n        self.base_url = base_url\n        self.api_key= self.get_api_key(api_key)\n        self.default_model = default_model\n        # Use API key from parameters, or from environment variable, or from stored keys\n\n        self.client = openai.OpenAI(\n            base_url=self.base_url,\n            api_key=self.api_key, \n            timeout=timeout,\n            max_retries=max_retries,\n        )\n\n    def forward(\n        self,\n        message: str,\n        *extra_text , \n        history: list = None,\n        stream: bool = False,\n        model:str = None,\n        max_tokens: int = 10000000,\n        temperature: float = 0,\n        verbose: bool = False,\n\n        **kwargs\n    ) -> str :\n        \"\"\"\n        Generates a response using the OpenAI language providers.\n\n        Args:\n            message (str): The message to send to the language providers.\n            history (ChatHistory): The conversation history.\n            stream (bool): Whether to stream the response or not.\n            max_tokens (int): The maximum number of tokens to generate.\n            temperature (float): The sampling temperature to use.\n\n        Returns:\n        Generator[str] | str: A generator for streaming responses or the full streamed response.\n        \"\"\"\n        model =  model or self.default_model\n        message = str(message)\n        if len(extra_text) > 0:\n            message = message + ' '.join(extra_text)\n        history = history or []\n        model = self.get_model(model)\n        model_info = self.get_model_info(model)\n        num_tokens = len(message)\n        max_tokens = min(max_tokens, model_info['context_length'] - num_tokens)\n        messages = history.copy()\n        messages.append({\"role\": \"user\", \"content\": message})\n        result = self.client.chat.completions.create(model=model, \n                                                    messages=messages, \n                                                    stream= bool(stream),\n                                                    max_tokens = max_tokens, \n                                                    temperature= temperature  )\n        if stream:\n            def stream_generator( result):\n                for token in result:\n                    token = token.choices[0].delta.content\n                    if verbose:\n                        print(token, end='', flush=True)\n                    yield token\n            return stream_generator(result)\n        else:\n            return result.choices[0].message.content\n        \n    def get_model(self, model=None):\n        models =  self.models()\n        model = str(model)\n        if str(model) not in models:\n            if ',' in model:\n                models = [m for m in models if any([s in m for s in providers.split(',')])]\n            else:\n                models = [m for m in models if str(model) in m]\n            print(f\"Model {model} not found. Using {models} instead.\")\n            assert len(models) > 0\n            model = models[0]\n\n        return model\n\n    def get_json(self, path, default=None , update=False):\n        if not os.path.exists(path) and not update:\n            return default\n        else:\n            with open(path, 'r') as f:\n                data = json.load(f)\n                if isinstance(data, str):\n                    data = json.loads(data)\n            return data\n\n    def put_json(self, path, data):\n        dirpath = os.path.dirname(path)\n        if not os.path.exists(dirpath):\n            os.makedirs(dirpath)\n        with open(path, 'w') as f:\n            json.dump(data, f)\n        return {'status': 'success', 'path': path}\n\n    def get_api_key(self, api_key='OPENROUTER_API_KEY', save_key_if_not_found=True):\n        \"\"\"\n        get the api keys\n        \"\"\"\n        keys = self.get_json(self.api_key_path, [])\n        load_dotenv()\n        if isinstance(api_key, str):\n            env_dict = os.environ\n            env_var_found = False\n            if api_key in env_dict:\n                env_var_found = True\n                # how to change the color of the text in the terminal\n                api_key = env_dict[api_key]\n            if env_var_found:\n                if save_key_if_not_found:\n                    keys.append(api_key)\n                    keys = list(set(keys))\n                    self.put_json(self.api_key_path, keys)\n        assert len(keys) > 0, f'No API key found. Please set the {api_key} environment variable or add a key to {self.api_key_path}'\n        if len(keys) > 0:\n            return random.choice(keys)\n        else:\n            return 'password'\n\n\n    def get(self, path, default=None,  update=False):\n        \"\"\"\n        Get the json file from the path\n        \"\"\"\n        if update :\n            return default\n        try:\n            with open(path, 'r') as f:\n                data = json.load(f)\n                if isinstance(data, str):\n                    data = json.loads(data)\n                return data\n        except Exception as e:\n            return default\n\n    def put(self, path, data):\n        \"\"\"\n        Put the json file to the path\n        \"\"\"\n        dirpqth = os.path.dirname(path)\n        if not os.path.exists(dirpqth):\n            os.makedirs(dirpqth)\n        with open(path, 'w') as f:\n            json.dump(data, f)\n        return {'status': 'success', 'path': path}\n\n    def keys(self):\n        \"\"\"\n        Get the list of API keys\n        \"\"\"\n        return self.get_json(self.api_key_path, [])\n\n    def add_key(self, key):\n        keys = self.keys()\n        keys.append(key)\n        keys = list(set(keys))\n        self.put_json(self.api_key_path, keys)\n        return keys\n\n    def resolve_path(self, path):\n        return \n\n    def model2info(self, search: str = None, update=False):\n        path =  f'{self.storage_path}/models.json'\n        models = self.get_json(path, default={}, update=update)\n        if len(models) == 0:\n            response = requests.get(self.base_url + '/models')\n            models = json.loads(response.text)['data']\n            self.put_json(path, models)\n        models = self.filter_models(models, search=search)\n        return {m['id']:m for m in models}\n    \n    def models(self, search: str = None, update=False):\n        return list(self.model2info(search=search,  update=update).keys())\n\n    def get_model_info(self, model):\n        model = self.get_model(model)\n        model2info = self.model2info()\n        return model2info[model]\n    \n    @classmethod\n    def filter_models(cls, models, search:str = None):\n        if search == None:\n            return models\n        if isinstance(models[0], str):\n            models = [{'id': m} for m in models]\n        if ',' in search:\n            search = [s.strip() for s in search.split(',')]\n        else:\n            search = [search]\n        models = [m for m in models if any([s in m['id'] for s in search])]\n        return [m for m in models]\n    \n    def test(self, **kwargs):\n        self = self.__class__(**kwargs)\n        params = dict(\n        message = 'Hello, how are you?',\n        stream = False\n        )\n        result  =  self.forward(**params)\n        assert isinstance(result, str)\n        print('Test passed')\n        params = dict(\n        message = 'Hello, how are you?',\n        stream = True\n        )\n        stream_result = self.forward(**params)\n        print(next(stream_result))\n        return {'status': 'success', 'params_stream': params, 'params': params, 'result': result, 'stream_result': stream_result}",
        "tool/cmd.py": "\nimport commune as c\nimport subprocess\nimport shlex\nimport os\nfrom typing import List, Dict, Union, Optional, Any\n\nclass Cmd:\n    \"\"\"\n    Command-line execution tool for running shell commands with various options.\n    \n    This tool provides a clean interface for executing shell commands with options\n    for capturing output, handling errors, and processing results.\n    \"\"\"\n    \n    def __init__(self, cwd: str = None, shell: bool = False, env: Dict[str, str] = None):\n        \"\"\"\n        Initialize the Cmd tool.\n        \n        Args:\n            cwd: Current working directory for command execution\n            shell: Whether to use shell execution (can be a security risk)\n            env: Environment variables to set for command execution\n        \"\"\"\n        self.cwd = cwd\n        self.shell = shell\n        self.env = env\n        \n    def forward(\n        self,\n        command: Union[str, List[str]],\n        capture_output: bool = True,\n        text: bool = True,\n        check: bool = False,\n        timeout: Optional[float] = None,\n        cwd: Optional[str] = None,\n        env: Optional[Dict[str, str]] = None,\n        shell: Optional[bool] = None,\n        verbose: bool = True\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Execute a shell command and return the results.\n        \n        Args:\n            command: Command to execute (string or list of arguments)\n            capture_output: Whether to capture stdout/stderr\n            text: Whether to return strings instead of bytes\n            check: Whether to raise an exception on non-zero exit code\n            timeout: Maximum time to wait for command completion (in seconds)\n            cwd: Working directory for command execution (overrides instance setting)\n            env: Environment variables (overrides instance setting)\n            shell: Whether to use shell execution (overrides instance setting)\n            verbose: Whether to print command and output information\n            \n        Returns:\n            Dictionary containing:\n            - success: Whether the command executed successfully\n            - returncode: Exit code of the command\n            - stdout: Standard output (if captured)\n            - stderr: Standard error (if captured)\n            - command: The command that was executed\n        \"\"\"\n        # Use instance defaults if not specified\n        cwd = cwd if cwd is not None else self.cwd\n        env = env if env is not None else self.env\n        shell = shell if shell is not None else self.shell\n        \n        # Process the command\n        if isinstance(command, str) and not shell:\n            command = shlex.split(command)\n        \n        if verbose:\n            c.print(f\"Executing: {command}\", color=\"cyan\")\n        \n        try:\n            # Execute the command\n            result = subprocess.run(\n                command,\n                capture_output=capture_output,\n                text=text,\n                check=check,\n                timeout=timeout,\n                cwd=cwd,\n                env=env,\n                shell=shell\n            )\n            \n            # Prepare the result dictionary\n            output = {\n                \"success\": result.returncode == 0,\n                \"returncode\": result.returncode,\n                \"command\": command\n            }\n            \n            # Add stdout/stderr if captured\n            if capture_output:\n                output[\"stdout\"] = result.stdout\n                output[\"stderr\"] = result.stderr\n                \n                if verbose:\n                    if result.stdout:\n                        c.print(\"STDOUT:\", color=\"green\")\n                        c.print(result.stdout)\n                    if result.stderr:\n                        c.print(\"STDERR:\", color=\"red\")\n                        c.print(result.stderr)\n            \n            if verbose:\n                status = \"Success\" if output[\"success\"] else f\"Failed (code: {result.returncode})\"\n                c.print(f\"Command execution: {status}\", color=\"green\" if output[\"success\"] else \"red\")\n                \n            return output\n            \n        except subprocess.TimeoutExpired as e:\n            if verbose:\n                c.print(f\"Command timed out after {timeout} seconds\", color=\"red\")\n            return {\n                \"success\": False,\n                \"error\": \"timeout\",\n                \"command\": command,\n                \"timeout\": timeout,\n                \"message\": str(e)\n            }\n            \n        except subprocess.SubprocessError as e:\n            if verbose:\n                c.print(f\"Command execution error: {e}\", color=\"red\")\n            return {\n                \"success\": False,\n                \"error\": \"subprocess_error\",\n                \"command\": command,\n                \"message\": str(e)\n            }\n            \n        except Exception as e:\n            if verbose:\n                c.print(f\"Unexpected error: {e}\", color=\"red\")\n            return {\n                \"success\": False,\n                \"error\": \"unexpected\",\n                \"command\": command,\n                \"message\": str(e)\n            }\n    \n    def pipe(\n        self,\n        commands: List[str],\n        verbose: bool = True,\n        **kwargs\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Execute a pipeline of commands, passing output from one to the next.\n        \n        Args:\n            commands: List of commands to execute in sequence\n            verbose: Whether to print command and output information\n            **kwargs: Additional arguments to pass to forward()\n            \n        Returns:\n            Dictionary with the result of the final command\n        \"\"\"\n        if not commands:\n            return {\"success\": False, \"error\": \"no_commands\", \"message\": \"No commands provided\"}\n        \n        if verbose:\n            c.print(f\"Executing pipeline of {len(commands)} commands\", color=\"cyan\")\n        \n        result = None\n        for i, cmd in enumerate(commands):\n            if verbose:\n                c.print(f\"Step {i+1}/{len(commands)}: {cmd}\", color=\"blue\")\n                \n            if result is not None and result.get(\"stdout\"):\n                # Use previous command's output as input\n                if kwargs.get(\"shell\", self.shell):\n                    cmd = f\"echo '{result['stdout']}' | {cmd}\"\n                else:\n                    # For non-shell execution, we need a different approach\n                    result = self.forward(\n                        f\"bash -c \\\"echo '{result['stdout']}' | {cmd}\\\"\",\n                        shell=True,\n                        verbose=verbose,\n                        **kwargs\n                    )\n                    continue\n                    \n            result = self.forward(cmd, verbose=verbose, **kwargs)\n            \n            if not result[\"success\"]:\n                if verbose:\n                    c.print(f\"Pipeline failed at step {i+1}\", color=\"red\")\n                break\n                \n        return result\n",
        "tool/create_file.py": "\nimport commune as c\nimport os\nfrom typing import Dict, Any, Optional, Union\nfrom ..utils import abspath, put_text, ensure_directory_exists\n\nclass CreateFile:\n    \"\"\"\n    A utility tool for creating new files at specified paths.\n    \n    This class provides functionality to:\n    - Create new files with specified content\n    - Ensure parent directories exist\n    - Handle different file types appropriately\n    - Provide feedback on the operation\n    \"\"\"\n    \n    def __init__(self, **kwargs):\n        \"\"\"\n        Initialize the CreateFile tool.\n        \n        Args:\n            **kwargs: Additional configuration parameters\n        \"\"\"\n        pass\n    \n    def forward(self, \n                file_path: str, \n                content: str = \"\",\n                create_parent_dirs: bool = True,\n                overwrite: bool = False,\n                verbose: bool = True) -> Dict[str, Any]:\n        \"\"\"\n        Create a new file at the specified path with the given content.\n        \n        Args:\n            file_path: Path where the file should be created\n            content: Content to write to the file\n            create_parent_dirs: Whether to create parent directories if they don't exist\n            overwrite: Whether to overwrite the file if it already exists\n            verbose: Print detailed information about the operation\n            \n        Returns:\n            Dictionary with operation results including:\n            - success: Whether the operation was successful\n            - file_path: Path to the created file\n            - message: Description of the operation result\n        \"\"\"\n        file_path = abspath(file_path)\n        \n        # Check if file already exists\n        if os.path.exists(file_path) and not overwrite:\n            if verbose:\n                c.print(f\"File already exists: {file_path}\", color=\"yellow\")\n            return {\n                \"success\": False,\n                \"file_path\": file_path,\n                \"message\": f\"File already exists and overwrite is False\"\n            }\n        \n        # Create parent directories if needed\n        parent_dir = os.path.dirname(file_path)\n        if create_parent_dirs and parent_dir and not os.path.exists(parent_dir):\n            try:\n                ensure_directory_exists(parent_dir)\n                if verbose:\n                    c.print(f\"Created parent directory: {parent_dir}\", color=\"blue\")\n            except Exception as e:\n                if verbose:\n                    c.print(f\"Failed to create parent directory: {str(e)}\", color=\"red\")\n                return {\n                    \"success\": False,\n                    \"file_path\": file_path,\n                    \"message\": f\"Failed to create parent directory: {str(e)}\"\n                }\n        \n        # Write content to file\n        try:\n            put_text(file_path, content)\n            if verbose:\n                c.print(f\"Successfully created file: {file_path}\", color=\"green\")\n            return {\n                \"success\": True,\n                \"file_path\": file_path,\n                \"message\": \"File created successfully\"\n            }\n        except Exception as e:\n            if verbose:\n                c.print(f\"Failed to create file: {str(e)}\", color=\"red\")\n            return {\n                \"success\": False,\n                \"file_path\": file_path,\n                \"message\": f\"Failed to create file: {str(e)}\"\n            }\n    \n    \n",
        "tool/delete_file.py": "\nimport commune as c\nimport os\nimport shutil\nfrom typing import Dict, Any, Optional, Union\nfrom ..utils import abspath\n\nclass DeleteFile:\n    \"\"\"\n    A utility tool for deleting files and directories at specified paths.\n    \n    This class provides functionality to:\n    - Delete individual files\n    - Optionally delete directories (recursively or not)\n    - Implement safety checks before deletion\n    - Provide feedback on the operation\n    \"\"\"\n    \n    def __init__(self, **kwargs):\n        \"\"\"\n        Initialize the DeleteFile tool.\n        \n        Args:\n            **kwargs: Additional configuration parameters\n        \"\"\"\n        pass\n    \n    def forward(self, \n                path: str, \n                recursive: bool = False,\n                force: bool = False,\n                allow_dir: bool = False,\n                verbose: bool = True) -> Dict[str, Any]:\n        \"\"\"\n        Delete a file or directory at the specified path.\n        \n        Args:\n            path: Path to the file or directory to delete\n            recursive: Whether to recursively delete directories (only applies if allow_dir=True)\n            force: Whether to ignore non-existent files\n            allow_dir: Whether to allow directory deletion\n            verbose: Print detailed information about the operation\n            \n        Returns:\n            Dictionary with operation results including:\n            - success: Whether the operation was successful\n            - path: Path that was targeted for deletion\n            - message: Description of the operation result\n        \"\"\"\n        path = abspath(path)\n        \n        # Check if path exists\n        if not os.path.exists(path):\n            if force:\n                if verbose:\n                    c.print(f\"Path does not exist, but force=True: {path}\", color=\"yellow\")\n                return {\n                    \"success\": True,\n                    \"path\": path,\n                    \"message\": \"Path does not exist, but operation considered successful due to force=True\"\n                }\n            else:\n                if verbose:\n                    c.print(f\"Path does not exist: {path}\", color=\"red\")\n                return {\n                    \"success\": False,\n                    \"path\": path,\n                    \"message\": \"Path does not exist\"\n                }\n        \n        # Handle directory deletion\n        if os.path.isdir(path):\n            if not allow_dir:\n                if verbose:\n                    c.print(f\"Path is a directory but allow_dir=False: {path}\", color=\"red\")\n                return {\n                    \"success\": False,\n                    \"path\": path,\n                    \"message\": \"Path is a directory but allow_dir=False\"\n                }\n            \n            try:\n                if recursive:\n                    shutil.rmtree(path)\n                    if verbose:\n                        c.print(f\"Successfully deleted directory recursively: {path}\", color=\"green\")\n                    return {\n                        \"success\": True,\n                        \"path\": path,\n                        \"message\": \"Directory deleted recursively\"\n                    }\n                else:\n                    os.rmdir(path)\n                    if verbose:\n                        c.print(f\"Successfully deleted empty directory: {path}\", color=\"green\")\n                    return {\n                        \"success\": True,\n                        \"path\": path,\n                        \"message\": \"Empty directory deleted\"\n                    }\n            except OSError as e:\n                if not recursive and len(os.listdir(path)) > 0:\n                    if verbose:\n                        c.print(f\"Cannot delete non-empty directory without recursive=True: {path}\", color=\"red\")\n                    return {\n                        \"success\": False,\n                        \"path\": path,\n                        \"message\": \"Cannot delete non-empty directory without recursive=True\"\n                    }\n                if verbose:\n                    c.print(f\"Failed to delete directory: {str(e)}\", color=\"red\")\n                return {\n                    \"success\": False,\n                    \"path\": path,\n                    \"message\": f\"Failed to delete directory: {str(e)}\"\n                }\n        \n        # Handle file deletion\n        try:\n            os.remove(path)\n            if verbose:\n                c.print(f\"Successfully deleted file: {path}\", color=\"green\")\n            return {\n                \"success\": True,\n                \"path\": path,\n                \"message\": \"File deleted successfully\"\n            }\n        except Exception as e:\n            if verbose:\n                c.print(f\"Failed to delete file: {str(e)}\", color=\"red\")\n            return {\n                \"success\": False,\n                \"path\": path,\n                \"message\": f\"Failed to delete file: {str(e)}\"\n            }\n",
        "tool/insert_text.py": "\nimport commune as c\nimport os\nimport re\nfrom typing import Dict, List, Union, Optional, Any\nfrom ..utils import get_text, put_text, abspath\nprint = c.print\nclass Insert:\n    \"\"\"\n    A utility tool for inserting text between specified anchor points in files.\n    \n    This class provides functionality to:\n    - Find anchor points in files\n    - Insert new content between those anchor points\n    - Replace existing content between anchor points\n    - Preserve the original file structure\n    - Handle multiple insertions in a single operation\n    \"\"\"\n    \n    def __init__(self, cache_dir: str = '~/.commune/insert_cache', **kwargs):\n        \"\"\"\n        Initialize the Insert tool.\n        \n        Args:\n            cache_dir: Directory to store cache files if needed\n            **kwargs: Additional configuration parameters\n        \"\"\"\n        self.cache_dir = abspath(cache_dir)\n        if not os.path.exists(self.cache_dir):\n            os.makedirs(self.cache_dir, exist_ok=True)\n    \n    def forward(self, \n                file_path: str, \n                new_content: str,\n                start_anchor: str,\n                end_anchor: str,\n                create_if_missing: bool = False,\n                backup: bool = True,\n                verbose: bool = True) -> Dict[str, Any]:\n        \"\"\"\n        Insert content between two anchor points in a file.\n        \n        Args:\n            file_path: Path to the target file\n            new_content: Content to insert between the anchors\n            start_anchor: Text marking the beginning of the insertion point\n            end_anchor: Text marking the end of the insertion point\n            create_if_missing: Create the file with anchors if it doesn't exist\n            backup: Create a backup of the original file before modifying\n            verbose: Print detailed information about the operation\n            \n        Returns:\n            Dictionary with operation results including:\n            - success: Whether the operation was successful\n            - file_path: Path to the modified file\n            - backup_path: Path to the backup file (if created)\n            - message: Description of the operation result\n        \"\"\"\n        file_path = abspath(file_path)\n        \n        # Check if file exists\n        if not os.path.exists(file_path):\n            if not create_if_missing:\n                if verbose:\n                    print(f\"File not found: {file_path}\", color=\"red\")\n                return {\n                    \"success\": False,\n                    \"file_path\": file_path,\n                    \"message\": f\"File not found and create_if_missing is False\"\n                }\n            else:\n                # Create new file with anchors and content\n                content = f\"{start_anchor}\\n{new_content}\\n{end_anchor}\"\n                put_text(file_path, content)\n                if verbose:\n                    print(f\"Created new file with content: {file_path}\", color=\"green\")\n                return {\n                    \"success\": True,\n                    \"file_path\": file_path,\n                    \"message\": \"Created new file with anchors and content\"\n                }\n        \n        # Read the original content\n        original_content = get_text(file_path)\n        if original_content is None:\n            if verbose:\n                print(f\"Could not read file: {file_path}\", color=\"red\")\n            return {\n                \"success\": False,\n                \"file_path\": file_path,\n                \"message\": \"Could not read file content\"\n            }\n        \n        # Create backup if requested\n        backup_path = None\n        if backup:\n            backup_path = f\"{file_path}.bak\"\n            put_text(backup_path, original_content)\n            if verbose:\n                print(f\"Created backup: {backup_path}\", color=\"blue\")\n        \n        # Find the anchor points\n        pattern = re.escape(start_anchor) + r\"(.*?)\" + re.escape(end_anchor)\n        match = re.search(pattern, original_content, re.DOTALL)\n        \n        if match:\n            # Replace content between anchors\n            new_file_content = original_content.replace(\n                f\"{start_anchor}{match.group(1)}{end_anchor}\",\n                f\"{start_anchor}\\n{new_content}\\n{end_anchor}\"\n            )\n            if verbose:\n                print(f\"Found anchors and replacing content\", color=\"green\")\n        else:\n            # Anchors not found - append to end of file\n            if verbose:\n                print(f\"Anchors not found in file, appending to end\", color=\"yellow\")\n            new_file_content = f\"{original_content}\\n\\n{start_anchor}\\n{new_content}\\n{end_anchor}\"\n        \n        # Write the modified content\n        put_text(file_path, new_file_content)\n        \n        if verbose:\n            print(f\"Successfully inserted content in: {file_path}\", color=\"green\")\n        \n        return {\n            \"success\": True,\n            \"file_path\": file_path,\n            \"backup_path\": backup_path,\n            \"message\": \"Successfully inserted content between anchors\"\n        }\n    ",
        "tool/memory/README.md": "\n# Memory Tool\n\nA flexible memory management system for AI applications that provides both short-term and long-term memory capabilities.\n\n## Features\n\n- **Short-term Memory**: In-memory storage with automatic expiration\n- **Long-term Memory**: Persistent file-based storage\n- **Relevance Filtering**: Find memories most relevant to a query\n- **Memory Management**: Automatic cleanup of expired items\n- **Memory Search**: Search through stored memories\n- **Memory Summarization**: Generate summaries of stored memories\n\n## Usage\n\n```python\nimport commune as c\n\n# Initialize the memory tool\nmemory = c.module('dev.tool.memory')()\n\n# Store information in short-term memory (expires after default TTL)\nmemory.add_short_term(\"user_preference\", {\"theme\": \"dark\", \"language\": \"python\"})\n\n# Store information in long-term memory (persistent)\nmemory.add_long_term(\"project_requirements\", {\n    \"name\": \"AI Assistant\",\n    \"features\": [\"code generation\", \"memory management\", \"file editing\"]\n})\n\n# Retrieve memories\nuser_pref = memory.get_short_term(\"user_preference\")\nrequirements = memory.get_long_term(\"project_requirements\")\n\n# Filter a list of items by relevance to a query\nfiles = [\"main.py\", \"utils.py\", \"memory.py\", \"database.py\"]\nrelevant_files = memory.forward(files, query=\"memory management\", n=2)\n# Returns: [\"memory.py\", \"utils.py\"]\n\n# Search long-term memory\nrelevant_memories = memory.search_long_term(\"project features\")\n\n# Generate a summary of memories\nsummary = memory.summarize_memories(query=\"user preferences\")\n```\n\n## Integration with Dev Module\n\nThe Memory tool is designed to work seamlessly with the Dev module:\n\n```python\ndev = c.module('dev')()\ndev.set_memory(c.module('dev.tool.memory')())\n\n# Now Dev will use the memory tool to maintain context\n```\n\n## Advanced Features\n\n### Memory Eviction Policies\n\nWhen short-term memory reaches capacity, items are evicted using a Least Recently Used (LRU) strategy.\n\n### Memory Persistence\n\nLong-term memories are stored as JSON files in the specified directory (default: `~/.commune/memory/long_term`).\n\n### Relevance Scoring\n\nThe tool uses LLM-based relevance scoring to find the most relevant memories for a given query.\n",
        "tool/memory/memory.py": "\nimport commune as c\nimport os\nimport json\nimport time\nfrom typing import Dict, List, Any, Optional, Union\nfrom pathlib import Path\n\nclass Memory:\n    \"\"\"\n    A memory management tool that provides both short-term and long-term memory capabilities.\n    \n    This tool helps maintain context across interactions by:\n    - Storing temporary information in short-term memory (in-memory)\n    - Persisting important information in long-term memory (file-based)\n    - Retrieving and filtering memories based on relevance\n    - Managing memory expiration and prioritization\n    \"\"\"\n    \n    def __init__(\n        self,\n        long_term_path: str = \"~/.commune/memory/long_term\",\n        short_term_capacity: int = 100,\n        default_ttl: int = 3600,  # 1 hour default TTL for short-term memory\n        model: str = 'dev.model.openrouter',\n        **kwargs\n    ):\n        \"\"\"\n        Initialize the Memory module.\n        \n        Args:\n            long_term_path: Path to store long-term memories\n            short_term_capacity: Maximum number of items in short-term memory\n            default_ttl: Default time-to-live for short-term memories (in seconds)\n            model: Model to use for relevance scoring\n            **kwargs: Additional arguments to pass to the model\n        \"\"\"\n        self.model = c.module(model)(**kwargs)\n        self.long_term_path = os.path.expanduser(long_term_path)\n        self.short_term_capacity = short_term_capacity\n        self.default_ttl = default_ttl\n        \n        # Initialize memory stores\n        self.short_term = {}  # {key: {'data': Any, 'timestamp': float, 'ttl': int}}\n        \n        # Ensure long-term storage directory exists\n        os.makedirs(self.long_term_path, exist_ok=True)\n        \n    def add_short_term(\n        self, \n        key: str, \n        data: Any, \n        ttl: Optional[int] = None\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Add an item to short-term memory.\n        \n        Args:\n            key: Unique identifier for the memory\n            data: Data to store\n            ttl: Time-to-live in seconds (None for default)\n            \n        Returns:\n            Dictionary with status and info about the stored memory\n        \"\"\"\n        # Clean expired items first\n        self._clean_expired_short_term()\n        \n        # Check capacity\n        if len(self.short_term) >= self.short_term_capacity:\n            self._evict_short_term()\n            \n        # Store with timestamp\n        self.short_term[key] = {\n            'data': data,\n            'timestamp': time.time(),\n            'ttl': ttl if ttl is not None else self.default_ttl\n        }\n        \n        return {\n            'status': 'success',\n            'key': key,\n            'ttl': ttl if ttl is not None else self.default_ttl,\n            'expires_at': time.time() + (ttl if ttl is not None else self.default_ttl)\n        }\n    \n    def get_short_term(self, key: str) -> Optional[Any]:\n        \"\"\"\n        Retrieve an item from short-term memory.\n        \n        Args:\n            key: Key of the memory to retrieve\n            \n        Returns:\n            The stored data or None if not found or expired\n        \"\"\"\n        # Clean expired items first\n        self._clean_expired_short_term()\n        \n        if key in self.short_term:\n            # Update access timestamp (keeps frequently accessed items alive)\n            self.short_term[key]['timestamp'] = time.time()\n            return self.short_term[key]['data']\n        \n        return None\n    \n    def add_long_term(self, key: str, data: Any) -> Dict[str, Any]:\n        \"\"\"\n        Add an item to long-term memory.\n        \n        Args:\n            key: Unique identifier for the memory\n            data: Data to store\n            \n        Returns:\n            Dictionary with status and info about the stored memory\n        \"\"\"\n        # Sanitize key for filename\n        safe_key = self._sanitize_key(key)\n        file_path = os.path.join(self.long_term_path, f\"{safe_key}.json\")\n        \n        memory_data = {\n            'data': data,\n            'timestamp': time.time(),\n            'metadata': {\n                'created_at': time.time(),\n                'key': key,\n                'type': type(data).__name__\n            }\n        }\n        \n        try:\n            with open(file_path, 'w') as f:\n                json.dump(memory_data, f, indent=2)\n                \n            return {\n                'status': 'success',\n                'key': key,\n                'path': file_path\n            }\n        except Exception as e:\n            return {\n                'status': 'error',\n                'key': key,\n                'error': str(e)\n            }\n    \n    def get_long_term(self, key: str) -> Optional[Any]:\n        \"\"\"\n        Retrieve an item from long-term memory.\n        \n        Args:\n            key: Key of the memory to retrieve\n            \n        Returns:\n            The stored data or None if not found\n        \"\"\"\n        safe_key = self._sanitize_key(key)\n        file_path = os.path.join(self.long_term_path, f\"{safe_key}.json\")\n        \n        if os.path.exists(file_path):\n            try:\n                with open(file_path, 'r') as f:\n                    memory_data = json.load(f)\n                return memory_data['data']\n            except Exception:\n                return None\n        \n        return None\n    \n    def list_memories(\n        self, \n        memory_type: str = 'all'\n    ) -> Dict[str, List[str]]:\n        \"\"\"\n        List available memories.\n        \n        Args:\n            memory_type: Type of memories to list ('short', 'long', or 'all')\n            \n        Returns:\n            Dictionary with lists of memory keys\n        \"\"\"\n        result = {'short_term': [], 'long_term': []}\n        \n        # Clean expired items first\n        self._clean_expired_short_term()\n        \n        if memory_type in ['short', 'all']:\n            result['short_term'] = list(self.short_term.keys())\n            \n        if memory_type in ['long', 'all']:\n            try:\n                files = os.listdir(self.long_term_path)\n                result['long_term'] = [\n                    os.path.splitext(f)[0] for f in files \n                    if f.endswith('.json')\n                ]\n            except Exception:\n                result['long_term'] = []\n                \n        return result\n    \n    def delete_memory(\n        self, \n        key: str, \n        memory_type: str = 'all'\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Delete a memory.\n        \n        Args:\n            key: Key of the memory to delete\n            memory_type: Type of memory to delete ('short', 'long', or 'all')\n            \n        Returns:\n            Dictionary with deletion status\n        \"\"\"\n        result = {'status': 'success', 'deleted': []}\n        \n        if memory_type in ['short', 'all']:\n            if key in self.short_term:\n                del self.short_term[key]\n                result['deleted'].append('short_term')\n                \n        if memory_type in ['long', 'all']:\n            safe_key = self._sanitize_key(key)\n            file_path = os.path.join(self.long_term_path, f\"{safe_key}.json\")\n            \n            if os.path.exists(file_path):\n                try:\n                    os.remove(file_path)\n                    result['deleted'].append('long_term')\n                except Exception as e:\n                    result['status'] = 'partial'\n                    result['error'] = str(e)\n        \n        if not result['deleted']:\n            result['status'] = 'not_found'\n            \n        return result\n    \n    def forward(\n        self, \n        data: Union[List[str], Dict[str, Any], str],\n        query: str = None,\n        n: int = 5,\n        memory_type: str = 'short',\n        store: bool = True,\n        key: str = None,\n        **kwargs\n    ) -> Union[List[str], Dict[str, Any], str]:\n        \"\"\"\n        Process data through memory, optionally storing it and retrieving\n        relevant items based on a query.\n        \n        Args:\n            data: Data to process (can be a list, dict, or string)\n            query: Optional query to filter/retrieve relevant memories\n            n: Number of items to return when filtering\n            memory_type: Where to store/retrieve from ('short' or 'long')\n            store: Whether to store the data in memory\n            key: Optional key for storing (generated if not provided)\n            **kwargs: Additional arguments for the model\n            \n        Returns:\n            Processed data, potentially filtered by relevance to query\n        \"\"\"\n        # Generate a key if not provided\n        if store and key is None:\n            if isinstance(data, str):\n                key = f\"mem_{hash(data) & 0xffffffff}\"\n            else:\n                key = f\"mem_{int(time.time())}_{hash(str(data)) & 0xffffffff}\"\n        \n        # Store the data if requested\n        if store:\n            if memory_type == 'short':\n                self.add_short_term(key, data)\n            else:\n                self.add_long_term(key, data)\n        \n        # If there's a query, filter the data by relevance\n        if query and isinstance(data, list):\n            return self._filter_by_relevance(data, query, n, **kwargs)\n        \n        return data\n    \n    def _filter_by_relevance(\n        self, \n        items: List[Any], \n        query: str, \n        n: int = 5,\n        **kwargs\n    ) -> List[Any]:\n        \"\"\"\n        Filter a list of items by relevance to a query.\n        \n        Args:\n            items: List of items to filter\n            query: Query to compare against\n            n: Maximum number of items to return\n            **kwargs: Additional arguments for the model\n            \n        Returns:\n            List of most relevant items\n        \"\"\"\n        if not items:\n            return []\n        \n        # For simple string items, we can use the model to score relevance\n        if all(isinstance(item, str) for item in items):\n            # Prepare the prompt for relevance scoring\n            prompt = str({\n                \"task\": \"Rank these items by relevance to the query and return the top N most relevant items.\",\n                \"query\": query,\n                \"items\": items,\n                \"n\": n,\n                \"format\": \"Return a JSON array of the most relevant items in order of relevance.\"\n            })\n            \n            try:\n                # Get relevance scores from model\n                result = self.model.forward(prompt, **kwargs)\n                \n                # Parse the result - expecting a JSON array\n                import re\n                json_match = re.search(r'\\[.*\\]', result, re.DOTALL)\n                if json_match:\n                    try:\n                        relevant_items = json.loads(json_match.group(0))\n                        # Ensure we only return items that were in the original list\n                        return [item for item in relevant_items if item in items][:n]\n                    except json.JSONDecodeError:\n                        pass\n            except Exception as e:\n                c.print(f\"Error in relevance filtering: {e}\", color=\"red\")\n        \n        # Fallback: return first n items\n        return items[:n]\n    \n    def _clean_expired_short_term(self) -> int:\n        \"\"\"\n        Remove expired items from short-term memory.\n        \n        Returns:\n            Number of items removed\n        \"\"\"\n        now = time.time()\n        expired_keys = [\n            key for key, value in self.short_term.items()\n            if now > value['timestamp'] + value['ttl']\n        ]\n        \n        for key in expired_keys:\n            del self.short_term[key]\n            \n        return len(expired_keys)\n    \n    def _evict_short_term(self) -> None:\n        \"\"\"\n        Evict items from short-term memory when capacity is reached.\n        Uses LRU (Least Recently Used) strategy.\n        \"\"\"\n        if not self.short_term:\n            return\n            \n        # Find oldest item by timestamp\n        oldest_key = min(\n            self.short_term.keys(),\n            key=lambda k: self.short_term[k]['timestamp']\n        )\n        \n        # Remove it\n        del self.short_term[oldest_key]\n    \n    def _sanitize_key(self, key: str) -> str:\n        \"\"\"\n        Sanitize a key for use as a filename.\n        \n        Args:\n            key: Key to sanitize\n            \n        Returns:\n            Sanitized key\n        \"\"\"\n        # Replace invalid filename characters\n        import re\n        return re.sub(r'[^\\w\\-\\.]', '_', str(key))\n    \n    def search_long_term(\n        self, \n        query: str, \n        n: int = 5,\n        **kwargs\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Search long-term memory for relevant items.\n        \n        Args:\n            query: Search query\n            n: Maximum number of items to return\n            **kwargs: Additional arguments for the model\n            \n        Returns:\n            List of relevant memory items with metadata\n        \"\"\"\n        # Get all long-term memories\n        memories = []\n        try:\n            files = os.listdir(self.long_term_path)\n            for filename in files:\n                if filename.endswith('.json'):\n                    file_path = os.path.join(self.long_term_path, filename)\n                    try:\n                        with open(file_path, 'r') as f:\n                            memory_data = json.load(f)\n                            memories.append({\n                                'key': os.path.splitext(filename)[0],\n                                'data': memory_data['data'],\n                                'timestamp': memory_data['timestamp'],\n                                'metadata': memory_data.get('metadata', {})\n                            })\n                    except Exception:\n                        continue\n        except Exception as e:\n            c.print(f\"Error searching long-term memory: {e}\", color=\"red\")\n            return []\n        \n        if not memories:\n            return []\n            \n        # Use the model to rank memories by relevance\n        memory_texts = [\n            f\"Memory {i}: {str(mem['data'])[:500]}\" \n            for i, mem in enumerate(memories)\n        ]\n        \n        prompt = str({\n            \"task\": \"Rank these memory items by relevance to the query and return the indices of the top N most relevant items in order.\",\n            \"query\": query,\n            \"memory_items\": memory_texts,\n            \"n\": n,\n            \"format\": \"Return a JSON array of indices, e.g. [2, 5, 0]\"\n        })\n        \n        try:\n            result = self.model.forward(prompt, **kwargs)\n            \n            # Parse the result - expecting a JSON array of indices\n            import re\n            json_match = re.search(r'\\[.*\\]', result, re.DOTALL)\n            if json_match:\n                try:\n                    indices = json.loads(json_match.group(0))\n                    # Return the memories in order of relevance\n                    return [memories[i] for i in indices if i < len(memories)]\n                except (json.JSONDecodeError, TypeError, IndexError):\n                    pass\n        except Exception as e:\n            c.print(f\"Error in relevance ranking: {e}\", color=\"red\")\n        \n        # Fallback: return most recent memories\n        memories.sort(key=lambda x: x['timestamp'], reverse=True)\n        return memories[:n]\n    \n    def summarize_memories(\n        self, \n        query: Optional[str] = None, \n        memory_type: str = 'all',\n        **kwargs\n    ) -> str:\n        \"\"\"\n        Generate a summary of relevant memories.\n        \n        Args:\n            query: Optional query to filter relevant memories\n            memory_type: Type of memories to summarize ('short', 'long', or 'all')\n            **kwargs: Additional arguments for the model\n            \n        Returns:\n            Summary text\n        \"\"\"\n        memories = []\n        \n        # Collect short-term memories if requested\n        if memory_type in ['short', 'all']:\n            self._clean_expired_short_term()\n            for key, value in self.short_term.items():\n                memories.append({\n                    'key': key,\n                    'data': value['data'],\n                    'source': 'short_term',\n                    'timestamp': value['timestamp']\n                })\n        \n        # Collect long-term memories if requested\n        if memory_type in ['long', 'all']:\n            long_term_memories = self.search_long_term(\n                query if query else \"recent important information\", \n                n=10,\n                **kwargs\n            )\n            for mem in long_term_memories:\n                memories.append({\n                    'key': mem['key'],\n                    'data': mem['data'],\n                    'source': 'long_term',\n                    'timestamp': mem['timestamp']\n                })\n        \n        if not memories:\n            return \"No memories available.\"\n        \n        # Sort by timestamp (newest first)\n        memories.sort(key=lambda x: x['timestamp'], reverse=True)\n        \n        # Filter by relevance if query provided\n        if query:\n            memory_texts = [\n                f\"Memory {i} ({mem['source']}): {str(mem['data'])[:500]}\" \n                for i, mem in enumerate(memories)\n            ]\n            \n            prompt = str({\n                \"task\": \"Filter these memory items by relevance to the query and return the indices of relevant items.\",\n                \"query\": query,\n                \"memory_items\": memory_texts,\n                \"format\": \"Return a JSON array of indices, e.g. [2, 5, 0]\"\n            })\n            \n            try:\n                result = self.model.forward(prompt, **kwargs)\n                \n                # Parse the result\n                import re\n                json_match = re.search(r'\\[.*\\]', result, re.DOTALL)\n                if json_match:\n                    try:\n                        indices = json.loads(json_match.group(0))\n                        memories = [memories[i] for i in indices if i < len(memories)]\n                    except (json.JSONDecodeError, TypeError, IndexError):\n                        pass\n            except Exception:\n                pass\n        \n        # Generate summary\n        memory_texts = [\n            f\"Memory {i+1} ({mem['source']}): {str(mem['data'])}\" \n            for i, mem in enumerate(memories)\n        ]\n        \n        prompt = str({\n            \"task\": \"Summarize these memory items into a coherent summary.\",\n            \"memory_items\": memory_texts,\n            \"query\": query if query else \"Summarize recent important information\",\n            \"format\": \"Return a concise summary that captures the key information.\"\n        })\n        \n        try:\n            summary = self.model.forward(prompt, **kwargs)\n            return summary\n        except Exception as e:\n            return f\"Error generating summary: {e}\"\n",
        "tool/select_files.py": "\nimport commune as c\nimport json\nimport os\nfrom typing import List, Dict, Union, Optional, Any\n\nprint = c.print\nclass SelectFiles:\n    \"\"\"\n    Advanced search and relevance ranking module powered by LLMs.\n    \n    This module helps find the most relevant items from a list of options based on a query,\n    using LLM-based semantic understanding to rank and filter options.\n    \"\"\"\n\n    def __init__(self, provider='dev.model.openrouter'):\n        \"\"\"\n        Initialize the Find module.\n        \n        Args:\n            model: Pre-initialized model instance (optional)\n            default_provider: Provider to use if no model is provided\n            default_model: Default model to use for ranking\n        \"\"\"\n        self.model = c.module(provider)()\n\n    def forward(self,  \n              query: str = 'most relevant', \n              path: Union[List[str], Dict[Any, str]] = './',  \n              n: int = 10,  \n              trials: int = 3,\n              min_score: int = 0,\n              max_score: int = 10,\n              threshold: int = 5,\n              model: str = None,\n              context: Optional[str] = None,\n              temperature: float = 0.5,\n              allow_selection: bool = False,\n              verbose: bool = True) -> List[str]:\n        \"\"\"\n        Find the most relevant options based on a query.\n        \n        Args:\n            options: List of options or dictionary of options\n            query: Search query to match against options\n            n: Maximum number of results to return\n            trials: Number of retry attempts if an error occurs\n            min_score: Minimum possible score\n            max_score: Maximum possible score\n            threshold: Minimum score required to include in results\n            model: Model to use for ranking\n            context: Additional context to help with ranking\n            temperature: Temperature for generation (lower = more deterministic)\n            allow_selection: Whether to allow user to select files by index\n            verbose: Whether to print output during generation\n            \n        Returns:\n            List of the most relevant options\n        \"\"\"\n        \n\n        anchors = [\"<START_JSON>\", \"</END_JSON>\"]\n        options = self.files(path)\n        home_path = os.path.expanduser(\"~\")\n        idx2options = {i: option.replace(home_path, '~') for i, option in enumerate(options)}\n        if not idx2options:\n            return []\n           \n        # Format context if provided\n        context_str = f\"\\nCONTEXT:\\n{context}\" if context else \"\"\n        \n        # Build the prompt\n\n        prompt = f'''\n        --QUERY--\n        {query}\n        {context_str}\n        --OPTIONS--\n        {idx2options} \n        --RULES--\n        - Evaluate each option based on its relevance to the query\n        - Return at most {n} options with their scores\n        - Score range: {min_score} (lowest) to {max_score} (highest)\n        - Only include options with scores >= {threshold}\n        - Be conservative with scoring to prioritize quality over quantity\n        - Respond ONLY with the JSON format specified below\n        --OUTPUT_FORMAT--\n        {anchors[0]}(data:(idx:INT, score:INT)]){anchors[1]}\n        '''\n        \n        # Generate the response\n        output = ''\n\n        response = self.model.forward( \n            prompt, \n            model=model, \n            stream=True,\n            temperature=temperature\n        )\n        for ch in response: \n            if verbose:\n                print(ch, end='')\n            output += ch\n            if anchors[1] in output:\n                break\n                \n        # Extract and parse the JSON\n        try:\n            if anchors[0] in output:\n                json_str = output.split(anchors[0])[1].split(anchors[1])[0]\n            else:\n                json_str = output\n                \n            if verbose:\n                print(\"\\nParsing response...\", color=\"cyan\")\n                \n            result = json.loads(json_str)\n            \n            # Validate the response structure\n            if not isinstance(result, dict) or \"data\" not in result:\n                if verbose:\n                    print(\"Invalid response format, missing 'data' field\", color=\"red\")\n                result = {\"data\": []}\n                \n            # Filter and convert to final output format\n            filtered_options = []\n            for item in result[\"data\"]:\n                if isinstance(item, dict) and \"idx\" in item and \"score\" in item:\n                    idx, score = item[\"idx\"], item[\"score\"]\n                    if score >= threshold and idx in idx2options:\n                        filtered_options.append((idx, idx2options[idx]))         \n            if verbose:\n                print(f\"Found {filtered_options} relevant options\", color=\"green\")\n            # Allow user to select files by index if requested\n            if allow_selection and filtered_options:\n                selected_options = self.select_by_index(filtered_options, verbose)\n                return [option[1] for option in selected_options]\n            return [os.path.expanduser(option[1]) for option in filtered_options]\n            \n        except json.JSONDecodeError as e:\n            if verbose:\n                print(f\"JSON parsing error: {e}\", color=\"red\")\n                print(f\"Raw output: {output}\", color=\"red\")\n            if trials > 0:\n                print(f\"Retrying... ({trials} attempts left)\", color=\"yellow\")\n                return self.forward(options, query, n, trials - 1, min_score, max_score, threshold, model, context, temperature, allow_selection, verbose)\n            raise ValueError(f\"Failed to parse LLM response as JSON: {e}\")\n    \n    def select_by_index(self, options, verbose=True):\n        \"\"\"\n        Allow user to select files by index from a list of options.\n        \n        Args:\n            options: List of tuples containing (idx, option)\n            verbose: Whether to print output during selection\n            \n        Returns:\n            List of selected options\n        \"\"\"\n        if verbose:\n            print(\"\\nSelect files by index (comma-separated, e.g. '0,2,3')\", color=\"yellow\")\n            print(\"Press Enter to accept all files, or Ctrl+C to cancel\", color=\"yellow\")\n            \n        # Display options with indices\n        for i, (idx, option) in enumerate(options):\n            print(f\"[{i}] {option}\", color=\"cyan\")\n        \n        try:\n            # Get user input\n            selection = input(\"\\nEnter indices of files to select: \")\n            \n            # If empty, select all\n            if not selection.strip():\n                if verbose:\n                    print(\"Selecting all files\", color=\"green\")\n                return options\n            \n            # Parse selection\n            selected_indices = [int(idx.strip()) for idx in selection.split(',') if idx.strip().isdigit()]\n            selected_options = [options[idx] for idx in selected_indices if 0 <= idx < len(options)]\n            \n            if verbose:\n                print(f\"Selected {len(selected_options)} files\", color=\"green\")\n            \n            return selected_options\n            \n        except (KeyboardInterrupt, EOFError):\n            # Handle keyboard interrupt (Ctrl+C) or EOF\n            if verbose:\n                print(\"\\nSelection cancelled, defaulting to all files\", color=\"yellow\")\n            return options\n        except Exception as e:\n            # Handle any other errors\n            if verbose:\n                print(f\"\\nError during selection: {e}\", color=\"red\")\n                print(\"Defaulting to all files\", color=\"yellow\")\n            return options\n\n    def files(self, path: str) -> List[str]:\n        return c.files(path)",
        "tool/summarize.py": "\nimport commune as c\nimport json\nimport os\nfrom typing import List, Dict, Union, Optional, Any\n\nprint = c.print\nclass Summarize:\n    \"\"\"\n    Advanced search and relevance ranking module powered by LLMs.\n    \n    This module helps find the most relevant items from a list of options based on a query,\n    using LLM-based semantic understanding to rank and filter options.\n    \"\"\"\n\n    \n    def __init__(self, provider='dev.model.openrouter'):\n        \"\"\"\n        Initialize the Find module.\n        \n        Args:\n            model: Pre-initialized model instance (optional)\n            default_provider: Provider to use if no model is provided\n            default_model: Default model to use for ranking\n        \"\"\"\n        self.model = c.module(provider)()\n        self.anchors = [\"<START_JSON>\", \"</END_JSON>\"]\n\n    def forward(self,  \n              path: str = __file__, # Path to the file containing options or a file  \n              query: str = 'most relevant', \n              model: str = None,\n              temperature: float = 0.5,\n              task = None,\n              verbose: bool = True) -> List[str]:\n        anchors = self.anchors\n        # Format context if provided\n        assert os.path.exists(path), f\"File not found: {path}\"\n        assert os.path.isfile(path), f\"Path is not a file: {path}\"\n        content = c.text(path)\n\n        # hash\n        cache_path = 'reuslts/' + c.hash(path)\n\n        # Build the prompt\n\n        prompt = f'''\n        TASK\n        - summarize the follwoing based on the format based on the wquery \n        - query --> {query}\n        CONTENT\n        {content} \n        RESULT_FORMAT\n        {anchors[0]}(LIST(DICT(obj:str, desc:str))){anchors[1]}\n        '''\n        \n        # Generate the response\n        output = ''\n        response = self.model.forward( \n            prompt, \n            model=model, \n            stream=True,\n            temperature=temperature\n        )\n\n        # PROCEESS THE REPSONSE \n        for ch in response: \n            if verbose:\n                print(ch, end='')\n            output += ch\n\n        output = anchors[0].join(output.split(anchors[0])[1:])\n        output = anchors[1].join(output.split(anchors[1])[:-1])\n        if verbose:\n            print(\"\\nParsing response...\", color=\"cyan\")\n            \n        result =   json.loads(output)\n    \n        return result\n",
        "tool/tool.py": "\nimport commune as c\nimport json\nimport os\nfrom typing import List, Dict, Union, Optional, Any\nimport importlib\nimport inspect\n\nprint = c.print\n\nclass Tool:\n\n\n    fn = 'forward'\n    \"\"\"\n    A toolbox that provides access to various tools and can intelligently select\n    the most appropriate tool based on a query.\n    \n    This module helps organize and access tools within the dev.tool namespace,\n    with the ability to automatically select the most relevant tool for a given task.\n    \"\"\"\n    def __init__(self, model='dev.model.openrouter', prefix='dev.tool'):\n\n        self.prefix = prefix\n        self.model = c.module(model)()\n\n    def forward(\n        self, \n        query: str = 'i want to edit a file of ./', \n        *extra_query,\n        tools: Optional[List[str]] = None, \n        **kwargs\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Forward the query to the appropriate tool based on the provided query.\n        \n        Args:\n            query (str): The query to be processed.\n            tools (List[str], optional): List of specific tools to consider. If None, all tools are considered.\n            **kwargs: Additional arguments to pass to the selected tool.\n        \n        Returns:\n            Dict[str, Any]: The result from the selected tool.\n        \"\"\"\n        \n        # Forward the query to the selected tool\n        prompt = self.preprocess(\" \".join([query] + list(extra_query)))\n        output  =  self.model.forward(prompt, **kwargs)\n        output = self.postprocess(output)\n        return output\n\n        \n    def preprocess(self, prompt):\n\n        selector = c.mod('dev.tool.select')()\n        tool2schema  = self.tool2schema()\n        module =  selector.forward(query=query, options=tool2schema, n=1, **kwargs)[0]['name']\n        tool_schema = c.schema(module)\n        # get the function name from the module\n        fn_name = selector.forward(query=query, options=tool_schema, n=1, **kwargs)[0]['name']\n        anchors = ['<PARAMS>', '</PARAMS>']\n        prompt = str({\n            \"query\": query,\n            \"schema\": schema[fn_name],\n            'task': 'your goal is to create a plan of selecting at least one tool to be execturd',\n            'outputformat': f\"{anchors[0]}\\nLIST(DICT(FN, PARAMS))\\n{anchors[1]}\\n\",\n        })\n\n    def postprocess(self, output):\n        return json.loads(output.split(anchors[0])[1].split(anchors[1])[0])\n\n\n    def tools(self) -> List[str]:\n        return [t for t in  c.mods() if t.startswith(self.prefix)]\n\n\n    def tool2code(self) -> str:\n        tool2schema = {\n            tool: c.schema(tool, include_code=True)\n            for tool in self.tools()\n        }\n        \n    \n    def tool2schema(self) -> Dict[str, str]:\n        \"\"\"\n        Map each tool to its schema.\n        \n        Returns:\n            Dict[str, str]: Dictionary mapping tool names to their schemas.\n        \"\"\"\n        tool2schema = {}\n        for tool in self.tools():\n            tool2schema[tool] = self.schema(tool)\n            tool2schema[tool].pop('name', None)\n            tool2schema[tool].pop('format', None)\n        return tool2schema\n    \n    def schema(self, tool: str,) -> Dict[str, str]:\n        \"\"\"\n        Get the schema for a specific tool.\n        \n        Args:\n            tool (str): The name of the tool.\n        \n        Returns:\n            Dict[str, str]: The schema for the specified tool.\n        \"\"\"\n        fn = self.fn\n        schema =  c.fnschema(getattr( c.module(tool), fn))\n        schema['input'].pop('self', None)\n        params_format = ' '.join([f'<{k.upper()}>{v[\"type\"]}</{k.upper()}>' for k,v in schema['input'].items()]) \n        fn_format = f'FN::{fn.upper()}'\n        schema['format'] =  f'<{fn_format}>' + params_format + f'</{fn_format}>'\n        return schema\n\n    def tool2code(self) -> Dict[str, str]:\n        \"\"\"\n        Map each tool to its code.\n        \n        Returns:\n            Dict[str, str]: Dictionary mapping tool names to their code.\n        \"\"\"\n        tool2code = {\n            tool: c.code(tool)\n            for tool in self.tools()\n        }\n        return tool2code\n\n    def tool2size(self) -> Dict[str, int]:\n        \"\"\"\n        Map each tool to its code size.\n        \n        Returns:\n            Dict[str, int]: Dictionary mapping tool names to their code size.\n        \"\"\"\n        tool2code_size = {\n            tool: len(c.code(tool))\n            for tool in self.tools()\n        }\n        return tool2code_size\n\n",
        "tool/web_scraper.py": "import commune as c\nimport requests\nimport json\nimport os\nimport time\nfrom typing import List, Dict, Union, Optional, Any\nfrom bs4 import BeautifulSoup\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.chrome.service import Service\nfrom webdriver_manager.chrome import ChromeDriverManager\n\nprint = c.print\n\nclass WebScraper:\n    \"\"\"\n    A tool for scraping the web and retrieving relevant information based on queries\n    without relying on search engine APIs.\n    \n    This tool provides functionality to:\n    - Search the web using direct scraping of search engines\n    - Extract and format relevant information from search results\n    - Return context that can be used for further processing\n    - Cache results to minimize redundant requests\n    \"\"\"\n    \n    def __init__(self, \n                 search_engine: str = 'bing',\n                 cache_dir: str = '~/.commune/web_scraper_cache',\n                 cache_expiry: int = 3600,  # 1 hour\n                 use_selenium: bool = True,\n                 headless: bool = True,\n                 **kwargs):\n        \"\"\"\n        Initialize the WebScraper tool.\n        \n        Args:\n            search_engine: Search engine to use ('google', 'bing', 'duckduckgo')\n            cache_dir: Directory to store cached results\n            cache_expiry: Time in seconds before cache entries expire\n            use_selenium: Whether to use Selenium for JavaScript-heavy sites\n            headless: Whether to run browser in headless mode (Selenium only)\n            **kwargs: Additional configuration parameters\n        \"\"\"\n        self.search_engine = search_engine.lower()\n        self.cache_dir = os.path.expanduser(cache_dir)\n        self.cache_expiry = cache_expiry\n        self.use_selenium = use_selenium\n        self.headless = headless\n        self.driver = None\n        \n        # Create cache directory if it doesn't exist\n        if not os.path.exists(self.cache_dir):\n            os.makedirs(self.cache_dir, exist_ok=True)\n        \n        # Set up search engine configurations\n        self.engine_configs = {\n            'google': {\n                'search_url': 'https://www.google.com/search?q={query}&num={num_results}',\n                'result_selector': 'div.g',\n                'title_selector': 'h3',\n                'link_selector': 'a',\n                'snippet_selector': 'div.VwiC3b',\n                'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36'\n            },\n            'bing': {\n                'search_url': 'https://www.bing.com/search?q={query}&count={num_results}',\n                'result_selector': '.b_algo',\n                'title_selector': 'h2',\n                'link_selector': 'a',\n                'snippet_selector': '.b_caption p',\n                'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36'\n            },\n            'duckduckgo': {\n                'search_url': 'https://html.duckduckgo.com/html/?q={query}',\n                'result_selector': '.result',\n                'title_selector': '.result__title',\n                'link_selector': '.result__url',\n                'snippet_selector': '.result__snippet',\n                'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36'\n            }\n        }\n        \n        # Validate configuration\n        if self.search_engine not in self.engine_configs:\n            raise ValueError(f\"Unsupported search engine: {self.search_engine}. Supported engines: {list(self.engine_configs.keys())}\")\n    \n    def _initialize_selenium(self):\n        \"\"\"\n        Initialize Selenium WebDriver if not already initialized.\n        \"\"\"\n        if self.driver is not None:\n            return\n        \n        try:\n            chrome_options = Options()\n            if self.headless:\n                chrome_options.add_argument('--headless')\n            chrome_options.add_argument('--no-sandbox')\n            chrome_options.add_argument('--disable-dev-shm-usage')\n            chrome_options.add_argument(f\"user-agent={self.engine_configs[self.search_engine]['user_agent']}\")\n            \n            # Initialize Chrome WebDriver\n            service = Service(ChromeDriverManager().install())\n            self.driver = webdriver.Chrome(service=service, options=chrome_options)\n            print(\"Selenium WebDriver initialized successfully\", color=\"green\")\n        except Exception as e:\n            print(f\"Failed to initialize Selenium WebDriver: {e}\", color=\"red\")\n            self.use_selenium = False\n    \n    def _close_selenium(self):\n        \"\"\"\n        Close Selenium WebDriver if it's open.\n        \"\"\"\n        if self.driver is not None:\n            try:\n                self.driver.quit()\n            except Exception:\n                pass\n            finally:\n                self.driver = None\n    \n    def forward(self,\n                query: str,\n                num_results: int = 5,\n                include_snippets: bool = True,\n                include_links: bool = True,\n                filter_domains: Optional[List[str]] = None,\n                safe_search: bool = True,\n                use_cache: bool = False,\n                cache_key: Optional[str] = None,\n                verbose: bool = True) -> Dict[str, Any]:\n        \"\"\"\n        Search the web for information related to the query.\n        \n        Args:\n            query: Search query string\n            num_results: Number of results to return\n            include_snippets: Whether to include text snippets in results\n            include_links: Whether to include links in results\n            filter_domains: List of domains to include/exclude (e.g., ['wikipedia.org'])\n            safe_search: Whether to enable safe search filtering\n            use_cache: Whether to use cached results if available\n            cache_key: Custom key for caching (defaults to query hash)\n            verbose: Whether to print detailed information\n            \n        Returns:\n            Dictionary containing:\n            - success: Whether the search was successful\n            - results: List of search results\n            - context: Extracted context from results\n            - query: Original search query\n            - source: Search engine used\n        \"\"\"\n        if verbose:\n            c.print(f\"Searching for: {query}\", color=\"cyan\")\n        \n        # Generate cache key if not provided\n        if use_cache and not cache_key:\n            cache_key = f\"{self.search_engine}_{hash(query)}_{num_results}\"\n        \n        # Check cache first if enabled\n        if use_cache:\n            cached_result = self._get_from_cache(cache_key)\n            if cached_result:\n                if verbose:\n                    c.print(f\"Retrieved results from cache\", color=\"green\")\n                return cached_result\n        \n        try:\n            # Perform search based on engine\n            if self.use_selenium:\n                # Initialize Selenium if needed\n                self._initialize_selenium()\n                results = self._search_with_selenium(query, num_results, safe_search, filter_domains)\n            else:\n                results = self._search_with_requests(query, num_results, safe_search, filter_domains)\n            \n            # Process results\n            processed_results = []\n            for result in results:\n                processed_result = {}\n                \n                if include_links and 'link' in result:\n                    processed_result['url'] = result['link']\n                \n                if 'title' in result:\n                    processed_result['title'] = result['title']\n                \n                if include_snippets and 'snippet' in result:\n                    processed_result['snippet'] = result['snippet']\n                \n                processed_results.append(processed_result)\n            \n            # Extract context from results\n            context = self._extract_context(processed_results)\n            \n            # Prepare response\n            response = {\n                \"success\": True,\n                \"results\": processed_results,\n                \"context\": context,\n                \"query\": query,\n                \"source\": self.search_engine\n            }\n            \n            # Cache the results if enabled\n            if use_cache:\n                self._save_to_cache(cache_key, response)\n            \n            if verbose:\n                c.print(f\"Found {len(processed_results)} results\", color=\"green\")\n                if len(processed_results) > 0:\n                    c.print(\"Top result:\", color=\"blue\")\n                    c.print(f\"Title: {processed_results[0].get('title', 'N/A')}\")\n                    if include_snippets:\n                        c.print(f\"Snippet: {processed_results[0].get('snippet', 'N/A')}\")\n            \n            return response\n            \n        except Exception as e:\n            error_msg = f\"Search failed: {str(e)}\"\n            if verbose:\n                c.print(error_msg, color=\"red\")\n            \n            return {\n                \"success\": False,\n                \"error\": error_msg,\n                \"query\": query,\n                \"source\": self.search_engine\n            }\n        finally:\n            # Close Selenium if we're not caching the driver\n            if self.use_selenium and not getattr(self, 'keep_driver_alive', False):\n                self._close_selenium()\n    \n    def _search_with_selenium(self, query, num_results, safe_search, filter_domains):\n        \"\"\"\n        Perform a search using Selenium WebDriver.\n        \n        Args:\n            query: Search query\n            num_results: Number of results to return\n            safe_search: Whether to enable safe search\n            filter_domains: Domains to filter\n            \n        Returns:\n            List of search results\n        \"\"\"\n        config = self.engine_configs[self.search_engine]\n        \n        # Add domain filtering if specified\n        search_query = query\n        if filter_domains:\n            site_query = ' OR '.join([f'site:{domain}' for domain in filter_domains])\n            search_query = f\"({search_query}) {site_query}\"\n        \n        # Add safe search if enabled\n        if safe_search and self.search_engine == 'google':\n            search_query += \" &safe=active\"\n        \n        # Format the search URL\n        search_url = config['search_url'].format(query=search_query.replace(' ', '+'), num_results=num_results)\n        \n        # Navigate to the search page\n        self.driver.get(search_url)\n        time.sleep(2)  # Allow page to load\n        \n        # Extract search results\n        results = []\n        result_elements = self.driver.find_elements(By.CSS_SELECTOR, config['result_selector'])\n        \n        for element in result_elements[:num_results]:\n            try:\n                title_element = element.find_element(By.CSS_SELECTOR, config['title_selector'])\n                title = title_element.text.strip()\n                \n                link_element = title_element.find_element(By.CSS_SELECTOR, config['link_selector'])\n                link = link_element.get_attribute('href')\n                \n                snippet = \"\"\n                try:\n                    snippet_element = element.find_element(By.CSS_SELECTOR, config['snippet_selector'])\n                    snippet = snippet_element.text.strip()\n                except Exception:\n                    pass  # Snippet might not be available\n                \n                results.append({\n                    'title': title,\n                    'link': link,\n                    'snippet': snippet\n                })\n                \n                if len(results) >= num_results:\n                    break\n            except Exception as e:\n                print(f\"Error extracting result: {e}\", color=\"yellow\")\n        \n        return results\n    \n    def _search_with_requests(self, query, num_results, safe_search, filter_domains):\n        \"\"\"\n        Perform a search using requests and BeautifulSoup.\n        \n        Args:\n            query: Search query\n            num_results: Number of results to return\n            safe_search: Whether to enable safe search\n            filter_domains: Domains to filter\n            \n        Returns:\n            List of search results\n        \"\"\"\n        config = self.engine_configs[self.search_engine]\n        \n        # Add domain filtering if specified\n        search_query = query\n        if filter_domains:\n            site_query = ' OR '.join([f'site:{domain}' for domain in filter_domains])\n            search_query = f\"({search_query}) {site_query}\"\n        \n        # Add safe search if enabled\n        if safe_search and self.search_engine == 'google':\n            search_query += \" &safe=active\"\n        \n        # Format the search URL\n        search_url = config['search_url'].format(query=search_query.replace(' ', '+'), num_results=num_results)\n        \n        # Set up headers to mimic a browser\n        headers = {\n            'User-Agent': config['user_agent'],\n            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n            'Accept-Language': 'en-US,en;q=0.5',\n            'Referer': f\"https://www.{self.search_engine}.com/\",\n            'DNT': '1',\n            'Connection': 'keep-alive',\n            'Upgrade-Insecure-Requests': '1'\n        }\n        \n        # Send request\n        response = requests.get(search_url, headers=headers)\n        response.raise_for_status()\n        \n        # Parse HTML\n        soup = BeautifulSoup(response.text, 'html.parser')\n        \n        # Extract search results\n        results = []\n        result_elements = soup.select(config['result_selector'])\n        \n        for element in result_elements[:num_results]:\n            try:\n                title_element = element.select_one(config['title_selector'])\n                title = title_element.get_text().strip() if title_element else 'No title'\n                \n                link_element = title_element.select_one(config['link_selector']) if title_element else None\n                link = link_element.get('href') if link_element else ''\n                \n                # For Google, links might be relative or in a special format\n                if self.search_engine == 'google' and link and not link.startswith('http'):\n                    if link.startswith('/url?q='):\n                        link = link.split('/url?q=')[1].split('&')[0]\n                \n                snippet_element = element.select_one(config['snippet_selector'])\n                snippet = snippet_element.get_text().strip() if snippet_element else ''\n                \n                results.append({\n                    'title': title,\n                    'link': link,\n                    'snippet': snippet\n                })\n                \n                if len(results) >= num_results:\n                    break\n            except Exception as e:\n                print(f\"Error extracting result: {e}\", color=\"yellow\")\n        \n        return results\n    \n    def _extract_context(self, results):\n        \"\"\"\n        Extract and format context from search results.\n        \n        Args:\n            results: List of search results\n            \n        Returns:\n            Formatted context string\n        \"\"\"\n        if not results:\n            return \"\"\n        \n        context = []\n        for i, result in enumerate(results):\n            title = result.get('title', 'No title')\n            snippet = result.get('snippet', 'No description available')\n            url = result.get('url', '')\n            \n            entry = f\"[{i+1}] {title}\\n\"\n            if snippet:\n                entry += f\"{snippet}\\n\"\n            if url:\n                entry += f\"Source: {url}\\n\"\n            \n            context.append(entry)\n        \n        return \"\\n\".join(context)\n    \n    def _get_from_cache(self, key):\n        \"\"\"\n        Retrieve results from cache if available and not expired.\n        \n        Args:\n            key: Cache key\n            \n        Returns:\n            Cached results or None if not found/expired\n        \"\"\"\n        cache_file = os.path.join(self.cache_dir, f\"{key}.json\")\n        \n        if not os.path.exists(cache_file):\n            return None\n        \n        # Check if cache is expired\n        if self.cache_expiry > 0:\n            file_age = time.time() - os.path.getmtime(cache_file)\n            if file_age > self.cache_expiry:\n                return None\n        \n        try:\n            with open(cache_file, 'r') as f:\n                return json.load(f)\n        except Exception:\n            return None\n    \n    def _save_to_cache(self, key, data):\n        \"\"\"\n        Save results to cache.\n        \n        Args:\n            key: Cache key\n            data: Data to cache\n        \"\"\"\n        cache_file = os.path.join(self.cache_dir, f\"{key}.json\")\n        \n        try:\n            with open(cache_file, 'w') as f:\n                json.dump(data, f)\n        except Exception as e:\n            c.print(f\"Failed to save to cache: {e}\", color=\"yellow\")\n    \n    def search_and_summarize(self,\n                            query: str,\n                            model: Optional[str] = None,\n                            num_results: int = 5,\n                            max_tokens: int = 300,\n                            verbose: bool = True) -> Dict[str, Any]:\n        \"\"\"\n        Search the web and generate a concise summary of the results.\n        \n        Args:\n            query: Search query\n            model: Model to use for summarization (uses default if None)\n            num_results: Number of search results to consider\n            max_tokens: Maximum length of summary\n            verbose: Whether to print detailed information\n            \n        Returns:\n            Dictionary containing:\n            - success: Whether the operation was successful\n            - summary: Generated summary\n            - query: Original search query\n            - results: Raw search results\n        \"\"\"\n        # First, search the web\n        search_results = self.forward(\n            query=query,\n            num_results=num_results,\n            verbose=verbose\n        )\n        \n        if not search_results[\"success\"]:\n            return search_results\n        \n        try:\n            # Get the model for summarization\n            llm = c.module('dev.model.openrouter')()\n            \n            # Create prompt for summarization\n            context = search_results[\"context\"]\n            prompt = f\"\"\"\n            Based on the following search results for the query \"{query}\", provide a concise, \n            informative summary of the key information. Focus on factual information and \n            include the most important points from multiple sources if available.\n            \n            SEARCH RESULTS:\n            {context}\n            \n            SUMMARY:\n            \"\"\"\n            \n            # Generate summary\n            summary = llm.forward(\n                prompt=prompt,\n                model=model,\n                max_tokens=max_tokens\n            )\n            \n            if verbose:\n                c.print(\"Generated summary:\", color=\"green\")\n                c.print(summary)\n            \n            return {\n                \"success\": True,\n                \"summary\": summary,\n                \"query\": query,\n                \"results\": search_results[\"results\"]\n            }\n            \n        except Exception as e:\n            error_msg = f\"Summarization failed: {str(e)}\"\n            if verbose:\n                c.print(error_msg, color=\"red\")\n            \n            return {\n                \"success\": False,\n                \"error\": error_msg,\n                \"query\": query,\n                \"results\": search_results[\"results\"]\n            }\n\n# Example usage\nif __name__ == \"__main__\":\n    scraper = WebScraper(use_selenium=True, headless=True)\n    results = scraper.forward(\"latest AI developments\", num_results=5)\n    print(results[\"context\"])\n",
        "utils.py": "\nimport os\nimport glob\nimport json\nimport shutil\nimport hashlib\nimport subprocess\nfrom pathlib import Path\nfrom typing import Dict, List, Union, Optional, Any, Tuple\n\ndef abspath(path):\n    \"\"\"\n    Convert a path to an absolute path, expanding user directory (~).\n    \n    Args:\n        path: Path to convert\n        \n    Returns:\n        Absolute path\n    \"\"\"\n    return os.path.abspath(os.path.expanduser(path))\n\ndef makedirs(path):\n    if not os.path.exists(path):\n        os.makedirs(path, exist_ok=True)\n    return path\n\ndef put_text(path, text):\n    \"\"\"\n    Write text to a file.\n    \n    Args:\n        path: Path to the file\n        text: Text to write\n        \n    Returns:\n        Dictionary with path and text\n    \"\"\"\n    path = abspath(path)\n    dirpath = os.path.dirname(path)\n    makedirs(dirpath)  # Ensure the directory exists\n    \n    # Ensure the directory exists\n    with open(path, 'w', encoding='utf-8') as f:\n        f.write(text)\n    return {'path': path, 'text': text}\n\ndef get_text(path):\n    \"\"\"\n    Read text from a file.\n    \n    Args:\n        path: Path to the file\n        \n    Returns:\n        Text content of the file\n    \"\"\"\n    if os.path.isdir(path):\n        file2text = {}\n        for root, _, files in os.walk(path):\n            for file in files:\n                file_path = os.path.join(root, file)\n                if os.path.isfile(file_path):\n                    path = os.path.abspath(file_path)\n                    file2text[file_path] = get_text(file_path)\n        return file2text\n    else:\n        try:\n            with open(path, 'r', encoding='utf-8') as f:\n                return f.read()\n        except Exception as e:\n            print(f\"Error reading file {path}: {e}\")\n            return None\n\ndef ensure_directory_exists(directory_path):\n    \"\"\"\n    Ensure that a directory exists, creating it if necessary.\n    \n    Args:\n        directory_path: Path to the directory\n    \"\"\"\n    if directory_path and not os.path.exists(directory_path):\n        os.makedirs(directory_path, exist_ok=True)\n\ndef list_files(directory, \n              pattern=\"*\", \n              recursive=True, \n              ignore_patterns=None,\n              max_size=None):\n    \"\"\"\n    List files in a directory matching a pattern.\n    \n    Args:\n        directory: Directory to search\n        pattern: Glob pattern to match\n        recursive: Whether to search recursively\n        ignore_patterns: Patterns to ignore\n        max_size: Maximum file size in bytes\n        \n    Returns:\n        List of file paths\n    \"\"\"\n    ignore_patterns = ignore_patterns or []\n    \n    if recursive:\n        matches = []\n        for root, dirnames, filenames in os.walk(directory):\n            # Filter out directories to ignore\n            for ignore_pattern in ignore_patterns:\n                dirnames[:] = [d for d in dirnames if not glob.fnmatch.fnmatch(d, ignore_pattern)]\n            \n            for filename in filenames:\n                if glob.fnmatch.fnmatch(filename, pattern) and not any(\n                    glob.fnmatch.fnmatch(filename, ignore) for ignore in ignore_patterns\n                ):\n                    file_path = os.path.join(root, filename)\n                    if max_size is None or os.path.getsize(file_path) <= max_size:\n                        matches.append(file_path)\n        return matches\n    else:\n        return [\n            f for f in glob.glob(os.path.join(directory, pattern))\n            if os.path.isfile(f) and not any(\n                glob.fnmatch.fnmatch(os.path.basename(f), ignore) for ignore in ignore_patterns\n            ) and (max_size is None or os.path.getsize(f) <= max_size)\n        ]\n\ndef detect_project_type(directory):\n    \"\"\"\n    Attempt to detect the type of project in a directory.\n    \n    Args:\n        directory: Directory to analyze\n        \n    Returns:\n        Project type string or None if unknown\n    \"\"\"\n    files = set(os.path.basename(f) for f in list_files(directory))\n    \n    # Check for various project types\n    if 'package.json' in files:\n        return 'node'\n    elif 'requirements.txt' in files or 'setup.py' in files or any(f.endswith('.py') for f in files):\n        if 'manage.py' in files and any('django' in get_text(os.path.join(directory, f)).lower() \n                                       for f in ['requirements.txt', 'setup.py'] if f in files):\n            return 'django'\n        elif 'app.py' in files and any('flask' in get_text(os.path.join(directory, f)).lower() \n                                     for f in ['requirements.txt', 'setup.py'] if f in files):\n            return 'flask'\n        elif 'main.py' in files and any('fastapi' in get_text(os.path.join(directory, f)).lower() \n                                      for f in ['requirements.txt', 'setup.py'] if f in files):\n            return 'fastapi'\n        return 'python'\n    elif 'pom.xml' in files or 'build.gradle' in files:\n        return 'java'\n    elif 'Cargo.toml' in files:\n        return 'rust'\n    elif 'go.mod' in files:\n        return 'go'\n    elif 'Gemfile' in files or 'config/routes.rb' in files:\n        return 'ruby_on_rails'\n    elif 'composer.json' in files:\n        return 'php'\n    elif 'CMakeLists.txt' in files:\n        return 'cmake'\n    elif 'Makefile' in files:\n        return 'make'\n    elif 'docker-compose.yml' in files or 'Dockerfile' in files:\n        return 'docker'\n    \n    return None\n\ndef calculate_file_hash(file_path):\n    \"\"\"\n    Calculate the SHA-256 hash of a file.\n    \n    Args:\n        file_path: Path to the file\n        \n    Returns:\n        Hex digest of the hash\n    \"\"\"\n    sha256_hash = hashlib.sha256()\n    with open(file_path, \"rb\") as f:\n        # Read and update hash in chunks\n        for byte_block in iter(lambda: f.read(4096), b\"\"):\n            sha256_hash.update(byte_block)\n    return sha256_hash.hexdigest()\n\ndef backup_directory(directory, backup_dir=None):\n    \"\"\"\n    Create a backup of a directory.\n    \n    Args:\n        directory: Directory to backup\n        backup_dir: Destination directory (default: directory + '.bak')\n        \n    Returns:\n        Path to the backup directory\n    \"\"\"\n    directory = abspath(directory)\n    if backup_dir is None:\n        backup_dir = directory + '.bak'\n    \n    backup_dir = abspath(backup_dir)\n    \n    # Ensure the backup directory exists\n    ensure_directory_exists(os.path.dirname(backup_dir))\n    \n    # Remove existing backup if it exists\n    if os.path.exists(backup_dir):\n        shutil.rmtree(backup_dir)\n    \n    # Create the backup\n    shutil.copytree(directory, backup_dir)\n    \n    return backup_dir\n\ndef run_command(command, cwd=None, capture_output=True):\n    \"\"\"\n    Run a shell command.\n    \n    Args:\n        command: Command to run\n        cwd: Working directory\n        capture_output: Whether to capture stdout/stderr\n        \n    Returns:\n        Dictionary with returncode, stdout, and stderr\n    \"\"\"\n    try:\n        result = subprocess.run(\n            command,\n            shell=True,\n            cwd=cwd,\n            capture_output=capture_output,\n            text=True\n        )\n        \n        return {\n            'returncode': result.returncode,\n            'stdout': result.stdout if capture_output else '',\n            'stderr': result.stderr if capture_output else '',\n            'success': result.returncode == 0\n        }\n    except Exception as e:\n        return {\n            'returncode': -1,\n            'stdout': '',\n            'stderr': str(e),\n            'success': False\n        }\n\ndef find_files_by_content(directory, search_text, file_pattern=\"*\", ignore_patterns=None):\n    \"\"\"\n    Find files containing specific text.\n    \n    Args:\n        directory: Directory to search\n        search_text: Text to search for\n        file_pattern: File pattern to match\n        ignore_patterns: Patterns to ignore\n        \n    Returns:\n        List of file paths containing the search text\n    \"\"\"\n    matching_files = []\n    files = list_files(directory, pattern=file_pattern, ignore_patterns=ignore_patterns)\n    \n    for file_path in files:\n        try:\n            content = get_text(file_path)\n            if search_text in content:\n                matching_files.append(file_path)\n        except:\n            # Skip files that can't be read as text\n            pass\n    \n    return matching_files\n\ndef diff_files(file1, file2):\n    \"\"\"\n    Compare two files and return the differences.\n    \n    Args:\n        file1: Path to the first file\n        file2: Path to the second file\n        \n    Returns:\n        Differences as a string\n    \"\"\"\n    file1_content = get_text(file1).splitlines()\n    file2_content = get_text(file2).splitlines()\n    \n    import difflib\n    differ = difflib.Differ()\n    diff = list(differ.compare(file1_content, file2_content))\n    \n    return '\\n'.join(diff)\n\ndef save_json(data, file_path):\n    \"\"\"\n    Save data as JSON.\n    \n    Args:\n        data: Data to save\n        file_path: Path to save to\n        \n    Returns:\n        Path to the saved file\n    \"\"\"\n    file_path = abspath(file_path)\n    ensure_directory_exists(os.path.dirname(file_path))\n    \n    with open(file_path, 'w', encoding='utf-8') as f:\n        json.dump(data, f, indent=2, ensure_ascii=False)\n    \n    return file_path\n\ndef load_json(file_path):\n    \"\"\"\n    Load data from JSON.\n    \n    Args:\n        file_path: Path to load from\n        \n    Returns:\n        Loaded data\n    \"\"\"\n    with open(file_path, 'r', encoding='utf-8') as f:\n        return json.load(f)\n\ndef get_file_info(file_path):\n    \"\"\"\n    Get information about a file.\n    \n    Args:\n        file_path: Path to the file\n        \n    Returns:\n        Dictionary with file information\n    \"\"\"\n    file_path = abspath(file_path)\n    stat = os.stat(file_path)\n    \n    return {\n        'path': file_path,\n        'size': stat.st_size,\n        'modified': stat.st_mtime,\n        'created': stat.st_ctime,\n        'extension': os.path.splitext(file_path)[1],\n        'is_binary': is_binary_file(file_path)\n    }\n\ndef is_binary_file(file_path, sample_size=1024):\n    \"\"\"\n    Check if a file is binary.\n    \n    Args:\n        file_path: Path to the file\n        sample_size: Number of bytes to check\n        \n    Returns:\n        True if the file is binary, False otherwise\n    \"\"\"\n    try:\n        with open(file_path, 'rb') as f:\n            sample = f.read(sample_size)\n        # Check for null bytes and high ratio of non-printable characters\n        textchars = bytearray({7, 8, 9, 10, 12, 13, 27} | set(range(0x20, 0x100)) - {0x7f})\n        return bool(sample.translate(None, textchars))\n    except:\n        return True\n\n"
    },
    "schema": {
        "forward": {
            "input": {
                "self": {
                    "value": "_empty",
                    "type": "_empty"
                },
                "text": {
                    "value": "",
                    "type": "str"
                },
                "extra_text": {
                    "value": "_empty",
                    "type": "_empty"
                },
                "path": {
                    "value": "./",
                    "type": "str"
                },
                "temperature": {
                    "value": 0.5,
                    "type": "float"
                },
                "max_tokens": {
                    "value": 1000000,
                    "type": "int"
                },
                "model": {
                    "value": "anthropic/claude-3.7-sonnet",
                    "type": "str"
                },
                "stream": {
                    "value": true,
                    "type": "bool"
                },
                "verbose": {
                    "value": true,
                    "type": "bool"
                },
                "mode": {
                    "value": "auto",
                    "type": "str"
                },
                "max_age": {
                    "value": 10000,
                    "type": "int"
                },
                "kwargs": {
                    "value": "_empty",
                    "type": "_empty"
                }
            },
            "output": {
                "value": null,
                "type": "typing.Dict[str, str]"
            },
            "docs": null,
            "cost": 1,
            "name": "forward",
            "source": {
                "start": 58,
                "length": 28,
                "path": "~/commune/commune/modules/dev/src/dev/dev.py",
                "code": null,
                "hash": "sha256:203f453835871603759144fb9a9eabc030cf1a8e73467383a15ce5af509dd335",
                "end": 86
            }
        },
        "postprocess": {
            "input": {
                "self": {
                    "value": "_empty",
                    "type": "_empty"
                },
                "output": {
                    "value": "_empty",
                    "type": "_empty"
                }
            },
            "output": {
                "value": null,
                "type": "None"
            },
            "docs": "\n        Postprocess tool outputs and extract fn calls.\n        \n        This fn parses the raw output text and identifies fn calls in the format:\n        <FN::function_name>param1</FN::function_name> or \n        <FN::function_name><param_name>param_value</param_name></FN::function_name>\n        \n        Args:\n            output (str): The raw output from the model\n                \n        Returns:\n            str: The processed output with extracted fn calls\n        ",
            "cost": 1,
            "name": "postprocess",
            "source": {
                "start": 129,
                "length": 38,
                "path": "~/commune/commune/modules/dev/src/dev/dev.py",
                "code": null,
                "hash": "sha256:2fee4b3a78c182c396e2c363747098534e73fadf8b55878911ae846c523e5c02",
                "end": 167
            }
        },
        "preprocess": {
            "input": {
                "self": {
                    "value": "_empty",
                    "type": "_empty"
                },
                "text": {
                    "value": "_empty",
                    "type": "_empty"
                },
                "threshold": {
                    "value": 1000,
                    "type": "int"
                }
            },
            "output": {
                "value": null,
                "type": "None"
            },
            "docs": null,
            "cost": 1,
            "name": "preprocess",
            "source": {
                "start": 88,
                "length": 27,
                "path": "~/commune/commune/modules/dev/src/dev/dev.py",
                "code": null,
                "hash": "sha256:f144396966fa0a525e20847a582c7907a6a7da91889e232999660f237ebe4477",
                "end": 115
            }
        },
        "test": {
            "input": {
                "self": {
                    "value": "_empty",
                    "type": "_empty"
                },
                "text": {
                    "value": "write a fn that adds two numbers and a test.js file that i can test it all in one class and have me test it in test.js and a script to run it",
                    "type": "str"
                }
            },
            "output": {
                "value": null,
                "type": "None"
            },
            "docs": "\n        Test the Dev module by generating code based on a prompt.\n        \n        Args:\n            text: The prompt text\n            \n        Returns:\n            Dictionary mapping file paths to generated content\n        ",
            "cost": 1,
            "name": "test",
            "source": {
                "start": 116,
                "length": 12,
                "path": "~/commune/commune/modules/dev/src/dev/dev.py",
                "code": null,
                "hash": "sha256:e9f418aa1b37b1e08a65f9a729997c7e9e34b9a73f7b31979f1de62a4eb59a56",
                "end": 128
            }
        }
    },
    "name": "dev",
    "key": "5CkJBMytUyuirCvaySjxUxd8jyc9XAdsRavCd311LQ8WbvaN",
    "founder": "5GKvu9qC8VPjXnofUxZP6zxTmvzTBCY1vpJAkh6gWF8YxPKy",
    "cid": "sha256:b04bea689845d9f45770a97c19bd346cba46ec5d5005c480bff30bcffc918973",
    "time": 1746536210.293653,
    "signature": "0xac8d1fd37064b46ffec56c5c5e11efefb89b2414f24070b6a7d080c8dfa99b10f06f21f4dfc70db960ddefa787ce6d6daa11444c93e94ee3259edbe092e15f84"
}