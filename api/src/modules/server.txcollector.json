{
    "code": {
        "txcollector.py": "\nimport os\nimport json\nimport time\nimport asyncio\nimport commune as c\nfrom typing import Dict, List, Optional, Any, Union\n\nclass TxCollector:\n    \"\"\"\n    Transaction Collector for tracking API requests and responses.\n    This separates transaction tracking from the Store module to maintain separation of concerns.\n    \"\"\"\n    \n    def __init__(self, \n                 dirpath: str = '~/.commune/server/transactions',\n                 retention_days: int = 30,\n                 batch_size: int = 100):\n        \"\"\"\n        Initialize the transaction collector\n        \n        Args:\n            dirpath: Directory to store transaction logs\n            retention_days: How many days to keep transaction logs\n            batch_size: How many transactions to batch before writing to disk\n        \"\"\"\n        self.dirpath = os.path.abspath(os.path.expanduser(dirpath))\n        self.retention_days = retention_days\n        self.batch_size = batch_size\n        self.pending_transactions = []\n        self.lock = asyncio.Lock()\n        \n        # Create directory if it doesn't exist\n        if not os.path.exists(self.dirpath):\n            os.makedirs(self.dirpath, exist_ok=True)\n            \n        # Start background tasks\n        asyncio.create_task(self.periodic_flush())\n        asyncio.create_task(self.cleanup_old_transactions())\n    \n    async def record_transaction(self, transaction_data: Dict) -> str:\n        \"\"\"\n        Record a transaction asynchronously\n        \n        Args:\n            transaction_data: Dictionary containing transaction information\n            \n        Returns:\n            Transaction ID\n        \"\"\"\n        # Generate transaction ID\n        tx_id = self.generate_tx_id(transaction_data)\n        \n        # Add metadata\n        transaction_data['tx_id'] = tx_id\n        transaction_data['timestamp'] = transaction_data.get('timestamp', time.time())\n        \n        # Add to pending transactions\n        async with self.lock:\n            self.pending_transactions.append(transaction_data)\n            \n            # If we've reached batch size, flush to disk\n            if len(self.pending_transactions) >= self.batch_size:\n                await self.flush_transactions()\n                \n        return tx_id\n    \n    def generate_tx_id(self, data: Dict) -> str:\n        \"\"\"Generate a unique transaction ID based on the data\"\"\"\n        # Create a string representation of the data\n        data_str = json.dumps(data, sort_keys=True)\n        # Hash it with a timestamp to ensure uniqueness\n        tx_hash = c.hash(f\"{data_str}_{time.time()}\")\n        return tx_hash\n    \n    async def flush_transactions(self) -> None:\n        \"\"\"Flush pending transactions to disk\"\"\"\n        async with self.lock:\n            if not self.pending_transactions:\n                return\n                \n            # Group transactions by date for easier querying\n            date_str = time.strftime(\"%Y-%m-%d\", time.localtime())\n            hour_str = time.strftime(\"%H\", time.localtime())\n            \n            # Create directory structure\n            date_dir = os.path.join(self.dirpath, date_str)\n            os.makedirs(date_dir, exist_ok=True)\n            \n            # Create filename with timestamp to avoid collisions\n            filename = f\"{hour_str}_{int(time.time())}.json\"\n            filepath = os.path.join(date_dir, filename)\n            \n            # Write transactions to file\n            with open(filepath, 'w') as f:\n                json.dump(self.pending_transactions, f)\n                \n            # Clear pending transactions\n            self.pending_transactions = []\n    \n    async def periodic_flush(self) -> None:\n        \"\"\"Periodically flush transactions to disk\"\"\"\n        while True:\n            await asyncio.sleep(60)  # Flush every minute\n            await self.flush_transactions()\n    \n    async def cleanup_old_transactions(self) -> None:\n        \"\"\"Clean up old transaction logs\"\"\"\n        while True:\n            await asyncio.sleep(86400)  # Run once a day\n            \n            # Get current time\n            current_time = time.time()\n            \n            # Walk through directory and remove old files\n            for root, dirs, files in os.walk(self.dirpath):\n                for dir_name in dirs:\n                    try:\n                        # Parse directory name as date\n                        dir_path = os.path.join(root, dir_name)\n                        dir_time = time.mktime(time.strptime(dir_name, \"%Y-%m-%d\"))\n                        \n                        # If directory is older than retention period, remove it\n                        if current_time - dir_time > self.retention_days * 86400:\n                            import shutil\n                            shutil.rmtree(dir_path)\n                    except ValueError:\n                        # Skip directories that don't match our date format\n                        pass\n    \n    def query_transactions(self, \n                          start_time: Optional[float] = None,\n                          end_time: Optional[float] = None,\n                          client_key: Optional[str] = None,\n                          path: Optional[str] = None,\n                          limit: int = 100) -> List[Dict]:\n        \"\"\"\n        Query transactions based on various filters\n        \n        Args:\n            start_time: Start timestamp for query range\n            end_time: End timestamp for query range\n            client_key: Filter by client key\n            path: Filter by request path\n            limit: Maximum number of results to return\n            \n        Returns:\n            List of matching transactions\n        \"\"\"\n        results = []\n        \n        # Default time range if not specified\n        if not end_time:\n            end_time = time.time()\n        if not start_time:\n            start_time = end_time - 86400  # Default to last 24 hours\n            \n        # Convert timestamps to dates for directory traversal\n        start_date = time.strftime(\"%Y-%m-%d\", time.localtime(start_time))\n        end_date = time.strftime(\"%Y-%m-%d\", time.localtime(end_time))\n        \n        # Walk through date directories\n        for root, dirs, files in os.walk(self.dirpath):\n            dir_name = os.path.basename(root)\n            \n            # Skip if directory is outside our date range\n            if dir_name < start_date or dir_name > end_date:\n                continue\n                \n            # Process files in this directory\n            for filename in files:\n                if not filename.endswith('.json'):\n                    continue\n                    \n                filepath = os.path.join(root, filename)\n                \n                try:\n                    with open(filepath, 'r') as f:\n                        transactions = json.load(f)\n                        \n                    # Filter transactions\n                    for tx in transactions:\n                        # Skip if outside time range\n                        tx_time = tx.get('timestamp', 0)\n                        if tx_time < start_time or tx_time > end_time:\n                            continue\n                            \n                        # Skip if client key doesn't match\n                        if client_key and tx.get('client', {}).get('key') != client_key:\n                            continue\n                            \n                        # Skip if path doesn't match\n                        if path and tx.get('path') != path:\n                            continue\n                            \n                        # Add to results\n                        results.append(tx)\n                        \n                        # Check if we've reached the limit\n                        if len(results) >= limit:\n                            return results\n                except Exception as e:\n                    print(f\"Error processing file {filepath}: {e}\")\n                    \n        return results\n    \n    def get_transaction(self, tx_id: str) -> Optional[Dict]:\n        \"\"\"\n        Retrieve a specific transaction by ID\n        \n        Args:\n            tx_id: Transaction ID to retrieve\n            \n        Returns:\n            Transaction data or None if not found\n        \"\"\"\n        # Walk through all transaction files\n        for root, dirs, files in os.walk(self.dirpath):\n            for filename in files:\n                if not filename.endswith('.json'):\n                    continue\n                    \n                filepath = os.path.join(root, filename)\n                \n                try:\n                    with open(filepath, 'r') as f:\n                        transactions = json.load(f)\n                        \n                    # Look for matching transaction\n                    for tx in transactions:\n                        if tx.get('tx_id') == tx_id:\n                            return tx\n                except Exception as e:\n                    print(f\"Error processing file {filepath}: {e}\")\n                    \n        return None\n    \n    def get_stats(self, days: int = 7) -> Dict:\n        \"\"\"\n        Get transaction statistics\n        \n        Args:\n            days: Number of days to include in statistics\n            \n        Returns:\n            Dictionary with statistics\n        \"\"\"\n        stats = {\n            'total_transactions': 0,\n            'transactions_by_day': {},\n            'transactions_by_path': {},\n            'transactions_by_client': {},\n            'average_response_time': 0\n        }\n        \n        # Calculate start time\n        start_time = time.time() - (days * 86400)\n        \n        # Query transactions\n        transactions = self.query_transactions(\n            start_time=start_time,\n            limit=10000  # Set a high limit for stats\n        )\n        \n        # Calculate statistics\n        total_response_time = 0\n        for tx in transactions:\n            # Increment total\n            stats['total_transactions'] += 1\n            \n            # Group by day\n            day = time.strftime(\"%Y-%m-%d\", time.localtime(tx.get('timestamp', 0)))\n            stats['transactions_by_day'][day] = stats['transactions_by_day'].get(day, 0) + 1\n            \n            # Group by path\n            path = tx.get('path', 'unknown')\n            stats['transactions_by_path'][path] = stats['transactions_by_path'].get(path, 0) + 1\n            \n            # Group by client\n            client = tx.get('client', {}).get('key', 'unknown')\n            stats['transactions_by_client'][client] = stats['transactions_by_client'].get(client, 0) + 1\n            \n            # Add response time if available\n            if 'duration' in tx:\n                total_response_time += tx['duration']\n                \n        # Calculate average response time\n        if stats['total_transactions'] > 0:\n            stats['average_response_time'] = total_response_time / stats['total_transactions']\n            \n        return stats\n    \n    async def test(self) -> Dict:\n        \"\"\"Run tests on the transaction collector\"\"\"\n        # Generate test transaction\n        test_tx = {\n            'client': {'key': 'test_key'},\n            'path': '/test',\n            'method': 'GET',\n            'ip': '127.0.0.1'\n        }\n        \n        # Record transaction\n        tx_id = await self.record_transaction(test_tx)\n        \n        # Force flush\n        await self.flush_transactions()\n        \n        # Query transaction\n        result = self.get_transaction(tx_id)\n        \n        # Verify result\n        success = result is not None and result['tx_id'] == tx_id\n        \n        return {\n            'success': success,\n            'tx_id': tx_id,\n            'result': result\n        }\n"
    },
    "schema": {
        "generate_tx_id": {
            "input": {
                "self": {
                    "value": "_empty",
                    "type": "_empty"
                },
                "data": {
                    "value": "_empty",
                    "type": "_empty"
                }
            },
            "output": {
                "value": null,
                "type": "<class 'str'>"
            },
            "docs": "Generate a unique transaction ID based on the data",
            "cost": 1,
            "name": "generate_tx_id",
            "source": {
                "start": 68,
                "length": 7,
                "path": "~/commune/commune/core/server/txcollector.py",
                "code": null,
                "hash": "sha256:4a31e5568c93dc7cb97e71aed73b56396b35642b82bcba2dd3cc996c99c29462",
                "end": 75
            }
        },
        "get_stats": {
            "input": {
                "self": {
                    "value": "_empty",
                    "type": "_empty"
                },
                "days": {
                    "value": 7,
                    "type": "int"
                }
            },
            "output": {
                "value": null,
                "type": "typing.Dict"
            },
            "docs": "\n        Get transaction statistics\n        \n        Args:\n            days: Number of days to include in statistics\n            \n        Returns:\n            Dictionary with statistics\n        ",
            "cost": 1,
            "name": "get_stats",
            "source": {
                "start": 238,
                "length": 54,
                "path": "~/commune/commune/core/server/txcollector.py",
                "code": null,
                "hash": "sha256:44e9dd574ffc28579690eed0076158a1bc7a615f8492a0ec7d91dbcb5df89de1",
                "end": 292
            }
        },
        "get_transaction": {
            "input": {
                "self": {
                    "value": "_empty",
                    "type": "_empty"
                },
                "tx_id": {
                    "value": "_empty",
                    "type": "_empty"
                }
            },
            "output": {
                "value": null,
                "type": "typing.Optional[typing.Dict]"
            },
            "docs": "\n        Retrieve a specific transaction by ID\n        \n        Args:\n            tx_id: Transaction ID to retrieve\n            \n        Returns:\n            Transaction data or None if not found\n        ",
            "cost": 1,
            "name": "get_transaction",
            "source": {
                "start": 207,
                "length": 30,
                "path": "~/commune/commune/core/server/txcollector.py",
                "code": null,
                "hash": "sha256:5621f4f112332d2574c57ec9021dff3c99572c5dd743e2297c1f6468c0fa9326",
                "end": 237
            }
        },
        "query_transactions": {
            "input": {
                "self": {
                    "value": "_empty",
                    "type": "_empty"
                },
                "start_time": {
                    "value": null,
                    "type": "NoneType"
                },
                "end_time": {
                    "value": null,
                    "type": "NoneType"
                },
                "client_key": {
                    "value": null,
                    "type": "NoneType"
                },
                "path": {
                    "value": null,
                    "type": "NoneType"
                },
                "limit": {
                    "value": 100,
                    "type": "int"
                }
            },
            "output": {
                "value": null,
                "type": "typing.List[typing.Dict]"
            },
            "docs": "\n        Query transactions based on various filters\n        \n        Args:\n            start_time: Start timestamp for query range\n            end_time: End timestamp for query range\n            client_key: Filter by client key\n            path: Filter by request path\n            limit: Maximum number of results to return\n            \n        Returns:\n            List of matching transactions\n        ",
            "cost": 1,
            "name": "query_transactions",
            "source": {
                "start": 131,
                "length": 75,
                "path": "~/commune/commune/core/server/txcollector.py",
                "code": null,
                "hash": "sha256:07df0b0088e018bb16c4dfe475f7258390cd9de1ceb4269d8856c4e3c8a9875e",
                "end": 206
            }
        }
    },
    "name": "server.txcollector",
    "key": "5FWtueY9ajeXNoxCe9Vpw7e3YvoLgXT4JYgj7TmkacFZ2C2K",
    "founder": "5GKvu9qC8VPjXnofUxZP6zxTmvzTBCY1vpJAkh6gWF8YxPKy",
    "cid": "sha256:18000c3a00c439f82cf65b8146db7896adb58b2dbc557c53df5d8f2cd3ed3019",
    "time": 1746536238.5216792,
    "signature": "0x04d11e92ba36c411b01a4284aac6e2943f62204394c6633feee3a8c3ff78035e2bfae42e1a845654c202e2ea003ff272c775e72cfc0e7e4c6c4758ce88950b8a"
}